{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture state\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'CIFAR2-Pool'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='cifar2_pool')\n",
    "epochs = 100\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 10000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy')\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM')\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='cifar2_pool')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(32,32,3))\n",
    "visualize(noisy_data[x_vis].reshape(32,32,3))\n",
    "visualize(fgsm_data[x_vis].reshape(32,32,3))\n",
    "visualize(bim_data[x_vis].reshape(32,32,3))\n",
    "visualize(cw_data[x_vis].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,32,32,3))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,32,32,3))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,32,32,3))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,32,32,3))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.81\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate using just norm\n",
    "gamma = 0.15\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use both cos and norm\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
