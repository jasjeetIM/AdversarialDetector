{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture state\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 10.8897 - acc: 0.5664 - val_loss: 3.2274 - val_acc: 0.6900\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 1.8725 - acc: 0.7265 - val_loss: 0.8917 - val_acc: 0.8720\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.6674 - acc: 0.8753 - val_loss: 0.3955 - val_acc: 0.9420\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4179 - acc: 0.8921 - val_loss: 0.5364 - val_acc: 0.8040\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.3324 - acc: 0.9127 - val_loss: 0.2586 - val_acc: 0.9420\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2926 - acc: 0.9177 - val_loss: 0.4108 - val_acc: 0.8570\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2612 - acc: 0.9291 - val_loss: 0.2081 - val_acc: 0.9500\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2358 - acc: 0.9350 - val_loss: 0.2304 - val_acc: 0.9340\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2355 - acc: 0.9322 - val_loss: 0.1786 - val_acc: 0.9580\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1979 - acc: 0.9489 - val_loss: 0.3379 - val_acc: 0.8820\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1961 - acc: 0.9477 - val_loss: 0.1692 - val_acc: 0.9530\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1764 - acc: 0.9540 - val_loss: 0.3329 - val_acc: 0.8990\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1833 - acc: 0.9509 - val_loss: 0.1871 - val_acc: 0.9500\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1616 - acc: 0.9583 - val_loss: 0.1330 - val_acc: 0.9630\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1597 - acc: 0.9579 - val_loss: 0.1453 - val_acc: 0.9620\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1629 - acc: 0.9565 - val_loss: 0.2052 - val_acc: 0.9400\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1431 - acc: 0.9640 - val_loss: 0.1527 - val_acc: 0.9590\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1444 - acc: 0.9617 - val_loss: 0.1742 - val_acc: 0.9490\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1337 - acc: 0.9672 - val_loss: 0.3679 - val_acc: 0.8770\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1373 - acc: 0.9648 - val_loss: 0.1216 - val_acc: 0.9690\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1234 - acc: 0.9695 - val_loss: 0.3618 - val_acc: 0.8820\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1325 - acc: 0.9663 - val_loss: 0.1195 - val_acc: 0.9720\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1195 - acc: 0.9696 - val_loss: 0.1292 - val_acc: 0.9690\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1267 - acc: 0.9684 - val_loss: 0.1507 - val_acc: 0.9520\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1153 - acc: 0.9714 - val_loss: 0.1159 - val_acc: 0.9710\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1145 - acc: 0.9708 - val_loss: 0.2106 - val_acc: 0.9390\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1212 - acc: 0.9688 - val_loss: 0.2430 - val_acc: 0.9380\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1069 - acc: 0.9724 - val_loss: 0.1153 - val_acc: 0.9670\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1054 - acc: 0.9739 - val_loss: 0.1065 - val_acc: 0.9750\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1144 - acc: 0.9712 - val_loss: 0.1987 - val_acc: 0.9440\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1011 - acc: 0.9753 - val_loss: 0.1034 - val_acc: 0.9680\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0992 - acc: 0.9765 - val_loss: 0.2503 - val_acc: 0.9280\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1000 - acc: 0.9769 - val_loss: 0.2700 - val_acc: 0.9110\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1262 - acc: 0.9708 - val_loss: 0.1024 - val_acc: 0.9740\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0869 - acc: 0.9798 - val_loss: 0.2358 - val_acc: 0.9400\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0917 - acc: 0.9778 - val_loss: 0.0964 - val_acc: 0.9790\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0932 - acc: 0.9771 - val_loss: 0.0976 - val_acc: 0.9740\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0877 - acc: 0.9789 - val_loss: 0.1019 - val_acc: 0.9690\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1022 - acc: 0.9742 - val_loss: 0.1345 - val_acc: 0.9650\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0811 - acc: 0.9814 - val_loss: 0.5137 - val_acc: 0.8580\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0824 - acc: 0.9808 - val_loss: 0.1465 - val_acc: 0.9640\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0862 - acc: 0.9800 - val_loss: 0.1190 - val_acc: 0.9670\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0824 - acc: 0.9803 - val_loss: 0.1284 - val_acc: 0.9690\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0813 - acc: 0.9812 - val_loss: 0.1023 - val_acc: 0.9730\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0832 - acc: 0.9800 - val_loss: 0.1155 - val_acc: 0.9710\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0796 - acc: 0.9819 - val_loss: 0.0946 - val_acc: 0.9760\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0807 - acc: 0.9804 - val_loss: 0.0891 - val_acc: 0.9830\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0762 - acc: 0.9825 - val_loss: 0.0958 - val_acc: 0.9790\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0754 - acc: 0.9824 - val_loss: 0.0854 - val_acc: 0.9780\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0767 - acc: 0.9814 - val_loss: 0.1473 - val_acc: 0.9620\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0730 - acc: 0.9836 - val_loss: 0.1128 - val_acc: 0.9680\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0706 - acc: 0.9830 - val_loss: 0.1337 - val_acc: 0.9640\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0727 - acc: 0.9839 - val_loss: 0.1471 - val_acc: 0.9550\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0682 - acc: 0.9850 - val_loss: 0.1066 - val_acc: 0.9720\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0715 - acc: 0.9835 - val_loss: 0.1451 - val_acc: 0.9600\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0583 - acc: 0.9873 - val_loss: 0.2445 - val_acc: 0.9420\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0618 - acc: 0.9864 - val_loss: 0.1044 - val_acc: 0.9740\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0597 - acc: 0.9875 - val_loss: 0.3040 - val_acc: 0.9480\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0598 - acc: 0.9875 - val_loss: 0.2056 - val_acc: 0.9460\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0647 - acc: 0.9867 - val_loss: 0.1185 - val_acc: 0.9720\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0552 - acc: 0.9884 - val_loss: 0.1147 - val_acc: 0.9700\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0532 - acc: 0.9888 - val_loss: 0.1447 - val_acc: 0.9620\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0540 - acc: 0.9886 - val_loss: 0.1138 - val_acc: 0.9680\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0557 - acc: 0.9884 - val_loss: 0.0890 - val_acc: 0.9840\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0541 - acc: 0.9889 - val_loss: 0.0828 - val_acc: 0.9800\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0545 - acc: 0.9888 - val_loss: 0.0845 - val_acc: 0.9800\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0562 - acc: 0.9884 - val_loss: 0.0990 - val_acc: 0.9750\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0507 - acc: 0.9905 - val_loss: 0.1013 - val_acc: 0.9730\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0539 - acc: 0.9882 - val_loss: 0.0995 - val_acc: 0.9760\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0453 - acc: 0.9903 - val_loss: 0.1641 - val_acc: 0.9590\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0485 - acc: 0.9898 - val_loss: 0.0984 - val_acc: 0.9770\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0447 - acc: 0.9920 - val_loss: 0.0801 - val_acc: 0.9790\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0448 - acc: 0.9908 - val_loss: 0.0972 - val_acc: 0.9750\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0472 - acc: 0.9903 - val_loss: 0.1605 - val_acc: 0.9510\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0490 - acc: 0.9899 - val_loss: 0.1349 - val_acc: 0.9710\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0410 - acc: 0.9930 - val_loss: 0.2078 - val_acc: 0.9280\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0390 - acc: 0.9933 - val_loss: 0.1409 - val_acc: 0.9640\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0440 - acc: 0.9899 - val_loss: 0.3638 - val_acc: 0.9340\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0520 - acc: 0.9884 - val_loss: 0.0929 - val_acc: 0.9810\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0360 - acc: 0.9940 - val_loss: 0.0904 - val_acc: 0.9780\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0414 - acc: 0.9915 - val_loss: 0.1438 - val_acc: 0.9690\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0413 - acc: 0.9923 - val_loss: 0.1023 - val_acc: 0.9780\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0370 - acc: 0.9939 - val_loss: 0.1144 - val_acc: 0.9760\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0352 - acc: 0.9930 - val_loss: 0.0957 - val_acc: 0.9800\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0360 - acc: 0.9936 - val_loss: 0.1003 - val_acc: 0.9750\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0380 - acc: 0.9922 - val_loss: 0.0938 - val_acc: 0.9820\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0372 - acc: 0.9938 - val_loss: 0.1005 - val_acc: 0.9740\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0341 - acc: 0.9940 - val_loss: 0.0943 - val_acc: 0.9790\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0428 - acc: 0.9907 - val_loss: 0.1126 - val_acc: 0.9650\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0320 - acc: 0.9950 - val_loss: 0.0913 - val_acc: 0.9760\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0378 - acc: 0.9932 - val_loss: 0.0855 - val_acc: 0.9770\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0339 - acc: 0.9936 - val_loss: 0.0932 - val_acc: 0.9690\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0273 - acc: 0.9966 - val_loss: 0.2400 - val_acc: 0.9480\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0282 - acc: 0.9953 - val_loss: 0.1070 - val_acc: 0.9740\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0249 - acc: 0.9952 - val_loss: 0.0985 - val_acc: 0.9790\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0375 - acc: 0.9916 - val_loss: 0.0946 - val_acc: 0.9750\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0306 - acc: 0.9953 - val_loss: 0.0825 - val_acc: 0.9840\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0272 - acc: 0.9952 - val_loss: 0.1469 - val_acc: 0.9700\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0257 - acc: 0.9955 - val_loss: 0.0925 - val_acc: 0.9770\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0310 - acc: 0.9951 - val_loss: 0.0883 - val_acc: 0.9830\n",
      "1198/1198 [==============================] - 1s 573us/step\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'CIFAR2'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='cifar2')\n",
    "epochs = 100\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 10000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebook/cleverhans/cleverhans/src/cleverhans/cleverhans/utils_keras.py:144: UserWarning: Please update your version to keras >= 2.1.3; support for earlier keras versions will be dropped on 2018-07-22\n",
      "  \"Please update your version to keras >= 2.1.3; \"\n"
     ]
    }
   ],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy')\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM')\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-577e7ca8c674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmod_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Get a test point with the target label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mguide_imgs_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmod_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Choose a guide image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mguide_img_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_imgs_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "#Whitebox CW Attack\n",
    "#First get guide images\n",
    "guide_indices = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images for modified CW attacks\n",
    "for idx in test_indices:\n",
    "    label = np.argmax(model.test_labels[idx])\n",
    "    #Add 1 to the label mod 10 to get a target label\n",
    "    mod_label = (label + 1) % 10\n",
    "    #Get a test point with the target label\n",
    "    guide_imgs_indices = np.where(model.train_labels[:,mod_label] == 1)[0]\n",
    "    #Choose a guide image\n",
    "    guide_img_idx = np.random.choice(guide_imgs_indices, 1)[0]\n",
    "    guide_indices.append(guide_img_idx)\n",
    "\n",
    "\n",
    "#1 Phase Attack\n",
    "p1_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True)\n",
    "\n",
    "#2 Phase Attack\n",
    "#Phase 1: Generate targeted adversarial images\n",
    "tar_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, use_cos_norm_reg=False)\n",
    "#Phase 2: Optimize for higher cosine sim and smaller norm\n",
    "p2_cw_data = model.generate_perturbed_data(tar_cw_data, model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='cifar2')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(32,32,3))\n",
    "visualize(noisy_data[x_vis].reshape(32,32,3))\n",
    "visualize(fgsm_data[x_vis].reshape(32,32,3))\n",
    "visualize(bim_data[x_vis].reshape(32,32,3))\n",
    "visualize(cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p1_cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p2_cw_data[x_vis].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,32,32,3))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,32,32,3))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,32,32,3))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,32,32,3))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,32,32,3))\n",
    "p1_cw_preds = model.model.predict(p1_cw_data.reshape(-1,32,32,3))\n",
    "p2_cw_preds = model.model.predict(p2_cw_data.reshape(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1\n",
    "\n",
    "p1_cw_labels = np.zeros(p1_cw_preds.shape)\n",
    "p1_cw_labels[np.arange(num_test_samples),np.argmax(p1_cw_preds, axis=1)] = 1\n",
    "\n",
    "p2_cw_labels = np.zeros(p2_cw_preds.shape)\n",
    "p2_cw_labels[np.arange(num_test_samples),np.argmax(p2_cw_preds, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))\n",
    "print (np.argmax(p1_cw_preds, axis=1))\n",
    "print (np.argmax(p2_cw_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "grads_p1_cw = model.get_gradients_wrt_params(p1_cw_data, p1_cw_labels)\n",
    "grads_p2_cw = model.get_gradients_wrt_params(p2_cw_data, p2_cw_labels)\n",
    "\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "grads_p1_cw_nm = normalize(grads_p1_cw)\n",
    "grads_p2_cw_nm = normalize(grads_p2_cw)\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()\n",
    "grads_p1_cw_norms = np.sqrt(np.dot(grads_p1_cw, grads_p1_cw.T)).diagonal()\n",
    "grads_p2_cw_norms = np.sqrt(np.dot(grads_p2_cw, grads_p2_cw.T)).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p1_cw = np.dot(grads_p1_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p2_cw = np.dot(grads_p2_cw_nm, grads_train_nm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.81\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('1 Phase CW:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('2 Phase CW:  %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate using just norm\n",
    "gamma = 0.15\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use both cos and norm\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta and grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta and grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
