{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture state\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4485 - acc: 0.8573 - val_loss: 0.0972 - val_acc: 0.9728\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1599 - acc: 0.9531 - val_loss: 0.0624 - val_acc: 0.9800\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1218 - acc: 0.9638 - val_loss: 0.0502 - val_acc: 0.9846\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1004 - acc: 0.969 - 3s 43us/step - loss: 0.1002 - acc: 0.9696 - val_loss: 0.0446 - val_acc: 0.9848\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0902 - acc: 0.9737 - val_loss: 0.0402 - val_acc: 0.9880\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0783 - acc: 0.9760 - val_loss: 0.0349 - val_acc: 0.9894\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0699 - acc: 0.9787 - val_loss: 0.0355 - val_acc: 0.9894\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0664 - acc: 0.9797 - val_loss: 0.0308 - val_acc: 0.9882\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0609 - acc: 0.9817 - val_loss: 0.0306 - val_acc: 0.9906\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.0329 - val_acc: 0.9894\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0541 - acc: 0.9840 - val_loss: 0.0289 - val_acc: 0.9912\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0509 - acc: 0.9846 - val_loss: 0.0276 - val_acc: 0.9908\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0500 - acc: 0.9848 - val_loss: 0.0280 - val_acc: 0.9914\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0467 - acc: 0.9856 - val_loss: 0.0261 - val_acc: 0.9924\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0456 - acc: 0.9865 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0436 - acc: 0.9870 - val_loss: 0.0266 - val_acc: 0.9918\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0425 - acc: 0.9874 - val_loss: 0.0262 - val_acc: 0.9914\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0406 - acc: 0.9877 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0392 - acc: 0.9883 - val_loss: 0.0269 - val_acc: 0.9920\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0386 - acc: 0.9885 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0370 - acc: 0.9882 - val_loss: 0.0248 - val_acc: 0.9924\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0353 - acc: 0.9893 - val_loss: 0.0250 - val_acc: 0.9926\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0357 - acc: 0.9890 - val_loss: 0.0256 - val_acc: 0.9924\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0244 - val_acc: 0.9936\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.0233 - val_acc: 0.9930\n",
      "6042/6042 [==============================] - 0s 13us/step\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'MNIST-Pool'\n",
    "input_shape = (28,28,1)\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='mnist_pool')\n",
    "epochs = 25\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 1000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebook/cleverhans/cleverhans/src/cleverhans/cleverhans/utils_keras.py:144: UserWarning: Please update your version to keras >= 2.1.3; support for earlier keras versions will be dropped on 2018-07-22\n",
      "  \"Please update your version to keras >= 2.1.3; \"\n"
     ]
    }
   ],
   "source": [
    "num_test_samples_per_class = 10\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy', eps=0.1)\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM', eps=0.1)\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10, eps=0.1)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False, eps=0.1)\n",
    "df_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='DF')\n",
    "jsma_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='JSMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist_pool')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA25JREFUeJztmz8ovWsAxz9HFjFIUQaShEVEiZQIg8GgFIPYWRQGSRYD\nszJTktWo/MmfolAoJoMNWQz+FeU33N5zrnvruu7vnK/3vPf72bznzfP49Onped/ziH18fGA0ZPz0\nBP5PWLYQyxZi2UIsW4hlC7FsIZYtxLKFZIrHi/LjauyrG1y2EMsWYtlCLFuIZQuxbCGWLUS9zw4N\n19fXAIyOjgIwPj4OQENDQ8rGdNlCIlv2+fk5AO/v75+uPz8/A9Db2wvAzc0NAH19fYDLjgyRLPvu\n7o7GxkYAXl5e/vHekZERAHp6elI+L5ctJFJlv729ATAzMxMvuqSkBID8/HwA2tvbAeLlt7W1ARCL\nffnS7rdx2UJi4hNRKR1sd3cXgJaWlvi1vb09AJqamlI5NPh9driIRNnB3rmgoCD+c7BGB0+KWVlZ\nqRj6z7jsMJHWu5HX11cAZmdngUThAPf39wCUlZUBsLi4CEBHR4dwhp9x2ULSes3e398HoLm5+W+f\n9ff3A7C8vAxAYWEhAJOTkwAMDQ0lcyrgNTtcpHXZAwMDQKLeiooKALa3t+M7k7OzMwDq6uoAyMj4\no6/j42MAampqkjUdlx0m0rrsh4cHIFFvdXU1ALm5ufF7np6eAOju7gZgY2MDgMPDQwDq6+uTNZ0v\ny05r2d9hfX0dgM7OTgCGh4cBmJ+fT9YQXkbCRFo/1HyHYDkJuL29lc/BZQuJfNnBI/309PSn611d\nXfK5uGwhkS97a2sLgIuLCwCys7MBaG1tlc/FZQuJ7D778fERSLykOj09BeDy8hKAysrKZA/pfXaY\niOSavbOzEz98ExRdXFwMJL5M+AlctpBIlL25uQnA6uoqACsrK/FDOkVFRQAcHBwAkJn5c3+yyxYS\nyt3IyckJAHNzcwDU1tZ++nxtbe3TfX89FpyTk8Pg4CAAU1NTQOKYQwrxbiRMhLLs8vJyAK6urv7V\nLw3W4eDY78TEBFVVVf9lfr+Dyw4ToSx7YWEBgKWlJQCOjo4AGBsbA6C0tBRIlBx8iZuXl5fEqX4b\nlx0mQll2muKyw4RlC7FsIZYtxLKFWLYQyxaifrmb+v/sDDEuW4hlC7FsIZYtxLKFWLYQyxZi2UIs\nW4hlC7FsIZYtxLKFWLYQyxZi2UIsW4hlC7FsIZYtxLKFWLYQyxbyC+fl53LX5ykCAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc956548610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABKZJREFUeJztm88rfG8Ux19+hMVISkphYWGhKDYkWdlISfb2lJ0FSspK\nltZko0hKFsofYGOlrCgLNU0UUgphYT6L7/eZO3PNvfe5d3zPfb59zmsz7nPPPM/j9J4z557zTFU+\nn0eRoTrtDfxNqLMFUWcLos4WRJ0tiDpbEHW2IOpsQdTZgtRKLvb6+poHyGQyQfcpvh/3ungev40h\nau0gLOarCp0AVbYoosr241dmkHps5ylHkJKj7G2VHgdVtiBVwlW/PETH0aBYHEQ5+zjx3WYvUWQy\nGY3ZLpFKzParLWmMtskskio6ajxonjBU2YJI59lAtFri5shJMoPv728ARkZGADg+Pgagq6srdO2g\nDMoGVbYgospOmvMabDMMgPPzcwC+vr4A6O3tBeDj4wOA7u7uEvujoyMAZmdny64RRJzMSZUtSKp5\ntm1OG7eeUVtbS39/PwDX19dlbTo7OwEYGhoCYHt7G4CqqtJ0OcYeNc92iVSyEf+1Xz1B8TIqfpr4\nPDMzw/v7OwA1NTUANDc3A7C2tgZ4ih4YGAjdS1RWEgdVtiCpVv0Mtt/4fvwq3NvbA+Di4qIwdnV1\nBUBbW5vV3L9dtylGlS2IaDZiOjVBxM2r/dc9PT0AvL29kc1mAfD/f5VWFLVT8z8h1apfXLsgRW9t\nbQFefAYvjzZ58+XlJfCz9mFbh6kkVhtU2YKk8gTpJ25XxYzf3NwAMDY2BlCI0wCLi4sA7O/vl9xb\nWloCYH19vezcfmxPAqAx2y1SyUZsqna+95VcG3uj0o2NDQAmJiYK1x0dHQC8vLwAXt26uvoffZ2d\nnQHQ3t5utReLT58q2yVSzbNt82q/vRl/eHgAvJpIXV0dAK2trQXbu7s7wFP27e1tyWtLS0vomn5C\n9hapbCecXckxs7Dx4nsm9ZucnARgbm4OgPn5+bJ7TZASahhxCScKUbYPL3GaDn4b0w4z3N/fh+4p\nKqQFrROGKlsQJxq+v6GaIPvHx0fAe/Axa01PT5e8J+6Xs5ZYHceJQzoVHGYsa198GP7w8LCsTVNT\nU+geKjlGEYQqW5BUC1G/VeYsN57L5QDo6+sDoLGxEYDd3V0ARkdHrTYcY03Ns13CiTzbT9KDlcY+\nl8uxsrJScs80DfyKjvt4HvSTFD1+5hhONA8qZWdnB/AaBAcHB4VjZ0bJp6engHdUOCkhCtaY7RKp\n5tlBMfnk5ASA1dVVAIaHh0vsnp+fAa/lZTBN3mw2y9TUVIlNQ0ND6F7i7jUJqmxBnDoybKivrwe8\npoAfo2CDidULCwsAjI+PMzg4WLJG3CqebSZUhMZsl0i14Vs0TvH48vIy4B1Qf3p6AmBzcxPw2mEm\nppuDOJ+fn4U5k1YYk+bdqLLdwomDlZUc6fp33h/zJO1rVoAq2yVS7dTE/RlHkm57pQr/zU+IKluQ\nVJ8go6p4/vfZKr/4b9snv/8ghv9AlS1IKvVs2256VGwOi59JaxlxPj1xUWULIl0b+atRZQuizhZE\nnS2IOlsQdbYg6mxB1NmCqLMFUWcLos4WRJ0tiDpbEHW2IOpsQdTZgqizBVFnC6LOFkSdLYg6WxB1\ntiDqbEHU2YL8ASVcxJBvF1WnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9564dfbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABEVJREFUeJztnMErPH8Yx1/Ym+WgSJKDSFHIBSVHB8oFJaXEUUQpN7fN\nzb9AOVAUiuTi7OCgbOTgspKkRE2klN/h2+z8Zto1MzvrmY/v93ldtp2ZnefTu/c883ye+cyWfH19\nochQGvcA/iVUbEFUbEFUbEFUbEFUbEFUbEFUbEFUbEESksEsyzJ2uppMJl3fLcvKuT/fdqDEL4Y6\nWxBRZ5uIn6P9todBnS3IX+/sfLnWxt5uHxfU6YWgzhYkFmd73ROWIG6LGsN7Hu8VUIjj1dmCiDo7\nqNui5skgca6vrwGYmZkBYH9/H4DGxsZvxxJlbOpsQYysRvJVBEHzpWVZnJ2dAdDS0gLA5eUlAM3N\nzQAsLi4C8Pr6CsDj4yMANTU1kcefD3W2INK9EcDfoVErgLu7O+bm5gB4e3v79tj5+XkAent7c8bI\nl/+1GjGcWHJ2UFd4XeXnePv7wcFB1tH39/cAjI6OAtDf3w9AT08PAHV1dTnPEXZsQVBnC1IiuSIq\naj/bz003NzcADAwMkMlkANje3gZgaGjIdQ6/+0UBaD/bJGJxdrH6Fl5aW1sBZ3YI8PDwQCExg1ZA\n+qTGUIzujQQ9fnp6GnA72sauQqampgAYHx8PNcZi9rfV2YL8it6IF9tdh4eHAKyvrwPQ0NAAQCaT\nYXl5GYCtrS0ANjY2AKeuHhwcdJ3LL1YxUGcLEmtvJCoXFxeA4+inpycA0uk0bW1tAMzOzgLQ19cH\nOPX28fGxa3u+MUV5MuNFnS1IrL2RQh1u/y6VSgFOpdHU1ARAIpHIxigrK3N92lfBx8dHzjH9JLFO\n139qcpNLuNvbWwCGh4cB6OrqAmBzczNSLJ3UGIqRpV9QwqSj09NTgGyDqqqqyrU/7I1QW6yGE6uz\nw94oC1n0+P7+DsDKyopr+8jISM7YP9VSAHW2KEbk7LBlV5gHwjs7O4CTo+3Sb2FhIdJYNWcbzl/1\nWOz/zn55eQGgvb0dgIqKCgDOz88BqK6ujjKUXA7XOtskYl0yHDZXB82Xe3t72cU3tsM7OjoAf0f7\nLdLRnP1LMKIaiUo6nQZgaWkJgJOTk+w+e1HO0dGR6zdBryq/V/S0zjYUI5YyeN3z/PwMwNraGgCf\nn5+u/bu7uwCUl5fn3F9ZWZltt66urgJQX18faewBHKzViEkYWWePjY0BcHV1BTidOht7FmiTSPy5\n9diVRiqVoru7+9sYxXqJSutsQzGyGuns7ASc2Z7NxMQEAJOTk4DzslFp6R/P1NbWFm0MQf8oIAzq\nbEGMytnFfCbp1xEM02f5Ds3ZhmLkwspiEtbRXnRh5S9FNGcDoYIV6qJkMhn6tb6wjtc623BicfZP\nv3wax70BdbZZSDv7n0adLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiK\nLYiKLYiKLYiKLYiKLYiKLYiKLYiKLYiKLch/mLbKMdsyWgEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9553f5410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDsSwXbkF39k2N6eGR3/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9553f54d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA2JJREFUeJztm00rrVEYhq+NfJWItE2YykD+gJESP0AkM0QKc0NDyUwp\nMvMfjJQBRUlGko8hSVEiH9k4Ay3vOUeHw9n79u733Ndk1+6t9eyru6dnrXft1PPzM0ZDwXcX8D9h\n2UIsW4hlC7FsIZYtxLKFWLYQyxZSJF4vydvV1EcPONlCLFuIZQuxbCGWLcSyhVi2EPWcHRsmJycB\nmJubA+Dg4ACAioqKnK3pZAtJbLJHR0cBmJqaAmBnZweAlpYWAE5OTgA4Pz8H4OHhIec1OdlCEpns\nxcVF1tbWAKiqqnr32e3tbQCqq6tzXpeTLSQlvjeS08XCb9nd3aW5uRmAkpISAGZmZgBoa2sDoLa2\nFoCzszMAmpqa/nV5n/rFiUQl++rqCnjpv5lMBoC+vj4AlpaWcrk0ONnxIhHTyOPjIxD140wmQ1HR\ny0+bmJj4trp+x8kWktc9++npCYgmif39/TfPDAwMAFBQ8JKr+fn5bJbwM+7ZcSKve3aYNEKiCwsL\ngZcevrGxAUBraysA/f39AJyengJQV1cnrRWcbCl53bNXVlYA6OzsBKC0tBSAra0tGhsbAbi5uQGg\nsrIS4HX+HhwcBGBhYSFb5bhnx4m8TnZI6e3tLQBlZWUArzM2wObmJgAdHR0AXF5eAm/Pt7PAh8nO\na9mf4eLiAoB0Og1AQ0MDAEdHR9lawm0kTuT16PcZhoaGgKj1XF9fy2twsoUkPtmHh4cArK6u/vJ9\nFke+v8bJFpL4ZIdLOGEaCYdWYSOkxMkWktg5O2xmwguF+/t7IJpCwtY+i3jOjhOJ7Nnd3d0sLy8D\n0UHU+Pg4EF1t+A6cbCGJSPbe3h4Aw8PDAKyvr7++BB4ZGQFgenoagFTqw9aaM5xsIbFMdrgU2dXV\nBURXxcLRaTipu7u7A6JrZ+EznU4zNjYGQH19PQDFxcWK0t/FyRYSyzk77PLCXy9C/w38qe/W1NQA\n0NPTw+zs7JeL/CKes+NELHt2uO57fHwMRBcme3t7ASgvLwfeXv9tb2+X1vlZnGwhsezZeYp7dpyw\nbCGWLcSyhVi2EMsWYtlC1DvI7ztMjgFOthDLFmLZQixbiGULsWwhli3EsoVYthDLFmLZQixbiGUL\nsWwhli3EsoVYthDLFmLZQixbiGULsWwhli3kBytY7rr0I+xkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc95529b2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABURJREFUeJztmz1IHF0Uhh93/SNrMIUoWgRMFVBIIKYwZZA0IoJoEVNY\npbFJI4igtlqnSauF6YMgpJAogk0EsUgsTBoLQQJqBBPiz+5X6Nlx7u7srEbPzHw5TzPs/N3x5Z0z\n55x7rcjlchg6pKJ+gH8JE1sRE1sRE1sRE1sRE1sRE1sRE1sRE1uRSuXxfOWqW72G/c5mswCkUinf\n8YqKCt95qVSq4Jh7TuiDBty7BKEnmrMVqVDujRQdTJ4hzNku4rpS18lb4Do0yLHljlnsUMkLMWer\noh2zi+I6VLYSo13ErWdnZ77fp6enAKTT6fy1lZWVRe/tOjjoDXCfJei8cjBnKxKLmH3lmziZgvwW\np8O5uy+fc3Jy4jtHrhGn1tTUXGnMIljMjhOxiNnXReKom0tfjtmyT+K5bL9//w7AxMQEANPT0wC0\ntbX5xnBj/HVitWDOViQRzna/K79//wa8uHx8fAxAdXU1cB6XNzY2AMhkMgAcHR357jU+Pg7A3t4e\nAIeHh77j8mZIjA+qRK/idHO2IolwtrhHXCaOFheKo8WN+/v79Pf3A/Dz508A7t27B0BDQwMAVVVV\nAHR3dwPQ2dnpG1PGkO1NYM5WRNXZQT2MoA6dGw/LddvU1BTb29sANDY2AvDw4UPAc3J7ezsAT58+\nBQrfmtvAnK2IagWZuxgsaEy3unNjdW1tbcn7S+7c0dHBwcEBALOzswD09vYCcPfuXcDLYCR2S4UZ\nNkYJrIKME4nsjbhIFtLS0gLA7u5u/pjEbnlLpAtYX18P+HPzy/dyHe7qVCS/NmfHiUTk2UFIn0Oq\nwcuOFl68eAHA6OgoAH19fYDX7ZPYLV0/2e8iTnZ7LlfBnK1IomK2uOrXr18ALC0tAdDT0wP4+9sj\nIyMAfPz4EYA7d+4A8ObNGwBevnwJwJ8/fwAvv5aY7hLUI7nkcIvZcSJRMVtcVFdXB8D8/Lxvf2tr\nKwArKyv5zOT169cAPH78GIDBwUHA65E8f/4cCK8c3Vkhi9kxJ5IK8m9mO4rx7ds3AJqbm4HzHrbE\n9x8/fgDQ1dUFwJcvXwD4/PkzAE+ePCl6T8l03OxDYvp18uxIPpA3McVUcpBcLp/SSXhYXl4GvLL9\n1atXALx9+xbwRJWy3RVXtlLeF/kb7AMZJxL1gXQJekOy2WzBB00aUzI9trOzA3jOl7LdLW6Clk1c\nB3O2IpE4+7qx2m0WyW9xo+yXQgU8J05OTvruNTAwABQWMWETuraUISFEMi0Wtlw3aHFjUIbgNonS\n6XQ+a1hYWABgc3MT8CYPpEGliTlbkVg0ooKe4aolshQi4C3kefbsGQBfv34FYGtrC4AHDx6U/dBl\nYnl2nIg0zw5ztHtemLMlZ15cXGR4eBgodLI0q6LAnK1IpM4Oq8qCFvW4Dv/06RMAc3NzALx//z4f\ns+/fvw/A6upq0WvLmMi9MczZisQiG8kfvHiW9fV14HwZGcCjR49853348AEgvyxY8mu5PpPJMDQ0\nBHiTwU1NTb5zwhxs/3SacCJ1dlBMlkWQMikQlrVIFiLLFMbGxvJvg+t66eYFLVn4C8zZcSLSmZqC\ngxf73717B8DMzAwAa2trAPnlCZIzy4J3cakseIfw6tOc/T8nVtnIrQ58xewiaIbG/uk0ISR6DvI2\nuckZGsGcrUginB02w12O626z51Eu5mxF/plsRAHLRuKEdsyOPnBGiDlbERNbERNbERNbERNbERNb\nERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbERNbkf8A8ilQ\nxKRZZ5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc95521c4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA5FJREFUeJztm80rNWEYh6+DFRYoyoIkYaNEiZSIlIWFUiyUP8CGsLCQ\njQVrZWGnJFtL8pGPoqSkWFlY+ciCha+ivAvNnMZbznHeObeZeX/X7sw8nbnn6td9nnnmObGPjw+E\nDRm/XcD/hGQbItmGSLYhkm2IZBsi2YZItiGSbUiW8fWi/LgaSzRAyTZEsg2RbEMk2xDJNkSyDZFs\nQ6zn2YHh8vISgNHRUQDGx8cBaGxsTNs1lWxDIpvs09NTAN7f3z3Hn5+fAejr6wPg+voagP7+fkDJ\njgyRTPbt7S1NTU0AvLy8fDt2eHgYgN7e3rTXpWQbEqlkv729ATA9Pe0muqysDIDCwkIAOjo6ANzk\nt7e3AxCLJVy0+2eUbENixjui0nqx3d1dAFpbW91je3t7ADQ3N3vGOkn28f61nh0kIpFsZ+5cVFTk\nfnZ6tPOkmJ2d7S3E//tWsoNEqGcjr6+vAMzMzADxhAPc3d0BUFFRAcD6+joAnZ2dliV6ULINCXXP\n3t/fB6ClpeWvcwMDAwAsLS0BUFxcDMDV1dVnIerZ0SbUPXthYcHzuaqqCoDt7W13ZjIyMgJAfX09\nAJmZmQCcnJwAUFtba1IrKNmmhLpnPzw8AJCfnw/A/f09AHl5ee6Yp6cnAHp6egDY2NgA4PDwEICG\nhga/yknYs0Mt++vi0Xf3sra2BkBXVxcAQ0NDAMzNzflWTqIBaiOGhPIH8ieJdnDaicPNzY2vNSWD\nkm1IKJPtJDmZBX/nkX5qaspzvLu72//CEqBkGxKqZKfSq7e2tgA4OzsDICcnB4C2tjafq0uMkm1I\nKObZqbzCenx8BOKLVM7j+fn5OQDV1dWplPIdmmcHiVD17GTZ2dlxN984iS4tLQXiLxN+AyXbkEgk\ne3NzE4CVlRUAlpeX3U06JSUlABwcHACQlfV7t6xkGxLI2cjx8TEAs7OzANTV1XnOr66uesZ93Rac\nm5vL4OAgAJOTk0B8m0Ma0WwkSAQy2ZWVlQBcXFwk9aVOH3a2/U5MTFBTU5NKff+Ckh0kApns+fl5\nABYXFwE4OjoCYGxsDIDy8nIgnuSMjM/MFBQU+Fjqj1Gyg0Qgkx1SlOwgIdmGSLYhkm2IZBsi2YZI\ntiHWi7vp/2dngFGyDZFsQyTbEMk2RLINkWxDJNsQyTZEsg2RbEMk2xDJNkSyDZFsQyTbEMk2RLIN\nkWxDJNsQyTZEsg2RbEMk25A/ljL5gAUrMx0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9551ba690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(input_shape))\n",
    "visualize(noisy_data[x_vis].reshape(input_shape))\n",
    "visualize(fgsm_data[x_vis].reshape(input_shape))\n",
    "visualize(bim_data[x_vis].reshape(input_shape))\n",
    "visualize(cw_data[x_vis].reshape(input_shape))\n",
    "visualize(df_data[x_vis].reshape(input_shape))\n",
    "visualize(jsma_data[x_vis].reshape(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,*input_shape))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,*input_shape))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,*input_shape))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,*input_shape))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,*input_shape))\n",
    "df_preds = model.model.predict(df_data.reshape(-1,*input_shape))\n",
    "jsma_preds = model.model.predict(jsma_data.reshape(-1,*input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1\n",
    "\n",
    "df_labels = np.zeros(df_preds.shape)\n",
    "df_labels[np.arange(num_test_samples),np.argmax(df_preds, axis=1)] = 1\n",
    "\n",
    "\n",
    "jsma_labels = np.zeros(jsma_preds.shape)\n",
    "jsma_labels[np.arange(num_test_samples),np.argmax(jsma_preds, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 7\n",
      " 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 7]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 7\n",
      " 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9]\n",
      "[0 9 0 0 0 0 0 0 0 0 1 8 1 1 1 1 1 1 1 1 2 2 7 2 2 2 2 2 2 2 3 3 2 3 3 3 3\n",
      " 3 3 3 4 9 4 4 4 4 4 4 4 4 5 5 5 5 5 3 5 5 3 5 6 6 6 6 6 6 6 6 6 6 7 7 7 9\n",
      " 7 7 7 7 7 7 0 8 8 8 8 8 8 8 8 8 9 9 5 9 9 9 9 4 9 7]\n",
      "[0 9 0 0 0 0 0 0 0 0 1 2 1 1 1 1 1 1 1 2 2 2 7 2 2 8 2 2 2 2 3 3 2 3 3 3 3\n",
      " 3 9 3 9 9 4 4 4 4 4 4 4 4 3 5 5 5 5 3 3 5 3 5 6 6 6 6 6 6 6 6 6 6 7 0 7 9\n",
      " 7 7 2 7 7 7 0 8 8 8 8 8 8 8 8 8 9 9 5 9 9 9 9 4 9 9]\n",
      "[2 9 6 9 5 2 2 6 6 2 3 8 3 7 3 5 8 3 3 8 3 7 7 3 1 8 7 1 0 1 5 5 2 5 8 5 5\n",
      " 9 9 8 9 9 9 7 9 9 9 8 9 9 3 3 3 3 3 3 3 6 3 6 5 5 3 5 0 5 5 5 5 0 3 0 9 3\n",
      " 2 9 3 9 3 8 0 9 9 9 2 3 9 3 9 6 4 4 5 4 7 8 4 4 7 9]\n",
      "[2 9 2 8 5 9 9 6 5 9 8 8 3 9 3 6 8 8 4 8 3 7 7 3 3 3 7 7 3 1 9 9 2 5 8 5 5\n",
      " 8 9 8 9 9 8 2 7 9 7 8 7 9 3 3 3 3 3 3 3 3 3 6 5 0 0 5 0 5 4 0 5 0 0 0 9 9\n",
      " 4 9 2 9 9 8 0 3 9 9 3 3 3 3 9 6 8 4 5 4 5 8 7 4 7 9]\n",
      "[6 3 3 2 8 6 5 2 5 8 0 8 9 9 0 0 6 0 8 7 5 1 8 2 9 8 7 6 0 4 1 8 4 9 4 1 4\n",
      " 0 7 4 0 0 1 8 2 7 7 3 7 9 6 3 7 7 0 0 8 4 4 9 7 4 1 5 0 5 8 8 3 8 9 6 1 5\n",
      " 1 9 3 9 5 5 1 5 3 5 7 3 8 5 4 5 5 8 4 0 4 3 7 3 5 9]\n"
     ]
    }
   ],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))\n",
    "print (np.argmax(df_preds, axis=1))\n",
    "print (np.argmax(jsma_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "grads_df = model.get_gradients_wrt_params(df_data, df_labels)\n",
    "grads_jsma = model.get_gradients_wrt_params(jsma_data, jsma_labels)\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "grads_df_nm = normalize(grads_df)\n",
    "grads_jsma_nm = normalize(grads_jsma)\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in sqrt\n",
      "  import sys\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()\n",
    "grads_df_norms = np.sqrt(np.dot(grads_df, grads_df.T)).diagonal()\n",
    "grads_jsma_norms = np.sqrt(np.dot(grads_jsma, grads_jsma.T)).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)\n",
    "cos_sim_df = np.dot(grads_df_nm, grads_train_nm.T)\n",
    "cos_sim_jsma = np.dot(grads_jsma_nm, grads_train_nm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8400\n",
      "Noisy:  0.8600\n",
      "FGSM:  0.6200\n",
      "BIM:  0.5300\n",
      "CW: 0.0200\n",
      "DF: 0.0300\n",
      "JSMA: 0.0300\n"
     ]
    }
   ],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.75\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_df[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('DF: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_jsma[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('JSMA: %.4f' % ( count/num_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8800\n",
      "Noisy:  0.6500\n",
      "FGSM:  0.0800\n",
      "BIM:  0.0400\n",
      "CW: 0.0000\n",
      "DF: 0.0000\n",
      "JSMA: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Separate using just norm\n",
    "gamma = .05\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_df_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('DF: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_jsma_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('JSMA: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8000\n",
      "Noisy:  0.6200\n",
      "FGSM:  0.0700\n",
      "BIM:  0.0400\n",
      "CW: 0.0000\n",
      "DF: 0.0000\n",
      "JSMA: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Use both\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_df[i]) > eta and grads_df_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('DF: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_jsma[i]) > eta and grads_jsma_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('JSMA: %.4f' % ( count/num_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_l2_distortion(orig, adv):\n",
    "    \"\"\"Get the mean l2 distortion between two orig and adv images\"\"\"\n",
    "    l2_dist = 0.0\n",
    "    for i in range(orig.shape[0]):\n",
    "        l2_dist+= np.linalg.norm(orig[i] - adv[i])\n",
    "    return l2_dist/orig.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11310651422\n",
      "1.86042913556\n",
      "2.78593719177\n",
      "1.64055152766\n",
      "4.85458270788\n"
     ]
    }
   ],
   "source": [
    "print (avg_l2_distortion(reg_data, fgsm_data))\n",
    "print (avg_l2_distortion(reg_data, bim_data))\n",
    "print (avg_l2_distortion(reg_data, cw_data))\n",
    "print (avg_l2_distortion(reg_data, df_data))\n",
    "print (avg_l2_distortion(reg_data, jsma_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
