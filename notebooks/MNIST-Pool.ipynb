{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture state\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.4476 - acc: 0.8573 - val_loss: 0.0973 - val_acc: 0.9730\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1599 - acc: 0.9528 - val_loss: 0.0624 - val_acc: 0.9796\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1216 - acc: 0.9637 - val_loss: 0.0502 - val_acc: 0.9842\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.1000 - acc: 0.9695 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0900 - acc: 0.9734 - val_loss: 0.0405 - val_acc: 0.9868\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0780 - acc: 0.9760 - val_loss: 0.0347 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0700 - acc: 0.9788 - val_loss: 0.0358 - val_acc: 0.9886\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0660 - acc: 0.9799 - val_loss: 0.0306 - val_acc: 0.9894\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0613 - acc: 0.9814 - val_loss: 0.0302 - val_acc: 0.9906\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0563 - acc: 0.9831 - val_loss: 0.0316 - val_acc: 0.9898\n",
      "6042/6042 [==============================] - 0s 14us/step\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'MNIST-Pool'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='mnist_pool')\n",
    "epochs = 10\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 10000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebook/cleverhans/cleverhans/src/cleverhans/cleverhans/utils_keras.py:144: UserWarning: Please update your version to keras >= 2.1.3; support for earlier keras versions will be dropped on 2018-07-22\n",
      "  \"Please update your version to keras >= 2.1.3; \"\n"
     ]
    }
   ],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy')\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM')\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name,dataset='mnist_pool')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDdJREFUeJztm0sotV0Yhi+f87GccpqQw5YywkAYmJiYUIqBksOADBRT\nx6SUkpQRJUbKgKIcSpKBkVCKlCRSRshxQP7R+va3tbH3/v7/+Reea+Y9rdXVvd+etd6H3+vrK4oM\nv/7vCfwkVLYgKlsQlS2IyhZEZQuisgVR2YKobEEChMf7zstVv88u0GQLorIFUdmCqGxBVLYg0tWI\nR5g99v7+fgB6enoAqKurAyA/Px+AyspKAFJSUqSn6BOabEH8hL/UfDiYmcvW1hYAJSUlHz4sISEB\ngI6ODgCqq6sBSE5O5tcv8RxpnW0TViX7+fkZgODgYJfjkZGRAISEhABwe3sLwNPTk9vnNDY20t3d\nDUBSUhIA/v7+vs7ZUzTZNmFVsl9eXgBIT08HIDw8HIC1tTUAEhMTATg4OACgs7MTgPn5+Xef2dTU\nBEBXVxfwnyZdk20TViXbW8w7e2NjA4DJyUkAFhcXeXx8dHvP6OgoAM3NzcC/mnBNtk186WS/x8rK\nCi0tLQCcnp66vaa+vh6AwcFBAOLi4v52WE22TXzLZAPc3d0BMDMzAzgTfHJy4nKdw+EAYHNzE4DY\n2Fhfh9Rk28S3TfZbDg8PAedO4dHRkct5k/Dd3V0AgoKCvB1Ck20TPybZBrOvkpubC8DZ2ZnL+fPz\nc8C50vQCTbZN/LhkGxYWFgCoqakBnKvRtLQ0wLn/EhgY6OkjNdk28WOTbaiqqgJgbm7O5bgP7+5P\nk/0lZJuPCvv7+wDMzs4CcHFxAUBbWxsAmZmZgHNr1hOWl5cBKC8vdzk+NDQEQHt7u6eP0teITVjZ\nyvCWiYkJAFpbW92en56eBqCiouL3396kWwpNtiBWJ9u8q83Hgc8wn8dqa2t/tzfk5eUBEBoa6vae\nnZ2dv52mx2iyBbG6GjGbRwUFBQCsrq4CkJWVBcDNzQ0AY2NjgLN8+/ODQWpqKgBTU1MAFBcXA87F\njLnH/IoMV1dXAERFRXk6Xa1GbMLqZA8MDADQ19cHwPr6OgBFRUVur7+/vwdgeHiY3t5el3NhYWGA\nc5Fi0v820Ybx8XEAGhoaPJ2uJtsmrK5GDKZ5x7QMm8bL+Ph4l+tMbW2afP7k4eEBgOPjY4/GzMnJ\n8W2yH6DJFsTqZJeVlQGwtLQEOBNt9kBMu8Le3h4A29vbAFxfX3s9VmFhoctYERERvk77XTTZglhd\njRhMPR0TE+P1vebdOzIyAkBGRgYA0dHRgLMN2TTPBwT4/GPXasQmvkSyzRxNs6RpoLy8vASc9bjZ\nFXQ4HGRnZwNQWloKIPFvH5psm/gSyf4iaLJtQmULorIFUdmCqGxBVLYgKlsQlS2IyhZEej/701XW\nd0aTLYjKFkRlC6KyBVHZgqhsQVS2ICpbEJUtiMoWRGULorIFUdmCqGxBVLYgKlsQlS2IyhZEZQui\nsgVR2YKobEFUtiD/AL2MQRFfbQAfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a75feb090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABVBJREFUeJztnE9IVU8Uxz9GgmALCXEruFAIDJ6ZJS3c6VrclCBUiFho\ntBMkTMUQwY1kBLowWrUU3KngooW2sCAFI0jaZEWLcGcp+lv4G++90/0z1+i8ic5n85h75987fO+5\nZ2bOeyVHR0coMpwp9gT+JdTYgqixBVFjC6LGFkSNLYgaWxA1tiBqbEHOSg725s2bI4BCoWDKhMsp\n7SL1TDmJcH9ZbV3nkjRmqH5J6qRQZYtSIrw3cgT5VZSlyrh2SYp1UGgqSf0VCgVVtk9I+2wgXZHh\n+1lKdsFuc1oFJ93PgypbEFFlu/rN169fA3D9+nUAmpubAXj+/DkAHz9+BGBxcRGAxsbGX/pyfYqS\n5pYVpbhGRmFU2YKIRiMmzraxVXP//n0ApqamItdv3rwZKT979gyAS5cuAdDT0xP5/H/M2LGyFJy3\njMbZflEUn22wVffq1SsAdnd3gUDJ586dA2B6ehqA3t7eSLv6+noAVldXAejv7+fHjx+xY9pzcV3F\nJpGnvSpbkKLG2ba6rly5AsDCwgIAjx49AsC8Vx4/fgzA2NhYpF/ju8OUlBy70LKyMiDw/2F/njY3\n+3oSeZ4IVbYgXu2NnDY2vn37NgBzc3MA3Llzh6dPn0bqGv8/MjICwJcvXwBoampKHcMeK2UuGo34\nhJdxdqh+5L7rrl9tbe1JBGMwyjb+/ezZ49eVWZXeuHEjtq+ssTTO9pSixtkG11jV1ZeXl5efRDA7\nOzsAzMzMAL+uQj98+ADAixcvgGA/5k+gyhakKHG2Td495jztvn79CsDw8DAQxN9G4UbZSXMyYyat\nEfKgyhakKHG24bQ7cnZ7l30O+56tcBOl2PbIsSbQaMQnvIyzXU9T0shSe1dXFxDsKO7t7QFQXV0N\nQFtbGxCcEjlETKpsn/BS2aH6sfV+5+TbbmN8t42xS4796kxli4Z+NlkvHfO5trYGwIMHDwDo6OgA\n4MyZ4wdzcHAQgJaWFgAqKyudU9rsRY7h8uXLQLAYstslfYc01I0I4sVy3cZWj1HuysoKAJ8+fQKC\nR92UW1tbgSDFIdyXqwsyIaBZ7NTU1KR+Fz0W8xSv0s+S1NLX1wcEyjYk+dtv377x8+dPAL5//x7p\n02ZgYACAiYmJ2D5dU+NcUGULUtTQzzXB0oRnJnnHHAyb7dNr164BcPXq1V/GHBoaAgKF37p1C4CG\nhgYAuru7ATg4OIi0M0dsMd8hdu7oosYvinrga0h6k7979w6AyclJgJND3M3Nzdh2S0tLwLGPf//+\nfeTe3bt3AaiqqgKCLVd7I8qUx8fHAfj8+XPqXDUZ3lO8SGVI8oMXLlwAYGtrC4CHDx8Cxwe6AJ2d\nnZH2htHRUSoqKlInEpfYE2Z/fx+AjY2N2Pvqsz2nqIcHhiQffnh4CMCTJ08AuHfvXqTe+vo6AG/f\nvgWCSCOM7ZOzrrvaI2bOqmyf8CrOTmJ+fh6A9vb21HpxK0rj37e3twG4ePEiEBwSnD9/HoDS0lIg\niOHzrhBV2Z7hxeGBISvNbHl5GQjUavavzQ+aXr58CRzvEtbV1QEwOztrz8FprKT69vVQO1W2T3ix\ngjS4/nTPZQXqmhD0O39CYKHK9om/Kv3Mrm+nhqXVSSq7JnPaY5zmh0+qbEG8WkHmVXia787re/Om\nvMX0pz7bJ7xIrPzdCMEmTeFZEU3eP4PR/WxP8cpnJ+Ga3ZRW77R/X6Qpw38p0sr+p1FlC6LGFkSN\nLYgaWxA1tiBqbEHU2IKosQVRYwuixhZEjS2IGlsQNbYgamxB1NiCqLEFUWMLosYWRI0tiBpbEDW2\nIGpsQdTYgvwHtP/1rLx3hvIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f591c6c7b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABJVJREFUeJztnMsrdVEUwH++PCZKCZMrBooYqGsgpchzQkZmHiExwIAy\nwUSGShkpj0hMlULiLzAyEmUij0zuhCgy8A10vuse59xzz72ss/Wt34Tz3Nvqt9ddZ+97pL2/v6PI\n8CfoDvxPaLAF0WALosEWRIMtiAZbEA22IBpsQTTYgqRLNnZ6ehr3cTUcDlvnpdyW/V7W9g+S5nWC\nmi2IqNl2/Nrmdr7TSLDvs2/b7+U2mr5zRKjZggRqthuJ5u5Ucnui13qNCD+o2YKkSc5n26sRL0tK\nS0sBuLy8BODg4ACAiooKAIqLi637fm9HffDpb9BqxCQCMdvL6Le3NwCGhobinpefnw/A8PAwACUl\nJZ/bijk30erDL2q2oRhpdlrahyR9fX0AZGdnA5CVlQXA8/MzAC8vL47X9/T00NjYmHqH8R4Barah\nGGX2yckJADU1NTH73fpoHwFO9Pb2AtDQ0ODWJz73yW0uJYEnTDXbJETNBhwbS7QysNv38PAAwObm\nJgDr6+tfrrFbPzs7C0BRUZFjG26me/UJNdssAjE70byY7DzEwMCAo+WfOT4+BqC5uTluH+y4GR8O\nh9Vskwh0bsQLr7wZx7J/v7e2tgJRk+3Mzc0BMDMz43jcx+eJmm0SRpvtRjJrlYeHhwBMTU3FPc8e\nj0RHlZptGL/SbDtOVYubkff39wC0tbU5Hk/UbIe21WyTMGJ1PdW55XjViN16a7u7uxuAra2tmOPW\nfIvd8O9YZVezBTFiDfIn1xC9vmtSVVXleHxtbc3x+jiGe+bsQNKI3yH5+voKwN7eHhCdeLq9vQWi\n5Vx9fT0AeXl5X+5hnyKwfj49PQEwOjoKwMbGBgBLS0sALC8vJ9VnJzSNCCJqdrJ2FBYWAnB3dwdA\nU1NTzHFrfyQSAaClpcX1XvaUZX1dwjL6J1GzBTHi62deE0o7OzsJ3efo6Aj4KNs6OzsByMzMjNvG\nzc1Nkr32j5otiJHLYvbcPjIyAsDi4iIA6ekfA3JhYQGA2tpaAPb394FYW63lr+npaQDOzs4A95LP\nYnd3F4COjg7HPtrRiSjDCDRne9lycXEBROts+yicmJiI2X58fAQgFAoxPz8PwPX1NQDj4+MAFBQU\nADA4OAjA6uoq8HVhuLq6Omb7Ox7A1GxBAs3ZXpZ0dXUBcH5+HrN/e3sbgPLy8pj9ln2RSITJycmU\nOrqysgJEPx/c0MUDQzGqzrawbGlvbwe+mm0ZHwqFgOgTpJXDrSrlM/G+ogbR6mRsbMxP132hZgti\nRJ2dKP39/THbfuYzrOqjsrISiL4ikpubC0BGRgYQfeK08JrP0ZxtKEZUI35nA+vq6oDok+LV1RUA\nOTk5wIe9ZWVlQPRVEa+qIll0wddQjMrZQb5iZ5Hsi06asw3DiDrbiyAXhr+zbTVbECPM9vuah+Q9\n9R8F/FKMqkaCIIUXluxoNWISv8Lsn8jpP4CabRLSZv/XqNmCaLAF0WALosEWRIMtiAZbEA22IBps\nQTTYgmiwBdFgC6LBFkSDLYgGWxANtiAabEE02IJosAXRYAuiwRZEgy2IBlsQDbYgfwHLX+RMssuF\nXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a74e8e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a74e19490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDhJREFUeJztm8srvG0Yxz/jLOeUBTlkQUkSKSSWskBZ2ZGNHFaysJI/\nADtlY2Fhxx8g5S8YEgtyiIVSkpzPh3cx7+VpNF7Db37Xew/XZzPNzN393PPtO9dz3fd1Pb7X11cM\nHWL+7wX8JkxsRUxsRUxsRUxsRUxsRUxsRUxsRUxsReKUr/eTt6u+zwaYsxUxsRUxsRUxsRUxsRXR\nzka+RGlpKQDb29sADA8PA1BQUABAe3t70HvXMWcr4lOu1IR1sbu7OwBSU1MBSE9PByArKwuA2NhY\nAPLy8gDo6OgAoLOzE4CMjAwSEhIiteZwsTzbJZx0ts8XMEl8fDwAtbW1ANTX1wOQmJgIwNzcHAD5\n+flB4+vq6ujt7QUgJycHgLi4v357Mme7hNPOlteXl5fgSf5dc2trKwAnJycAnJ+fA4EYf3NzA3gZ\ny9DQEODFfZk7gpizXcJJZ4fLxcUFAPPz8wDMzMwA4Pf73+J3cXExAIeHhwBMTk4C0N3dHcmlgDnb\nLaLa2R+xtLREc3MzANnZ2QCcnp4CXvzv7+8HYGpqKlKXNWe7xI90NsD9/T0AaWlpADw+PoYcJ/n3\nw8MD8EdZijnbJX6ss9+ztrYGQE1NDQBPT08hx/2BHuZsl/g1zhbE0XK+8n53ur+/D0BRUdFXpzZn\nu8Svc7awubkJQFlZWcjvb29vAUhKSgp3SnO2S/xaZwt9fX0ATE9PB32+sbEBQHl5ebhTfersqBB7\nfX0d8IoIo6OjAExMTABemWx3dxfwymnhIDdIKb1dX18DUFhYCMDBwUG4U1kYcQmnWxkEuYnJzUo2\nKCMjIwBsbW0BkJyc/OW5V1ZWAM/RwsDAwPcW+x+YsxWJCmfLoZJwdHQEeM07DQ0NgFc86OnpeYvj\nnx0sLS4uhvx8dXX1+wv+AHO2Ik5nI7I2OSaV9rOmpibA21Lv7e0BMD4+DsDx8fGbsxcWFgCv3UGc\nLnNeXV2FvLYUG6RAHAaWjbiE086WQyEp2kpL2fsYLpydnQGB/FsKu9Kkc3l5GTTm+fk55Bzyj/D7\n/QBUVlaGu1xztks4nY3ILk6Q0pXkxtXV1UHfZ2ZmAoE4LE060sIgsVpycTloiokJ+E1ieElJCQAV\nFRUR/CUBzNmKOB2zZW1VVVWAt3MUpBGnq6sLgOXlZSCQjXyUZQhS6JV/Q0tLCwCzs7PAtwq/FrNd\nwmlnCzs7O4AXT7+COFRa1OTRkdzcXMArj4kOKSkp31kimLPdIiqcLY99yNnz2NgY4LlV8nGJw4OD\ng7S1tQHQ2NgIePnzX8Sc7RJR4ewowZztEia2Iia2Iia2Iia2Iia2Iia2Iia2Iia2ItqVmog/wxxN\nmLMVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEVMbEV\nMbEVMbEVMbEVMbEV+Qdd4Uiw58ZrsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5a74daced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(28,28,1))\n",
    "visualize(noisy_data[x_vis].reshape(28,28,1))\n",
    "visualize(fgsm_data[x_vis].reshape(28,28,1))\n",
    "visualize(bim_data[x_vis].reshape(28,28,1))\n",
    "visualize(cw_data[x_vis].reshape(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,28,28,1))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,28,28,1))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,28,28,1))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,28,28,1))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 7 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 1 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 0 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 3 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 8 8 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 1 8 8 8 1 8 8 8 8 8 1\n",
      " 1 8 8 1 1 8 1 1 8 8 8 8 8 8 8 1 8 2 8 2 1 8 8 1 8 8 8 8 8 8 2 8 8 8 8 8 1\n",
      " 8 1 8 8 8 8 8 1 8 8 8 8 1 8 8 8 8 8 8 1 8 8 1 3 1 1 8 8 8 8 8 1 1 1 8 2 8\n",
      " 8 8 8 8 8 8 8 8 8 2 8 2 8 1 1 2 2 2 2 2 2 2 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 2 2 2 2 2 2 2 8 2 2 2\n",
      " 8 2 2 2 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 8 8 8 4 4 8 4 8\n",
      " 8 8 4 4 4 4 4 8 4 8 4 4 4 4 4 4 4 2 4 4 4 8 4 4 4 4 8 4 4 4 4 4 4 4 4 2 4\n",
      " 4 4 4 4 4 4 8 4 4 4 4 4 8 4 4 4 4 4 4 4 4 4 8 4 4 4 4 8 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 8 5 8 5 5 5 8 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 8 5 5 5 5 5 8 5 5 5 5 5 5 3 5 5 5 5 3 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 8 8 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 8 5 5 5 5 5 6 6 8 6 6 6 6 6 6 8 6 6 6 8 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 8 6 6 6 8 6 6 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6 6 6 8 6 6 6 6 6 6 6 8 6 7 7 7\n",
      " 8 3 7 3 7 7 7 7 2 7 7 8 8 7 7 3 7 7 3 7 7 7 7 7 7 8 7 7 7 7 7 7 7 8 7 7 8\n",
      " 7 7 9 7 2 7 7 7 8 3 7 7 8 7 8 7 7 2 7 7 7 7 7 2 2 7 8 7 7 7 7 2 8 8 7 7 2\n",
      " 7 7 8 3 7 7 8 8 7 7 7 7 7 7 7 7 7 7 7 8 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 9 8 9 8 9 0 9 9 9 9 8 9 9 9 8 9 9 8 9 9 9 9 9 9\n",
      " 8 9 9 9 9 9 9 9 9 9 8 9 9 9 8 8 8 8 9 9 9 9 8 4 9 8 8 8 8 9 9 9 9 9 9 8 9\n",
      " 9 9 8 9 9 9 9 9 9 9 8 9 9 8 9 8 9 9 8 9 9 9 9 8 9 9 8 9 9 8 9 8 9 9 9 9 8\n",
      " 9]\n",
      "[0 9 2 8 8 8 2 6 5 8 8 8 8 8 0 0 8 8 8 3 8 8 6 8 8 0 3 8 8 3 5 8 8 8 8 9 8\n",
      " 8 7 2 0 2 8 8 6 8 8 8 8 8 8 2 3 2 8 8 8 6 0 2 6 2 8 6 8 9 5 8 6 5 8 8 0 8\n",
      " 0 9 5 8 8 8 8 8 8 5 6 2 8 0 8 5 8 8 0 2 6 6 8 8 2 8 2 8 8 8 8 8 3 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 3 8 8 8 8 8 8 8 3 8 8 8 2 8\n",
      " 8 8 8 8 8 8 8 8 3 8 8 2 8 8 8 8 8 8 8 8 8 3 8 4 3 8 8 7 3 8 3 8 8 2 8 8 7\n",
      " 8 8 8 7 8 8 0 3 3 8 8 8 3 8 3 7 8 7 8 8 8 8 8 8 8 8 8 8 8 3 2 0 3 8 3 8 3\n",
      " 0 8 7 3 8 8 3 8 2 8 2 8 8 3 3 3 3 3 8 3 3 3 2 8 8 8 3 8 8 8 8 8 5 8 8 0 0\n",
      " 8 8 8 8 2 8 5 8 8 2 8 5 8 8 5 8 8 5 5 5 8 5 8 5 8 5 5 8 8 8 8 9 5 8 2 8 7\n",
      " 8 5 8 8 8 8 8 5 8 3 5 8 8 2 8 8 5 8 8 8 8 5 8 5 5 8 8 5 2 5 8 3 8 8 8 3 8\n",
      " 5 2 5 5 8 2 5 8 2 3 8 8 8 5 3 3 3 8 0 8 8 5 8 8 5 8 8 3 5 8 8 8 9 8 8 9 8\n",
      " 8 8 9 9 3 9 9 8 8 3 5 8 8 2 8 8 8 2 9 2 8 9 7 8 8 9 8 8 8 9 8 8 8 8 2 2 8\n",
      " 8 3 8 9 9 8 8 8 8 2 8 8 8 8 3 8 9 8 7 8 8 8 8 2 8 2 8 8 3 8 8 9 9 8 9 8 2\n",
      " 8 8 8 8 8 8 9 8 4 8 8 8 8 8 8 7 8 8 8 6 3 3 5 9 9 8 3 9 3 3 3 8 8 9 3 8 8\n",
      " 8 3 8 8 3 9 3 3 6 3 8 9 9 3 3 3 3 8 8 3 3 3 3 8 8 9 3 7 3 9 8 8 9 8 8 3 5\n",
      " 8 8 9 9 3 9 3 3 8 3 2 3 3 3 8 3 3 8 8 2 8 9 3 8 8 3 8 9 8 8 8 3 8 3 6 3 7\n",
      " 8 9 8 3 6 3 3 8 5 2 5 8 8 8 8 8 8 8 8 8 8 8 5 8 9 8 8 8 8 5 8 2 5 8 2 4 8\n",
      " 8 8 8 2 4 4 8 8 0 5 8 8 8 8 8 8 2 8 0 2 2 8 8 8 3 8 5 8 9 5 9 0 9 8 8 8 5\n",
      " 8 8 5 5 5 8 8 8 8 8 8 8 2 8 5 8 8 5 5 4 8 5 8 8 5 9 8 5 8 8 8 8 8 8 8 8 2\n",
      " 8 3 8 3 8 8 8 8 8 8 8 8 2 8 8 8 9 8 3 8 8 8 8 8 8 8 9 8 8 9 8 2 8 8 8 8 8\n",
      " 8 8 9 9 8 8 8 8 8 8 8 2 8 3 8 2 8 2 8 8 8 2 8 2 8 8 8 8 8 8 8 8 8 8 8 8 2\n",
      " 8 8 8 8 8 8 8 8 8 8 8 9 8 8 3 8 8 8 8 2 8 8 8 3 5 2 3 3 8 5 5 2 3 8 8 6 8\n",
      " 8 0 8 8 0 9 6 5 2 2 3 8 0 8 8 2 8 2 3 3 8 8 2 5 3 9 2 2 3 8 5 7 8 3 8 6 3\n",
      " 8 8 5 3 2 8 3 8 5 5 3 8 2 8 8 8 5 2 8 3 3 8 8 2 2 8 3 2 3 8 6 3 3 3 8 5 8\n",
      " 3 2 3 5 8 8 8 2 9 8 3 8 7 4 2 8 8 8 0 4 3 8 2 8 4 8 8 8 8 8 8 8 4 8 8 3 8\n",
      " 8 8 8 4 5 8 8 8 8 8 8 4 8 4 4 8 8 3 8 8 8 8 8 4 8 8 8 8 8 2 8 8 8 4 8 8 8\n",
      " 8 8 8 8 4 8 8 8 8 3 8 4 8 3 3 8 8 8 3 8 8 8 8 4 0 8 8 5 8 4 8 6 0 8 8 5 8\n",
      " 8]\n",
      "[2 9 2 8 9 8 2 6 5 5 8 8 5 8 3 8 8 8 8 3 8 3 6 8 8 6 3 8 8 3 9 8 8 8 8 9 3\n",
      " 8 7 2 9 2 9 8 6 8 8 6 8 5 2 2 3 2 6 8 8 6 5 2 6 2 3 6 3 9 5 8 6 5 8 8 9 8\n",
      " 8 9 5 2 8 8 8 3 5 5 6 2 8 6 3 5 5 8 8 6 6 6 6 8 3 2 2 8 8 8 3 2 8 4 2 8 8\n",
      " 8 8 2 8 8 2 8 8 8 8 8 4 3 8 8 3 3 2 3 8 8 8 8 3 8 3 8 8 8 2 2 2 8 8 8 3 8\n",
      " 2 3 8 8 8 8 8 8 8 4 8 8 8 8 2 2 8 8 8 3 8 2 8 3 8 8 6 8 2 8 8 3 8 8 8 3 8\n",
      " 2 8 2 2 2 8 2 8 8 8 8 3 8 8 8 8 8 8 8 3 8 3 2 4 3 3 1 7 3 8 3 8 8 0 8 8 7\n",
      " 8 8 8 7 1 8 0 7 3 8 3 3 3 8 3 7 3 7 8 8 3 8 8 8 8 8 8 8 8 3 3 0 7 8 7 0 3\n",
      " 0 3 7 3 8 8 8 8 8 8 8 8 8 3 3 3 8 3 8 3 3 3 8 8 8 3 3 8 8 8 8 4 4 2 3 0 0\n",
      " 8 8 3 8 2 8 5 8 8 2 8 5 8 8 5 9 8 5 5 5 9 5 8 5 8 5 5 8 5 8 8 9 5 8 2 8 4\n",
      " 8 5 9 8 8 5 5 5 8 5 5 8 8 2 8 5 5 5 9 8 8 5 8 5 5 9 4 5 7 9 8 8 8 8 8 8 8\n",
      " 5 2 5 5 8 7 5 8 2 5 8 8 8 5 5 8 2 5 0 3 8 5 8 8 5 8 8 8 5 8 8 8 9 9 9 9 8\n",
      " 8 8 9 9 3 9 9 9 9 9 9 8 8 2 8 2 8 2 9 9 8 9 7 8 9 9 9 9 9 9 3 9 8 9 7 2 9\n",
      " 9 9 9 9 9 9 8 9 2 9 8 8 8 9 3 8 9 8 8 9 9 9 8 2 8 2 3 8 2 3 2 9 9 8 9 8 2\n",
      " 9 8 9 8 9 5 9 9 8 8 8 8 8 8 9 7 9 9 8 6 3 3 3 9 9 0 3 9 3 3 3 8 8 9 3 8 8\n",
      " 8 3 8 8 3 9 3 3 6 3 8 9 3 3 3 3 3 8 8 3 3 8 3 3 8 9 3 5 3 9 8 9 9 8 8 3 3\n",
      " 2 8 9 9 3 9 3 3 8 3 2 3 3 3 8 3 3 8 8 2 3 9 3 8 8 3 8 9 8 8 8 3 3 3 6 3 3\n",
      " 8 9 8 3 6 3 3 8 5 2 3 0 3 0 8 8 8 8 8 8 8 8 5 8 9 8 8 8 8 5 4 2 5 3 0 4 8\n",
      " 3 8 3 2 4 4 3 8 0 5 8 3 8 8 8 3 4 8 9 0 0 8 4 8 9 8 5 3 9 5 9 0 4 8 8 8 5\n",
      " 8 4 5 5 3 8 3 8 3 8 8 8 4 8 5 0 8 5 5 4 8 5 8 5 5 4 3 5 8 2 8 8 8 5 9 3 2\n",
      " 8 3 8 3 3 8 8 3 2 9 8 8 2 9 8 8 9 8 3 3 8 3 9 9 8 9 9 9 9 9 8 2 8 2 8 3 8\n",
      " 3 3 9 9 2 8 0 8 8 3 9 2 8 3 8 2 3 2 8 3 8 2 8 2 2 3 8 9 3 3 4 6 8 8 2 3 2\n",
      " 1 3 8 3 8 3 1 8 3 9 9 9 8 9 3 8 2 9 2 2 3 0 3 3 5 2 3 3 2 5 6 2 3 3 0 6 3\n",
      " 5 0 3 6 0 9 6 5 3 2 3 2 0 3 3 2 2 2 3 3 3 3 2 5 3 9 2 2 3 3 9 7 3 3 0 6 3\n",
      " 2 0 5 3 8 2 3 9 5 5 3 2 2 3 1 3 5 2 5 3 3 3 5 2 2 2 3 3 3 5 6 3 0 3 3 5 3\n",
      " 3 2 3 5 2 4 9 2 9 5 3 5 7 4 2 8 8 4 9 4 3 4 2 8 4 8 8 8 5 8 8 4 4 8 8 3 8\n",
      " 8 8 8 4 5 8 4 4 4 8 8 4 8 4 4 8 8 3 8 8 7 8 8 4 7 4 8 8 8 4 8 8 8 4 4 8 8\n",
      " 2 8 4 8 4 8 4 8 2 3 4 4 8 5 3 8 8 8 3 4 7 8 4 4 0 8 8 5 7 4 3 6 0 2 5 5 8\n",
      " 8]\n",
      "[2 9 2 8 5 9 2 6 8 2 6 9 2 8 2 2 2 2 2 2 2 2 6 8 2 2 6 2 9 2 5 6 8 3 9 6 2\n",
      " 2 7 2 5 2 6 2 6 2 8 2 2 6 2 2 2 2 6 2 6 6 5 2 6 2 3 6 2 9 5 2 6 5 8 6 6 2\n",
      " 2 9 5 2 9 2 2 2 6 5 6 2 8 2 2 2 5 6 2 2 6 6 6 2 2 2 2 8 8 6 3 2 3 4 2 8 8\n",
      " 8 8 8 3 3 3 3 3 3 8 8 4 3 8 8 3 3 3 3 8 8 4 8 3 8 3 8 5 2 3 2 2 8 3 4 3 8\n",
      " 3 8 3 3 8 8 8 3 5 4 8 8 8 8 4 3 8 8 8 3 8 3 4 3 3 3 6 8 2 8 8 3 5 4 8 1 8\n",
      " 8 8 3 2 8 8 2 3 2 8 3 1 5 3 2 4 1 8 3 7 8 3 2 4 3 3 1 7 3 7 3 8 8 0 8 3 7\n",
      " 3 8 8 7 1 3 0 7 3 3 3 3 3 3 3 7 3 7 8 8 1 8 8 0 3 3 8 3 7 3 1 0 7 8 3 0 3\n",
      " 0 3 7 3 3 8 3 1 3 3 1 3 1 3 3 3 3 3 3 3 3 0 7 8 1 3 3 3 3 8 3 1 3 2 3 0 0\n",
      " 8 3 3 7 2 7 5 5 5 2 2 5 8 8 5 5 8 5 5 5 9 5 2 5 2 5 5 2 5 5 2 9 5 8 2 8 5\n",
      " 5 5 5 8 8 5 5 5 5 5 5 5 8 2 2 5 5 5 5 5 2 5 2 5 5 5 7 5 7 5 8 5 8 2 5 5 8\n",
      " 5 2 5 5 7 7 5 5 2 5 2 5 8 5 5 2 2 5 5 3 2 5 2 5 5 2 5 5 5 8 8 8 9 9 9 9 6\n",
      " 8 9 9 9 9 9 9 9 9 9 9 1 9 7 8 2 9 2 9 9 8 9 7 9 9 9 9 9 9 9 9 9 1 9 7 2 9\n",
      " 9 9 9 9 9 9 9 9 1 9 6 9 9 9 9 3 9 9 7 9 9 9 6 9 8 7 7 8 9 9 7 9 9 7 9 1 7\n",
      " 9 6 9 9 9 9 9 9 8 8 7 8 9 9 9 7 9 9 2 6 3 3 9 9 9 8 3 9 3 9 3 6 6 9 3 6 3\n",
      " 6 9 6 3 3 9 3 3 6 3 3 9 9 3 3 3 3 8 9 3 3 3 3 3 8 9 3 5 3 9 8 9 9 3 8 3 9\n",
      " 6 8 9 9 3 9 3 3 9 3 3 3 3 3 3 3 3 3 8 3 9 9 3 9 8 3 3 9 6 8 3 3 3 3 6 3 9\n",
      " 8 9 6 3 6 3 3 8 5 2 5 0 4 0 5 8 8 8 8 5 5 6 5 5 4 0 8 8 8 5 4 2 5 5 2 2 5\n",
      " 8 0 0 2 4 4 5 5 0 5 0 5 8 5 2 5 4 0 4 0 0 3 4 8 4 8 5 3 4 5 5 0 4 5 8 5 5\n",
      " 8 4 5 5 5 5 5 8 5 8 5 5 4 8 5 0 5 5 5 4 5 5 2 5 5 4 5 5 8 4 8 5 8 5 2 9 2\n",
      " 3 3 2 3 3 9 2 3 2 9 4 8 2 9 2 3 9 9 3 2 2 3 9 9 9 9 9 9 9 9 3 2 3 2 2 3 2\n",
      " 3 3 9 9 2 3 9 9 3 3 3 2 2 3 2 2 3 2 3 9 9 2 3 2 2 3 9 9 3 3 9 4 2 2 2 3 2\n",
      " 1 3 3 9 9 3 1 2 3 3 9 9 3 9 3 3 3 9 2 2 3 2 3 2 5 2 3 2 2 5 6 2 3 3 9 6 2\n",
      " 2 2 2 6 0 9 6 5 2 2 3 3 0 3 3 2 3 2 3 2 2 3 2 5 2 9 2 2 3 9 9 9 2 3 2 6 3\n",
      " 2 9 2 3 8 2 3 9 5 6 3 2 3 3 2 2 5 2 5 3 3 9 5 2 2 2 3 3 3 5 6 3 0 3 2 5 2\n",
      " 9 2 3 6 2 3 9 2 9 2 2 5 7 4 4 4 8 4 9 4 7 4 4 8 4 3 4 8 5 4 8 4 4 8 4 7 4\n",
      " 8 4 8 4 5 4 4 4 4 4 8 4 3 4 4 8 5 3 8 4 7 5 4 4 7 4 8 8 8 4 8 8 8 4 4 8 8\n",
      " 7 4 4 4 4 7 4 8 4 3 7 4 4 9 3 8 7 4 3 4 7 4 4 4 0 8 4 5 7 4 4 4 0 4 5 5 8\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "\n",
    "\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8590\n",
      "Noisy:  0.3900\n",
      "FGSM:  0.2400\n",
      "BIM:  0.4230\n",
      "CW: 0.0810\n"
     ]
    }
   ],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.81\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8640\n",
      "Noisy:  0.1280\n",
      "FGSM:  0.0170\n",
      "BIM:  0.3850\n",
      "CW: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Separate using just norm\n",
    "gamma = 0.15\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.7960\n",
      "Noisy:  0.0970\n",
      "FGSM:  0.0100\n",
      "BIM:  0.2540\n",
      "CW: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Use both\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Create training data with first 450 points of each class, with first 50 scores\\nx = np.zeros((6000, 4))\\ny = np.zeros((6000, 1))\\n\\nfor i in range(1000):\\n        reg_dis = cos_sim_reg[i][np.where( train_data_1k_labels_int == np.argmax(reg_preds[i]))[0]]\\n        noisy_dis = cos_sim_noisy[i][np.where( train_data_1k_labels_int == np.argmax(noisy_preds[i]))[0]]\\n        fgsm_dis = cos_sim_fgsm[i][np.where( train_data_1k_labels_int == np.argmax(fgsm_preds[i]))[0]]\\n        bim_dis = cos_sim_bim[i][np.where( train_data_1k_labels_int == np.argmax(bim_preds[i]))[0]]\\n        cw_dis = cos_sim_cw[i][np.where( train_data_1k_labels_int == np.argmax(cw_preds[i]))[0]]\\n        mod_cw_dis = cos_sim_mod_cw[i][np.where( train_data_1k_labels_int == np.argmax(mod_cw_preds[i]))[0]]\\n        x[i*6] = np.array([np.median(reg_dis), np.max(reg_dis), np.min(reg_dis), np.var(reg_dis)])\\n        y[i*6] = 0\\n        x[i*6 + 1] = np.array([np.median(noisy_dis), np.max(noisy_dis), np.min(noisy_dis), np.var(noisy_dis)])\\n        y[i*6 + 1] = 0\\n        x[i*6 + 2] = np.array([np.median(fgsm_dis), np.max(fgsm_dis), np.min(fgsm_dis), np.var(fgsm_dis)])\\n        y[i*6 + 2] = 1\\n        x[i*6+3] = np.array([np.median(bim_dis), np.max(bim_dis), np.min(bim_dis), np.var(bim_dis)])\\n        y[i*6+3] = 1\\n        x[i*6+4] = np.array([np.median(cw_dis), np.max(cw_dis), np.min(cw_dis), np.var(cw_dis)])\\n        y[i*6+4] = 1\\n        x[i*6+5] = np.array([np.median(mod_cw_dis), np.max(mod_cw_dis), np.min(mod_cw_dis), np.var(mod_cw_dis)])\\n        y[i*6+5] = 1\\nx_train = x[:5700]\\ny_train = y[:5700]\\nx_test = x[5700:]\\ny_test = y[5700:]\\nfrom sklearn.linear_model import LogisticRegression\\nclf = LogisticRegression(solver='newton-cg', max_iter=10000).fit(x_train, y_train)\\n\\n#Plot ROC \\npreds = clf.predict_proba(x_test)\\npreds_bad = preds[:,1]\\nfrom sklearn import metrics \\nfpr, tpr, thresholds = metrics.roc_curve(y_test, preds_bad, pos_label=1)\\nplt.plot(fpr,tpr)\\nplt.xlabel('FPR')\\nplt.ylabel('TPR')\\nplt.show() \\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Create training data with first 450 points of each class, with first 50 scores\n",
    "x = np.zeros((6000, 4))\n",
    "y = np.zeros((6000, 1))\n",
    "\n",
    "for i in range(1000):\n",
    "        reg_dis = cos_sim_reg[i][np.where( train_data_1k_labels_int == np.argmax(reg_preds[i]))[0]]\n",
    "        noisy_dis = cos_sim_noisy[i][np.where( train_data_1k_labels_int == np.argmax(noisy_preds[i]))[0]]\n",
    "        fgsm_dis = cos_sim_fgsm[i][np.where( train_data_1k_labels_int == np.argmax(fgsm_preds[i]))[0]]\n",
    "        bim_dis = cos_sim_bim[i][np.where( train_data_1k_labels_int == np.argmax(bim_preds[i]))[0]]\n",
    "        cw_dis = cos_sim_cw[i][np.where( train_data_1k_labels_int == np.argmax(cw_preds[i]))[0]]\n",
    "        mod_cw_dis = cos_sim_mod_cw[i][np.where( train_data_1k_labels_int == np.argmax(mod_cw_preds[i]))[0]]\n",
    "        x[i*6] = np.array([np.median(reg_dis), np.max(reg_dis), np.min(reg_dis), np.var(reg_dis)])\n",
    "        y[i*6] = 0\n",
    "        x[i*6 + 1] = np.array([np.median(noisy_dis), np.max(noisy_dis), np.min(noisy_dis), np.var(noisy_dis)])\n",
    "        y[i*6 + 1] = 0\n",
    "        x[i*6 + 2] = np.array([np.median(fgsm_dis), np.max(fgsm_dis), np.min(fgsm_dis), np.var(fgsm_dis)])\n",
    "        y[i*6 + 2] = 1\n",
    "        x[i*6+3] = np.array([np.median(bim_dis), np.max(bim_dis), np.min(bim_dis), np.var(bim_dis)])\n",
    "        y[i*6+3] = 1\n",
    "        x[i*6+4] = np.array([np.median(cw_dis), np.max(cw_dis), np.min(cw_dis), np.var(cw_dis)])\n",
    "        y[i*6+4] = 1\n",
    "        x[i*6+5] = np.array([np.median(mod_cw_dis), np.max(mod_cw_dis), np.min(mod_cw_dis), np.var(mod_cw_dis)])\n",
    "        y[i*6+5] = 1\n",
    "x_train = x[:5700]\n",
    "y_train = y[:5700]\n",
    "x_test = x[5700:]\n",
    "y_test = y[5700:]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='newton-cg', max_iter=10000).fit(x_train, y_train)\n",
    "\n",
    "#Plot ROC \n",
    "preds = clf.predict_proba(x_test)\n",
    "preds_bad = preds[:,1]\n",
    "from sklearn import metrics \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, preds_bad, pos_label=1)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show() \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
