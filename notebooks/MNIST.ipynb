{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os, gc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "from models.util import *\n",
    "\n",
    "\n",
    "#Seed used for choosing classes, training points, and test points.\n",
    "SEED = 14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define params of model\n",
    "input_shape = (28,28,1)\n",
    "num_classes = 10\n",
    "eps=0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Params: 3330314\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'MNIST'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "print ('Total Model Params: %d' % model.num_params)\n",
    "model.load_model(model_save_path, weights_save_path) \n",
    "#epochs = 50\n",
    "#model.train(epochs=epochs)\n",
    "#model.save_model(model_save_path, weights_save_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6055/6055 [==============================] - 1s 222us/step\n",
      "Model Accuracy: 0.99306\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy\n",
    "print ('Model Accuracy: %.5f' % (model.model.evaluate(model.test_data, model.test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 1000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebook/cleverhans/cleverhans/src/cleverhans/cleverhans/utils_keras.py:144: UserWarning: Please update your version to keras >= 2.1.3; support for earlier keras versions will be dropped on 2018-07-22\n",
      "  \"Please update your version to keras >= 2.1.3; \"\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = num_classes*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM', eps=eps)\n",
    "bim_a_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM-A', iterations=10, eps=eps)\n",
    "bim_b_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM-B', iterations=10, eps=eps)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False, eps=eps)\n",
    "df_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='DF', nb_candidate=num_classes)\n",
    "jsma_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='JSMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fgsm_guides = model.model.predict(fgsm_data.reshape(-1,*input_shape))\n",
    "bim_a_guides = model.model.predict(bim_a_data.reshape(-1,*input_shape))\n",
    "bim_b_guides = model.model.predict(bim_a_data.reshape(-1,*input_shape))\n",
    "\n",
    "#Whitebox CW Attack\n",
    "#First get guide images\n",
    "guide_indices_fgsm = list()\n",
    "guide_indices_bim_a = list()\n",
    "guide_indices_bim_b = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images for modified CW attacks\n",
    "for i in range(num_test_samples):\n",
    "    label_fgsm = np.argmax(fgsm_guides[i])\n",
    "    label_bim_a = np.argmax(bim_a_guides[i])\n",
    "    label_bim_b = np.argmax(bim_b_guides[i])\n",
    "   \n",
    "    #Get a test point with the target label\n",
    "    guide_imgs_indices_fgsm = np.where(model.train_labels[:,label_fgsm] == 1)[0]\n",
    "    guide_imgs_indices_bim_a = np.where(model.train_labels[:,label_bim_a] == 1)[0]\n",
    "    guide_imgs_indices_bim_b = np.where(model.train_labels[:,label_bim_b] == 1)[0]\n",
    "    #Choose a guide image\n",
    "    guide_img_idx_fgsm = np.random.choice(guide_imgs_indices_fgsm, 1)[0]\n",
    "    guide_img_idx_bim_a = np.random.choice(guide_imgs_indices_bim_a, 1)[0]\n",
    "    guide_img_idx_bim_b = np.random.choice(guide_imgs_indices_bim_b, 1)[0]\n",
    "\n",
    "\n",
    "    guide_indices_fgsm.append(guide_img_idx_fgsm)\n",
    "    guide_indices_bim_a.append(guide_img_idx_bim_a)\n",
    "    guide_indices_bim_b.append(guide_img_idx_bim_b)\n",
    "\n",
    "\n",
    "#1 Phase Attack\n",
    "fgsm_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM-WB', eps=eps, x_tar=model.train_data[guide_indices_fgsm], y_tar = model.train_labels[guide_indices_fgsm])\n",
    "bim_a_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='BIM-A-WB', eps=eps, x_tar=model.train_data[guide_indices_bim_a], y_tar = model.train_labels[guide_indices_bim_a])\n",
    "bim_b_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='BIM-B-WB', eps=eps, x_tar=model.train_data[guide_indices_bim_b], y_tar = model.train_labels[guide_indices_bim_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Whitebox CW Attack\n",
    "#First get guide images\n",
    "guide_indices = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images for modified CW attacks\n",
    "for idx in test_indices:\n",
    "    label = np.argmax(model.test_labels[idx])\n",
    "    #Add 1 to the label mod 10 to get a target label\n",
    "    mod_label = (label + 1) % num_classes\n",
    "    #Get a test point with the target label\n",
    "    guide_imgs_indices = np.where(model.train_labels[:,mod_label] == 1)[0]\n",
    "    #Choose a guide image\n",
    "    guide_img_idx = np.random.choice(guide_imgs_indices, 1)[0]\n",
    "    guide_indices.append(guide_img_idx)\n",
    "\n",
    "\n",
    "#1 Phase Attack\n",
    "p1_cw_data = model.generate_perturbed_data(model.test_data[test_indices], y_tar=model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True, eps=eps)\n",
    "\n",
    "#2 Phase Attack \n",
    "#Phase 1: Generate targeted adversarial images \n",
    "tar_cw_data = model.generate_perturbed_data(model.test_data[test_indices], y_tar=model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, use_cos_norm_reg=False, eps=eps)\n",
    "#Phase 2: Optimize for higher cosine sim and smaller norm of gradient vector\n",
    "p2_cw_data = model.generate_perturbed_data(tar_cw_data, y_tar=model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Whitebox CW 2 Phase attack with FGSM, BIM-a/b guide images\n",
    "p2_cw_fgsm_data = model.generate_perturbed_data(fgsm_data, y_tar=model.train_labels[guide_indices_fgsm],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_fgsm], use_cos_norm_reg=True, eps=eps)\n",
    "p2_cw_bim_a_data = model.generate_perturbed_data(bim_a_data, y_tar=model.train_labels[guide_indices_bim_a],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_bim_a], use_cos_norm_reg=True, eps=eps)\n",
    "p2_cw_bim_b_data = model.generate_perturbed_data(bim_b_data, y_tar=model.train_labels[guide_indices_bim_b],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_bim_b], use_cos_norm_reg=True, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Model Accuracy REG: %.5f' % (model.model.evaluate(reg_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy FGSM: %.5f' % (model.model.evaluate(fgsm_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-A: %.5f' % (model.model.evaluate(bim_a_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-B: %.5f' % (model.model.evaluate(bim_b_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy CW: %.5f' % (model.model.evaluate(cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy DF: %.5f' % (model.model.evaluate(df_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy JSMA: %.5f' % (model.model.evaluate(jsma_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy FGSM-WB: %.5f' % (model.model.evaluate(fgsm_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-A WB: %.5f' % (model.model.evaluate(bim_a_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-B WB: %.5f' % (model.model.evaluate(bim_b_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P1 CW: %.5f' % (model.model.evaluate(p1_cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 CW: %.5f' % (model.model.evaluate(p2_cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 FGSM: %.5f' % (model.model.evaluate(p2_cw_fgsm_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 BIM-A: %.5f' % (model.model.evaluate(p2_cw_bim_a_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 BIM-B %.5f' % (model.model.evaluate(p2_cw_bim_b_data,model.test_labels[test_indices])[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get distortion\n",
    "print ('FGSM: %.5f' % (avg_l2_dist(reg_data, fgsm_data)))\n",
    "print ('BIM-A: %.5f' % (avg_l2_dist(reg_data, bim_a_data)))\n",
    "print ('BIM-B: %.5f' % (avg_l2_dist(reg_data, bim_b_data)))\n",
    "print ('CW: %.5f' % (avg_l2_dist(reg_data, cw_data)))\n",
    "print ('DF: %.5f' % (avg_l2_dist(reg_data, df_data)))\n",
    "print ('FGSM-WB: %.5f' % (avg_l2_dist(reg_data, fgsm_wb_data)))\n",
    "print ('BIM-A-WB: %.5f' % (avg_l2_dist(reg_data, bim_a_wb_data)))\n",
    "print ('BIM-B-WB: %.5f' % (avg_l2_dist(reg_data, bim_b_wb_data)))\n",
    "print ('JSMA: %.5f' % (avg_l2_dist(reg_data, jsma_data)))\n",
    "print ('P1-CW: %.5f' % (avg_l2_dist(reg_data, p1_cw_data)))\n",
    "print ('P2-CW: %.5f' % (avg_l2_dist(reg_data, p2_cw_data)))\n",
    "print ('P2-CW FGSM: %.5f' % (avg_l2_dist(reg_data, p2_cw_fgsm_data)))\n",
    "print ('P2-CW BIM A: %.5f' % (avg_l2_dist(reg_data, p2_cw_bim_a_data)))\n",
    "print ('P2-CW BIM B: %.5f' % (avg_l2_dist(reg_data, p2_cw_bim_b_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "print ('Regular: ')\n",
    "visualize(reg_data[x_vis].reshape(*input_shape))\n",
    "print ('FGSM: ')\n",
    "visualize(fgsm_data[x_vis].reshape(*input_shape))\n",
    "print ('BIM-A: ')\n",
    "visualize(bim_a_data[x_vis].reshape(*input_shape))\n",
    "print ('BIM-B: ')\n",
    "visualize(bim_b_data[x_vis].reshape(*input_shape))\n",
    "print ('CW: ')\n",
    "visualize(cw_data[x_vis].reshape(*input_shape))\n",
    "print ('DF: ')\n",
    "visualize(df_data[x_vis].reshape(*input_shape))\n",
    "print ('JSMA: ')\n",
    "visualize(jsma_data[x_vis].reshape(*input_shape))\n",
    "print ('FGSM-WB: ')\n",
    "visualize(fgsm_wb_data[x_vis].reshape(*input_shape))\n",
    "print ('BIM-A-WB: ')\n",
    "visualize(bim_a_wb_data[x_vis].reshape(*input_shape))\n",
    "print ('BIM-B-WB: ')\n",
    "visualize(bim_b_wb_data[x_vis].reshape(*input_shape))\n",
    "print ('P1-CW: ')\n",
    "visualize(p1_cw_data[x_vis].reshape(*input_shape))\n",
    "print ('P2-CW: ')\n",
    "visualize(p2_cw_data[x_vis].reshape(*input_shape))\n",
    "print ('P2-FGSM: ')\n",
    "visualize(p2_cw_fgsm_data[x_vis].reshape(*input_shape))\n",
    "print ('P2-BIM-A')\n",
    "visualize(p2_cw_bim_a_data[x_vis].reshape(*input_shape))\n",
    "print ('P2-BIM-B')\n",
    "visualize(p2_cw_bim_b_data[x_vis].reshape(*input_shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,*input_shape))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,*input_shape))\n",
    "bim_a_preds = model.model.predict(bim_a_data.reshape(-1,*input_shape))\n",
    "bim_b_preds = model.model.predict(bim_b_data.reshape(-1,*input_shape))\n",
    "fgsm_wb_preds = model.model.predict(fgsm_wb_data.reshape(-1,*input_shape))\n",
    "bim_a_wb_preds = model.model.predict(bim_a_wb_data.reshape(-1,*input_shape))\n",
    "bim_b_wb_preds = model.model.predict(bim_a_wb_data.reshape(-1,*input_shape))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,*input_shape))\n",
    "df_preds = model.model.predict(df_data.reshape(-1,*input_shape))\n",
    "jsma_preds = model.model.predict(jsma_data.reshape(-1,*input_shape))\n",
    "p1_cw_preds = model.model.predict(p1_cw_data.reshape(-1,*input_shape))\n",
    "p2_cw_preds = model.model.predict(p2_cw_data.reshape(-1,*input_shape))\n",
    "p2_cw_fgsm_preds = model.model.predict(p2_cw_fgsm_data.reshape(-1,*input_shape))\n",
    "p2_cw_bim_a_preds = model.model.predict(p2_cw_bim_a_data.reshape(-1,*input_shape))\n",
    "p2_cw_bim_b_preds = model.model.predict(p2_cw_bim_b_data.reshape(-1,*input_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = preds_to_labels(reg_preds)\n",
    "fgsm_labels = preds_to_labels(fgsm_preds)\n",
    "bim_a_labels = preds_to_labels(bim_a_preds)\n",
    "bim_b_labels = preds_to_labels(bim_b_preds)\n",
    "fgsm_wb_labels = preds_to_labels(fgsm_wb_preds)\n",
    "bim_a_wb_labels = preds_to_labels(bim_a_wb_preds)\n",
    "bim_b_wb_labels = preds_to_labels(bim_b_wb_preds)\n",
    "cw_labels = preds_to_labels(cw_preds)\n",
    "df_labels = preds_to_labels(df_preds)\n",
    "jsma_labels = preds_to_labels(jsma_preds)\n",
    "p1_cw_labels = preds_to_labels(p1_cw_preds)\n",
    "p2_cw_labels = preds_to_labels(p2_cw_preds)\n",
    "p2_cw_fgsm_labels = preds_to_labels(p2_cw_fgsm_preds)\n",
    "p2_cw_bim_a_labels = preds_to_labels(p2_cw_bim_a_preds)\n",
    "p2_cw_bim_b_labels = preds_to_labels(p2_cw_bim_b_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select Adversarial Points (i.e. points that lead to misclassification)\n",
    "true_preds = np.argmax(model.test_labels[test_indices], axis=1)\n",
    "\n",
    "#Check which points are actually adversarial and select those\n",
    "fgsm_idx = np.where(np.argmax(fgsm_preds, axis=1) != true_preds)\n",
    "bim_a_idx = np.where(np.argmax(bim_a_preds, axis=1) != true_preds)\n",
    "bim_b_idx = np.where(np.argmax(bim_b_preds, axis=1) != true_preds)\n",
    "fgsm_wb_idx =  np.where(np.argmax(fgsm_wb_preds, axis=1) != true_preds)\n",
    "bim_a_wb_idx = np.where(np.argmax(bim_a_wb_preds, axis=1) != true_preds)\n",
    "bim_b_wb_idx = np.where(np.argmax(bim_b_wb_preds, axis=1) != true_preds)\n",
    "cw_idx = np.where(np.argmax(cw_preds, axis=1) != true_preds)\n",
    "df_idx = np.where(np.argmax(df_preds, axis=1) != true_preds)\n",
    "jsma_idx = np.where(np.argmax(jsma_preds, axis=1) != true_preds)\n",
    "p1_cw_idx = np.where(np.argmax(p1_cw_preds, axis=1) != true_preds)\n",
    "p2_cw_idx = np.where(np.argmax(p2_cw_preds, axis=1) != true_preds)\n",
    "p2_cw_fgsm_idx = np.where(np.argmax(p2_cw_fgsm_preds, axis=1) != true_preds)\n",
    "p2_cw_bim_a_idx = np.where(np.argmax(p2_cw_bim_a_preds, axis=1) != true_preds)\n",
    "p2_cw_bim_b_idx = np.where(np.argmax(p2_cw_bim_b_preds, axis=1) != true_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter data points to be used for similarity\n",
    "fgsm_data_fil = fgsm_data[fgsm_idx]\n",
    "bim_a_data_fil = bim_a_data[bim_a_idx]\n",
    "bim_b_data_fil = bim_b_data[bim_b_idx]\n",
    "fgsm_wb_data_fil = fgsm_wb_data[fgsm_wb_idx]\n",
    "bim_a_wb_data_fil = bim_a_wb_data[bim_a_wb_idx]\n",
    "bim_b_wb_data_fil = bim_b_wb_data[bim_b_wb_idx]\n",
    "cw_data_fil = cw_data[cw_idx]\n",
    "df_data_fil = df_data[df_idx]\n",
    "jsma_data_fil = jsma_data[jsma_idx]\n",
    "p1_cw_data_fil = p1_cw_data[p1_cw_idx]\n",
    "p2_cw_data_fil = p2_cw_data[p2_cw_idx]\n",
    "p2_cw_fgsm_data_fil = p2_cw_fgsm_data[p2_cw_fgsm_idx]\n",
    "p2_cw_bim_a_data_fil = p2_cw_bim_a_data[p2_cw_bim_a_idx]\n",
    "p2_cw_bim_b_data_fil = p2_cw_bim_b_data[p2_cw_bim_b_idx]\n",
    "\n",
    "#Filter labels to be used\n",
    "fgsm_labels_fil = fgsm_labels[fgsm_idx]\n",
    "bim_a_labels_fil = bim_a_labels[bim_a_idx]\n",
    "bim_b_labels_fil = bim_b_labels[bim_b_idx]\n",
    "fgsm_wb_labels_fil = fgsm_wb_labels[fgsm_wb_idx]\n",
    "bim_a_wb_labels_fil = bim_a_wb_labels[bim_a_wb_idx]\n",
    "bim_b_wb_labels_fil = bim_b_wb_labels[bim_b_wb_idx]\n",
    "cw_labels_fil = cw_labels[cw_idx]\n",
    "df_labels_fil = df_labels[df_idx]\n",
    "jsma_labels_fil = jsma_labels[jsma_idx]\n",
    "p1_cw_labels_fil = p1_cw_labels[p1_cw_idx]\n",
    "p2_cw_labels_fil = p2_cw_labels[p2_cw_idx]\n",
    "p2_cw_fgsm_labels_fil = p2_cw_fgsm_labels[p2_cw_fgsm_idx]\n",
    "p2_cw_bim_a_labels_fil = p2_cw_bim_a_labels[p2_cw_bim_a_idx]\n",
    "p2_cw_bim_b_labels_fil = p2_cw_bim_b_labels[p2_cw_bim_b_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity and norms\n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)\n",
    "grads_train = normalize(grads_train)\n",
    "grads_reg_norms, cos_sim_reg = norms_and_cos(model, reg_data, reg_labels, grads_train)\n",
    "grads_fgsm_norms, cos_sim_fgsm =norms_and_cos(model, fgsm_data_fil, fgsm_labels_fil, grads_train)\n",
    "grads_bim_a_norms, cos_sim_bim_a = norms_and_cos(model, bim_a_data_fil, bim_a_labels_fil, grads_train)\n",
    "grads_bim_b_norms , cos_sim_bim_b= norms_and_cos(model, bim_b_data_fil, bim_b_labels_fil, grads_train)\n",
    "grads_fgsm_wb_norms, cos_sim_fgsm_wb = norms_and_cos(model, fgsm_wb_data_fil, fgsm_wb_labels_fil, grads_train)\n",
    "grads_bim_a_wb_norms, cos_sim_bim_a_wb = norms_and_cos(model, bim_a_wb_data_fil, bim_a_wb_labels_fil, grads_train)\n",
    "grads_bim_b_wb_norms, cos_sim_bim_b_wb = norms_and_cos(model, bim_b_wb_data_fil, bim_b_wb_labels_fil, grads_train)\n",
    "grads_cw_norms, cos_sim_cw = norms_and_cos(model, cw_data_fil, cw_labels_fil, grads_train)\n",
    "grads_df_norms, cos_sim_df = norms_and_cos(model, df_data_fil, df_labels_fil, grads_train)\n",
    "grads_jsma_norms, cos_sim_jsma = norms_and_cos(model, jsma_data_fil, jsma_labels_fil, grads_train)\n",
    "grads_p1_cw_norms, cos_sim_p1_cw = norms_and_cos(model, p1_cw_data_fil, p1_cw_labels_fil, grads_train)\n",
    "grads_p2_cw_norms, cos_sim_p2_cw = norms_and_cos(model, p2_cw_data_fil, p2_cw_labels_fil, grads_train)\n",
    "grads_p2_cw_fgsm_norms, cos_sim_p2_cw_fgsm = norms_and_cos(model, p2_cw_fgsm_data_fil, p2_cw_fgsm_labels_fil, grads_train)\n",
    "grads_p2_cw_bim_a_norms, cos_sim_p2_cw_bim_a = norms_and_cos(model, p2_cw_bim_a_data_fil, p2_cw_bim_a_labels_fil, grads_train)\n",
    "grads_p2_cw_bim_b_norms, cos_sim_p2_cw_bim_b = norms_and_cos(model, p2_cw_bim_b_data_fil, p2_cw_bim_b_labels_fil, grads_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having cos sim greater\n",
    "print ('Noisy:  %.4f' % ( comp_cos(cos_sim_noisy, cos_sim_reg)))\n",
    "print ('FGSM:  %.4f' % ( comp_cos(cos_sim_fgsm, cos_sim_reg)))\n",
    "print ('BIM-A:  %.4f' % ( comp_cos(cos_sim_bim_a, cos_sim_reg)))\n",
    "print ('BIM-B:  %.4f' % ( comp_cos(cos_sim_bim_b, cos_sim_reg)))\n",
    "print ('CW: %.4f' % ( comp_cos(cos_sim_cw, cos_sim_reg)))\n",
    "print ('DF: %.4f' % ( comp_cos(cos_sim_df, cos_sim_reg)))\n",
    "print ('JSMA: %.4f' % ( comp_cos(cos_sim_jsma, cos_sim_reg)))\n",
    "print ('FGSM-WB:  %.4f' % ( comp_cos(cos_sim_fgsm_wb, cos_sim_reg)))\n",
    "print ('BIM-A-WB:  %.4f' % ( comp_cos(cos_sim_bim_a_wb, cos_sim_reg)))\n",
    "print ('BIM-B-WB:  %.4f' % ( comp_cos(cos_sim_bim_b_wb, cos_sim_reg)))\n",
    "print ('1 Phase CW:  %.4f' % ( comp_cos(cos_sim_p1_cw, cos_sim_reg)))\n",
    "print ('2 Phase CW:  %.4f' % ( comp_cos(cos_sim_p2_cw, cos_sim_reg)))\n",
    "print ('2 Phase CW FGSM:  %.4f' % ( comp_cos(cos_sim_p2_cw_fgsm, cos_sim_reg)))\n",
    "print ('2 Phase CW BIM A:  %.4f' % ( comp_cos(cos_sim_p2_cw_bim_a, cos_sim_reg)))\n",
    "print ('2 Phase CW BIM B:  %.4f' % ( comp_cos(cos_sim_p2_cw_bim_b, cos_sim_reg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having norm greater\n",
    "print ('Noisy:  %.4f' % ( comp_norm(grads_noisy_norms, grads_reg_norms)))\n",
    "print ('FGSM:  %.4f' % ( comp_norm(grads_fgsm_norms, grads_reg_norms)))\n",
    "print ('BIM-A:  %.4f' % ( comp_norm(grads_bim_a_norms, grads_reg_norms)))\n",
    "print ('BIM-B:  %.4f' % ( comp_norm(grads_bim_b_norms, grads_reg_norms)))\n",
    "print ('CW: %.4f' % ( comp_norm(grads_cw_norms, grads_reg_norms)))\n",
    "print ('DF: %.4f' % ( comp_norm(grads_df_norms, grads_reg_norms)))\n",
    "print ('JSMA: %.4f' % ( comp_norm(grads_jsma_norms, grads_reg_norms)))\n",
    "print ('FGSM-WB:  %.4f' % ( comp_norm(grads_fgsm_wb_norms, grads_reg_norms)))\n",
    "print ('BIM-A-WB:  %.4f' % ( comp_norm(grads_bim_a_wb_norms, grads_reg_norms)))\n",
    "print ('BIM-B-WB:  %.4f' % ( comp_norm(grads_bim_b_wb_norms, grads_reg_norms)))\n",
    "print ('1 Phase CW: %.4f' % ( comp_norm(grads_p1_cw_norms, grads_reg_norms)))\n",
    "print ('2 Phase CW: %.4f' % ( comp_norm(grads_p2_cw_norms, grads_reg_norms)))\n",
    "print ('2 Phase CW FGSM: %.4f' % ( comp_norm(grads_p2_cw_fgsm_norms, grads_reg_norms)))\n",
    "print ('2 Phase CW BIM A: %.4f' % ( comp_norm(grads_p2_cw_bim_a_norms, grads_reg_norms)))\n",
    "print ('2 Phase CW BIM B: %.4f' % ( comp_norm(grads_p2_cw_bim_b_norms, grads_reg_norms)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train a logistic regression classifier on the data. We only train on gray box attack points. \n",
    "#Due to lack of data (computationally expensive to compute attack points), we use 95% of data to train and 5% to test\n",
    "\n",
    "#Select training and test indices\n",
    "np.random.seed(SEED)\n",
    "train_pct = .95\n",
    "reg_train_idx = np.random.choice(range(num_test_samples), int(train_pct*num_test_samples))\n",
    "reg_test_idx = get_test_from_train_idx(range(num_test_samples), reg_train_idx)\n",
    "fgsm_train_idx = np.random.choice(fgsm_idx, int(len(fgsm_idx)*train_pct))\n",
    "fgsm_test_idx = get_test_from_train_idx(fgsm_idx, fgsm_train_idx)\n",
    "bim_a_train_idx = np.random.choice(bim_a_idx, int(len(bim_a_idx)*train_pct))\n",
    "bim_a_test_idx = get_test_from_train_idx(bim_a_idx, bim_a_train_idx)\n",
    "bim_b_train_idx =np.random.choice(bim_b_idx, int(len(bim_b_idx)*train_pct))\n",
    "bim_b_test_idx = get_test_from_train_idx(bim_b_idx, bim_b_train_idx)\n",
    "jsma_train_idx =np.random.choice(jsma_idx, int(len(jsma_idx)*train_pct))\n",
    "jsma_test_idx = get_test_from_train_idx(jsma_idx, jsma_train_idx)\n",
    "cw_train_idx = np.random.choice(cw_idx, int(len(cw_idx)*train_pct))\n",
    "cw_test_idx = get_test_from_train_idx(cw_idx, cw_train_idx)\n",
    "df_train_idx = np.random.choice(df_idx, int(len(df_idx)*train_pct))\n",
    "df_test_idx = get_test_from_train_idx(df_idx, df_train_idx)\n",
    "\n",
    "\n",
    "\n",
    "# Set up training and test data for logistic regression\n",
    "train_data = np.concatenate((cos_sim_reg[reg_train_idx], \n",
    "                             cos_sim_fgsm[fgsm_train_idx],\n",
    "                             cos_sim_bim_a[bim_a_train_idx],\n",
    "                             cos_sim_bim_b[bim_b_train_idx], \n",
    "                             cos_sim_jsma[jsma_train_idx], \n",
    "                             cos_sim_cw[cw_train_idx], \n",
    "                             cos_sim_df[df_train_idx]),axis=0)\n",
    "train_labels = np.concatenate((np.zeros(len(reg_train_idx)), \n",
    "                               np.ones(len(fgsm_train_idx)),\n",
    "                               np.ones(len(bim_a_train_idx)),\n",
    "                               np.ones(len(bim_b_train_idx)),\n",
    "                               np.ones(len(jsma_train_idx)),\n",
    "                               np.ones(len(cw_train_idx)),\n",
    "                               np.ones(len(df_train_idx))),axis=0)\n",
    "\n",
    "test_data = np.concatenate((cos_sim_reg[reg_test_idx], \n",
    "                             cos_sim_fgsm[fgsm_test_idx],\n",
    "                             cos_sim_bim_a[bim_a_test_idx],\n",
    "                             cos_sim_bim_b[bim_b_test_idx], \n",
    "                             cos_sim_jsma[jsma_test_idx], \n",
    "                             cos_sim_cw[cw_test_idx], \n",
    "                             cos_sim_df[df_test_idx],\n",
    "                             cos_sim_fgsm_wb,\n",
    "                             cos_sim_bim_a_wb,\n",
    "                             cos_sim_bim_b_wb,\n",
    "                             cos_sim_p1_cw, \n",
    "                             cos_sim_p2_cw,\n",
    "                             cos_sim_p2_cw_fgsm,\n",
    "                             cos_sim_p2_cw_bim_a,\n",
    "                             cos_sim_p2_cw_bim_b,),axis=0)\n",
    "\n",
    "test_labels = np.concatenate((np.zeros(len(reg_test_idx)), \n",
    "                               np.ones(len(fgsm_test_idx)),\n",
    "                               np.ones(len(bim_a_test_idx)),\n",
    "                               np.ones(len(bim_b_test_idx)),\n",
    "                               np.ones(len(jsma_test_idx)),\n",
    "                               np.ones(len(cw_test_idx)),\n",
    "                               np.ones(len(df_test_idx)),\n",
    "                               np.ones(len(cos_sim_fgsm_wb)), \n",
    "                               np.ones(len(cos_sim_bim_a_wb)),\n",
    "                               np.ones(len(cos_sim_bim_b_wb)),                               \n",
    "                               np.ones(len(cos_sim_p1_cw)), \n",
    "                               np.ones(len(cos_sim_p2_cw)),\n",
    "                               np.ones(len(cos_sim_p2_cw_fgsm)),\n",
    "                               np.ones(len(cos_sim_p2_cw_bim_a)),\n",
    "                               np.ones(len(cos_sim_p2_cw_bim_b,))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the data\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(train_data, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Accuracy for each attack type\n",
    "fgsm_acc = logreg.score(cos_sim_fgsm[fgsm_test_idx], np.ones(len(fgsm_test_idx)))\n",
    "bim_a_acc = logreg.score(cos_sim_bim_a[bim_a_test_idx], np.ones(len(bim_a_test_idx)))\n",
    "bim_b_acc = logreg.score(cos_sim_bim_b[bim_b_test_idx], np.ones(len(bim_b_test_idx)))\n",
    "jsma_acc = logreg.score(cos_sim_jsma[jsma_test_idx], np.ones(len(jsma_test_idx)))\n",
    "cw_acc = logreg.score(cos_sim_cw[cw_test_idx], np.ones(len(cw_test_idx)))\n",
    "df_acc = logreg.score(cos_sim_df[df_test_idx], np.ones(len(df_test_idx)))\n",
    "fgsm_wb_acc = logreg.score(cos_sim_fgsm_wb, np.ones(len(cos_sim_fgsm_wb)))\n",
    "bim_a_wb_acc = logreg.score(cos_sim_bim__wb, np.ones(len(cos_sim_bim__wb)))\n",
    "bim_b_wb_acc = logreg.score(cos_sim_fgsm_wb, np.ones(len(cos_sim_fgsm_wb)))\n",
    "p1_cw_acc = logreg.score(cos_sim_p1_cw, np.ones(cos_sim_p1_cw))\n",
    "p2_cw_acc = logreg.score(cos_sim_p2_cw, np.ones(cos_sim_p2_cw))\n",
    "p2_cw_fgsm_acc = logreg.score(cos_sim_p2_cw_fgsm, np.ones(cos_sim_p2_cw_fgsm))\n",
    "p2_cw_bim_a_acc = logreg.score(cos_sim_p2_cw_bim_a, np.ones(cos_sim_p2_cw_bim_a))\n",
    "p2_cw_bim_b_acc = logreg.score(cos_sim_p2_cw_bim_b, np.ones(cos_sim_p2_cw_bim_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Total accuracy\n",
    "total_acc = logreg.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot ROC for the entire test dataset\n",
    "probs = logreg.predict_proba(test_data)\n",
    "fpr, tpr, _ = roc_curve(test_labels, probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr,\n",
    "         label='ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc),\n",
    "         color='deeppink', linestyle=':', linewidth=1)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
