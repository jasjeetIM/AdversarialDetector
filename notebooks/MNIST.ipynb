{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os, gc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "from models.util import *\n",
    "\n",
    "\n",
    "#Seed used for choosing classes, training points, and test points.\n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define params of model\n",
    "input_shape = (28,28,1)\n",
    "num_classes = 10\n",
    "eps=0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Params: 3330314\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'MNIST'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "print ('Total Model Params: %d' % model.num_params)\n",
    "model.load_model(model_save_path, weights_save_path) \n",
    "#epochs = 50\n",
    "#model.train(epochs=epochs)\n",
    "#model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6055/6055 [==============================] - 1s 222us/step\n",
      "Model Accuracy: 0.99306\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy\n",
    "print ('Model Accuracy: %.5f' % (model.model.evaluate(model.test_data, model.test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 1000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GREYBOX ATTACKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = num_classes*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM', eps=eps)\n",
    "bim_a_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM-A', iterations=10, eps=eps)\n",
    "bim_b_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM-B', iterations=10, eps=eps)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False, eps=eps)\n",
    "df_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='DF', nb_candidate=num_classes)\n",
    "jsma_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='JSMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9626b71ab224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Reload the model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/notebook/Jay-Notebooks/src/adversarial_detector/models/cnn.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, non_linearity, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_linearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/notebook/Jay-Notebooks/src/adversarial_detector/models/neural_network.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, dataset, batch_size, initial_learning_rate, load_from_file, load_model_path, load_weights_path, seed)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'mnist'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'drebin'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/notebook/Jay-Notebooks/src/adversarial_detector/models/neural_network.pyc\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/datasets/mnist.pyc\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n\u001b[1;32m     18\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    232\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[1;32m    675\u001b[0m                                                              count=read_count)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/format.pyc\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36mread1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_crc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36m_update_crc\u001b[0;34m(self, newdata, eof)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# No need to compute the CRC if we don't have a reference value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Check the CRC if we're at the end of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meof\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expected_crc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Model Accuracy REG: %.5f' % (model.model.evaluate(reg_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy FGSM: %.5f' % (model.model.evaluate(fgsm_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-A: %.5f' % (model.model.evaluate(bim_a_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-B: %.5f' % (model.model.evaluate(bim_b_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy CW: %.5f' % (model.model.evaluate(cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy DF: %.5f' % (model.model.evaluate(df_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy JSMA: %.5f' % (model.model.evaluate(jsma_data,model.test_labels[test_indices])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets visualize samples from each attack\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 10)\n",
    "print ('Regular: ')\n",
    "visualize(reg_data[x_vis].reshape(-1,*input_shape), 10, '../figures/reg-cifar2')\n",
    "print ('FGSM: ')\n",
    "visualize(fgsm_data[x_vis].reshape(-1,*input_shape), 10, '../figures/fgsm-cifar2')\n",
    "print ('BIM-A: ')\n",
    "visualize(bim_a_data[x_vis].reshape(-1,*input_shape), 10, '../figures/bim-a-cifar2')\n",
    "print ('BIM-B: ')\n",
    "visualize(bim_b_data[x_vis].reshape(-1,*input_shape), 10, '../figures/bim-b-cifar2')\n",
    "print ('CW: ')\n",
    "visualize(cw_data[x_vis].reshape(-1,*input_shape), 10, '../figures/cw-cifar2')\n",
    "print ('DF: ')\n",
    "visualize(df_data[x_vis].reshape(-1,*input_shape), 10, '../figures/df-cifar2')\n",
    "print ('JSMA: ')\n",
    "visualize(jsma_data[x_vis].reshape(-1,*input_shape), 10, '../figures/jsma-cifar2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,*input_shape))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,*input_shape))\n",
    "bim_a_preds = model.model.predict(bim_a_data.reshape(-1,*input_shape))\n",
    "bim_b_preds = model.model.predict(bim_b_data.reshape(-1,*input_shape))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,*input_shape))\n",
    "df_preds = model.model.predict(df_data.reshape(-1,*input_shape))\n",
    "jsma_preds = model.model.predict(jsma_data.reshape(-1,*input_shape))\n",
    "\n",
    "#Convert preds to labels\n",
    "reg_labels = preds_to_labels(reg_preds)\n",
    "fgsm_labels = preds_to_labels(fgsm_preds)\n",
    "bim_a_labels = preds_to_labels(bim_a_preds)\n",
    "bim_b_labels = preds_to_labels(bim_b_preds)\n",
    "cw_labels = preds_to_labels(cw_preds)\n",
    "df_labels = preds_to_labels(df_preds)\n",
    "jsma_labels = preds_to_labels(jsma_preds)\n",
    "\n",
    "#Select Adversarial Points (i.e. points that lead to misclassification)\n",
    "true_preds = np.argmax(model.test_labels[test_indices], axis=1)\n",
    "\n",
    "#Check which points are actually adversarial and select those\n",
    "fgsm_idx = np.where(np.argmax(fgsm_preds, axis=1) != true_preds)[0]\n",
    "bim_a_idx = np.where(np.argmax(bim_a_preds, axis=1) != true_preds)[0]\n",
    "bim_b_idx = np.where(np.argmax(bim_b_preds, axis=1) != true_preds)[0]\n",
    "cw_idx = np.where(np.argmax(cw_preds, axis=1) != true_preds)[0]\n",
    "df_idx = np.where(np.argmax(df_preds, axis=1) != true_preds)[0]\n",
    "jsma_idx = np.where(np.argmax(jsma_preds, axis=1) != true_preds)[0]\n",
    "\n",
    "\n",
    "#Filter data points to be used for similarity\n",
    "fgsm_data_fil = fgsm_data[fgsm_idx]\n",
    "bim_a_data_fil = bim_a_data[bim_a_idx]\n",
    "bim_b_data_fil = bim_b_data[bim_b_idx]\n",
    "cw_data_fil = cw_data[cw_idx]\n",
    "df_data_fil = df_data[df_idx]\n",
    "jsma_data_fil = jsma_data[jsma_idx]\n",
    "\n",
    "\n",
    "#Filter labels to be used\n",
    "fgsm_labels_fil = fgsm_labels[fgsm_idx]\n",
    "bim_a_labels_fil = bim_a_labels[bim_a_idx]\n",
    "bim_b_labels_fil = bim_b_labels[bim_b_idx]\n",
    "cw_labels_fil = cw_labels[cw_idx]\n",
    "df_labels_fil = df_labels[df_idx]\n",
    "jsma_labels_fil = jsma_labels[jsma_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get distortion \n",
    "print ('FGSM: %.5f' % (avg_l2_dist(reg_data[fgsm_idx], fgsm_data_fil)))\n",
    "print ('BIM-A: %.5f' % (avg_l2_dist(reg_data[bim_a_idx], bim_a_data_fil)))\n",
    "print ('BIM-B: %.5f' % (avg_l2_dist(reg_data[bim_b_idx], bim_b_data_fil)))\n",
    "print ('CW: %.5f' % (avg_l2_dist(reg_data[cw_idx], cw_data_fil)))\n",
    "print ('DF: %.5f' % (avg_l2_dist(reg_data[df_idx], df_data_fil)))\n",
    "print ('JSMA: %.5f' % (avg_l2_dist(reg_data[jsma_idx], jsma_data_fil)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity and norms\n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)\n",
    "grads_train = normalize(grads_train)\n",
    "grads_reg_norms, cos_sim_reg = norms_and_cos(model, reg_data, reg_labels, grads_train)\n",
    "grads_fgsm_norms, cos_sim_fgsm =norms_and_cos(model, fgsm_data_fil, fgsm_labels_fil, grads_train)\n",
    "grads_bim_a_norms, cos_sim_bim_a = norms_and_cos(model, bim_a_data_fil, bim_a_labels_fil, grads_train)\n",
    "grads_bim_b_norms , cos_sim_bim_b= norms_and_cos(model, bim_b_data_fil, bim_b_labels_fil, grads_train)\n",
    "grads_cw_norms, cos_sim_cw = norms_and_cos(model, cw_data_fil, cw_labels_fil, grads_train)\n",
    "grads_df_norms, cos_sim_df = norms_and_cos(model, df_data_fil, df_labels_fil, grads_train)\n",
    "grads_jsma_norms, cos_sim_jsma = norms_and_cos(model, jsma_data_fil, jsma_labels_fil, grads_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION FOR GREYBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train a logistic regression classifier on the data. We only train on gray box attack points. \n",
    "#Due to lack of data (computationally expensive to compute attack points), we use 95% of data to train and 5% to test\n",
    "\n",
    "#Select training and test indices\n",
    "np.random.seed(SEED)\n",
    "train_pct = .95\n",
    "reg_train_idx = np.random.choice(np.arange(num_test_samples), int(train_pct*num_test_samples), replace=False)\n",
    "reg_test_idx = get_test_from_train_idx(np.arange(num_test_samples), reg_train_idx)\n",
    "fgsm_train_idx = np.random.choice(np.arange(len(fgsm_idx)), int(len(fgsm_idx)*train_pct), replace=False)\n",
    "fgsm_test_idx = get_test_from_train_idx(np.arange(len(fgsm_idx)), fgsm_train_idx)\n",
    "bim_a_train_idx = np.random.choice(np.arange(len(bim_a_idx)), int(len(bim_a_idx)*train_pct), replace=False)\n",
    "bim_a_test_idx = get_test_from_train_idx(np.arange(len(bim_a_idx)), bim_a_train_idx)\n",
    "bim_b_train_idx =np.random.choice(np.arange(len(bim_b_idx)), int(len(bim_b_idx)*train_pct), replace=False)\n",
    "bim_b_test_idx = get_test_from_train_idx(np.arange(len(bim_b_idx)), bim_b_train_idx)\n",
    "jsma_train_idx =np.random.choice(np.arange(len(jsma_idx)), int(len(jsma_idx)*train_pct), replace=False)\n",
    "jsma_test_idx = get_test_from_train_idx(np.arange(len(jsma_idx)), jsma_train_idx)\n",
    "cw_train_idx = np.random.choice(np.arange(len(cw_idx)), int(len(cw_idx)*train_pct), replace=False)\n",
    "cw_test_idx = get_test_from_train_idx(np.arange(len(cw_idx)), cw_train_idx)\n",
    "df_train_idx = np.random.choice(np.arange(len(df_idx)), int(len(df_idx)*train_pct), replace=False)\n",
    "df_test_idx = get_test_from_train_idx(np.arange(len(df_idx)), df_train_idx)\n",
    "\n",
    "\n",
    "\n",
    "# Set up training and test data for logistic regression\n",
    "train_data = np.concatenate((cos_sim_reg[reg_train_idx], \n",
    "                             cos_sim_fgsm[fgsm_train_idx],\n",
    "                             cos_sim_bim_a[bim_a_train_idx],\n",
    "                             cos_sim_bim_b[bim_b_train_idx], \n",
    "                             cos_sim_jsma[jsma_train_idx], \n",
    "                             cos_sim_cw[cw_train_idx], \n",
    "                             cos_sim_df[df_train_idx]),axis=0)\n",
    "train_labels = np.concatenate((np.zeros(len(reg_train_idx)), \n",
    "                               np.ones(len(fgsm_train_idx)),\n",
    "                               np.ones(len(bim_a_train_idx)),\n",
    "                               np.ones(len(bim_b_train_idx)),\n",
    "                               np.ones(len(jsma_train_idx)),\n",
    "                               np.ones(len(cw_train_idx)),\n",
    "                               np.ones(len(df_train_idx))),axis=0)\n",
    "\n",
    "test_data = np.concatenate((cos_sim_reg[reg_test_idx], \n",
    "                             cos_sim_fgsm[fgsm_test_idx],\n",
    "                             cos_sim_bim_a[bim_a_test_idx],\n",
    "                             cos_sim_bim_b[bim_b_test_idx], \n",
    "                             cos_sim_jsma[jsma_test_idx], \n",
    "                             cos_sim_cw[cw_test_idx], \n",
    "                             cos_sim_df[df_test_idx]),axis=0)\n",
    "\n",
    "test_labels = np.concatenate((np.zeros(len(reg_test_idx)), \n",
    "                               np.ones(len(fgsm_test_idx)),\n",
    "                               np.ones(len(bim_a_test_idx)),\n",
    "                               np.ones(len(bim_b_test_idx)),\n",
    "                               np.ones(len(jsma_test_idx)),\n",
    "                               np.ones(len(cw_test_idx)),\n",
    "                               np.ones(len(df_test_idx))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the data\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(train_data, train_labels)\n",
    "\n",
    "#Get Accuracy for each attack type\n",
    "fgsm_acc = logreg.score(cos_sim_fgsm[fgsm_test_idx], np.ones(len(fgsm_test_idx)))\n",
    "bim_a_acc = logreg.score(cos_sim_bim_a[bim_a_test_idx], np.ones(len(bim_a_test_idx)))\n",
    "bim_b_acc = logreg.score(cos_sim_bim_b[bim_b_test_idx], np.ones(len(bim_b_test_idx)))\n",
    "jsma_acc = logreg.score(cos_sim_jsma[jsma_test_idx], np.ones(len(jsma_test_idx)))\n",
    "cw_acc = logreg.score(cos_sim_cw[cw_test_idx], np.ones(len(cw_test_idx)))\n",
    "df_acc = logreg.score(cos_sim_df[df_test_idx], np.ones(len(df_test_idx)))\n",
    "\n",
    "#Get Total accuracy\n",
    "total_acc = logreg.score(test_data, test_labels)\n",
    "\n",
    "print ('FGSM Detection Acc: %.5f' % (fgsm_acc))\n",
    "print ('BIM-A Detection Acc: %.5f' % (bim_a_acc))\n",
    "print ('BIM-B Detection Acc: %.5f' % (bim_b_acc))\n",
    "print ('JSMA Detection Acc: %.5f' % (jsma_acc))\n",
    "print ('CW Detection Acc: %.5f' % (cw_acc))\n",
    "print ('DF Detection Acc: %.5f' % (df_acc))\n",
    "print ('TOTAL Detection Acc: %.5f' %(total_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot ROC for the entire test dataset\n",
    "probs = logreg.predict_proba(test_data)\n",
    "fpr, tpr, _ = roc_curve(test_labels, probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr,\n",
    "         label='ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc),\n",
    "         color='blue', linewidth=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('cifar.eps', format='eps', dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLDING FOR GREYBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having cos sim greater\n",
    "print ('FGSM:  %.4f' % ( comp_cos(cos_sim_fgsm, cos_sim_reg[fgsm_idx])))\n",
    "print ('BIM-A:  %.4f' % ( comp_cos(cos_sim_bim_a, cos_sim_reg[bim_a_idx])))\n",
    "print ('BIM-B:  %.4f' % ( comp_cos(cos_sim_bim_b, cos_sim_reg[bim_b_idx])))\n",
    "print ('CW: %.4f' % ( comp_cos(cos_sim_cw, cos_sim_reg[cw_idx])))\n",
    "print ('DF: %.4f' % ( comp_cos(cos_sim_df, cos_sim_reg[df_idx])))\n",
    "print ('JSMA: %.4f' % ( comp_cos(cos_sim_jsma, cos_sim_reg[jsma_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having norm greater\n",
    "print ('FGSM:  %.4f' % ( comp_norm(grads_fgsm_norms, grads_reg_norms[fgsm_idx])))\n",
    "print ('BIM-A:  %.4f' % ( comp_norm(grads_bim_a_norms, grads_reg_norms[bim_a_idx])))\n",
    "print ('BIM-B:  %.4f' % ( comp_norm(grads_bim_b_norms, grads_reg_norms[bim_b_idx])))\n",
    "print ('CW: %.4f' % ( comp_norm(grads_cw_norms, grads_reg_norms[cw_idx])))\n",
    "print ('DF: %.4f' % ( comp_norm(grads_df_norms, grads_reg_norms[df_idx])))\n",
    "print ('JSMA: %.4f' % ( comp_norm(grads_jsma_norms, grads_reg_norms[jsma_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Using Cos Sim\n",
    "eta = 0.7\n",
    "print ('Regular: %.4f' % ( greater_cos(cos_sim_reg, eta)))\n",
    "print ('FGSM:  %.4f' % ( greater_cos(cos_sim_fgsm, eta)))\n",
    "print ('BIM-A:  %.4f' % ( greater_cos(cos_sim_bim_a, eta)))\n",
    "print ('BIM-B:  %.4f' % ( greater_cos(cos_sim_bim_b, eta)))\n",
    "print ('CW: %.4f' % ( greater_cos(cos_sim_cw, eta)))\n",
    "print ('DF: %.4f' % ( greater_cos(cos_sim_df, eta)))\n",
    "print ('JSMA: %.4f' % ( greater_cos(cos_sim_jsma, eta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate using just norm\n",
    "gamma = .02\n",
    "print ('Regular: %.4f' % ( smaller_norm(grads_reg_norms, gamma)))\n",
    "print ('FGSM:  %.4f' % ( smaller_norm(grads_fgsm_norms, gamma)))\n",
    "print ('BIM-A:  %.4f' % ( smaller_norm(grads_bim_a_norms, gamma)))\n",
    "print ('BIM-B:  %.4f' % ( smaller_norm(grads_bim_b_norms, gamma)))\n",
    "print ('CW: %.4f' % ( smaller_norm(grads_cw_norms, gamma)))\n",
    "print ('DF: %.4f' % ( smaller_norm(grads_df_norms, gamma)))\n",
    "print ('JSMA: %.4f' % ( smaller_norm(grads_jsma_norms, gamma)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use both cos and norm\n",
    "print ('Regular: %.4f' % ( cos_and_norm_sep(cos_sim_reg, grads_reg_norms, eta, gamma)))\n",
    "print ('FGSM:  %.4f' % ( cos_and_norm_sep(cos_sim_fgsm, grads_fgsm_norms, eta, gamma)))\n",
    "print ('BIM-A:  %.4f' % ( cos_and_norm_sep(cos_sim_bim_a, grads_bim_a_norms, eta, gamma)))\n",
    "print ('BIM-B:  %.4f' % ( cos_and_norm_sep(cos_sim_bim_b, grads_bim_b_norms, eta, gamma)))\n",
    "print ('CW: %.4f' % ( cos_and_norm_sep(cos_sim_cw, grads_cw_norms, eta, gamma)))\n",
    "print ('DF: %.4f' % ( cos_and_norm_sep(cos_sim_df, grads_df_norms, eta, gamma)))\n",
    "print ('JSMA: %.4f' % ( cos_and_norm_sep(cos_sim_jsma, grads_jsma_norms, eta, gamma)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WHITEBOX ATTACKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Guide Indices for P1 attacks\n",
    "guide_indices_reg = list()\n",
    "reg_filter = np.arange(num_test_samples)\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images using max cosine similarity images\n",
    "for i in range(num_test_samples):\n",
    "    guide_img_idx = get_guide_idx(model,idx_filter=reg_filter,data_indices=data_indices,cos_sim=cos_sim_reg, idx=i)\n",
    "    guide_indices_reg.append(guide_img_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 Phase Attacks\n",
    "fgsm_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM-WB', eps=eps, x_tar=model.train_data[guide_indices_reg], y_tar = model.train_labels[guide_indices_reg])\n",
    "bim_a_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='BIM-A-WB', eps=eps, x_tar=model.train_data[guide_indices_reg], y_tar = model.train_labels[guide_indices_reg])\n",
    "bim_b_wb_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='BIM-B-WB', eps=eps, x_tar=model.train_data[guide_indices_reg], y_tar = model.train_labels[guide_indices_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 Phase CW Attack\n",
    "p1_cw_data = model.generate_perturbed_data(model.test_data[test_indices], y_tar=model.train_labels[guide_indices_reg],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_reg], use_cos_norm_reg=True, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WB Attacks - Generate Guide indices for FGSM, BIM-A, BIM-B, and CW for P2 attack\n",
    "guide_indices_fgsm = list()\n",
    "guide_indices_bim_a = list()\n",
    "guide_indices_bim_b = list()\n",
    "guide_indices_cw = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images using max cosine similarity images\n",
    "for i in range(num_test_samples):\n",
    "    \n",
    "    #Only use misclassified images\n",
    "    if i not in fgsm_idx:\n",
    "        continue\n",
    "    \n",
    "    #Choose the max similarity image as the guide image\n",
    "    else:\n",
    "        guide_img_idx_fgsm = get_guide_idx(model,idx_filter=fgsm_idx,cos_sim=cos_sim_fgsm,data_indices=data_indices, idx=i)\n",
    "        \n",
    "    if i not in bim_a_idx:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        guide_img_idx_bim_a = get_guide_idx(model,idx_filter=bim_a_idx,cos_sim=cos_sim_bim_a,data_indices=data_indices, idx=i)  \n",
    "    \n",
    "    if i not in bim_b_idx:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        guide_img_idx_bim_b = get_guide_idx(model,idx_filter=bim_b_idx,cos_sim=cos_sim_bim_b,data_indices=data_indices, idx=i) \n",
    "            \n",
    "    if i not in cw_idx:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        guide_img_idx_cw = get_guide_idx(model,idx_filter=cw_idx,cos_sim=cos_sim_cw,data_indices=data_indices, idx=i)  \n",
    "\n",
    "        \n",
    "    guide_indices_fgsm.append(guide_img_idx_fgsm)\n",
    "    guide_indices_bim_a.append(guide_img_idx_bim_a)\n",
    "    guide_indices_bim_b.append(guide_img_idx_bim_b)\n",
    "    guide_indices_cw.append(guide_img_idx_cw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CW Phase 2: Optimize for higher cosine sim and smaller norm of gradient vector\n",
    "p2_cw_data = model.generate_perturbed_data(cw_data_fil, y_tar=cw_labels_fil, seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_cw], use_cos_norm_reg=True, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Whitebox CW 2 Phase attack with FGSM, BIM-a/b guide images\n",
    "p2_cw_fgsm_data = model.generate_perturbed_data(fgsm_data_fil, y_tar=fgsm_labels_fil,seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_fgsm], use_cos_norm_reg=True, eps=eps)\n",
    "p2_cw_bim_a_data = model.generate_perturbed_data(bim_a_data_fil, y_tar=bim_a_labels_fil,seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_bim_a], use_cos_norm_reg=True, eps=eps)\n",
    "p2_cw_bim_b_data = model.generate_perturbed_data(bim_b_data_fil, y_tar=bim_a_labels_fil,seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices_bim_b], use_cos_norm_reg=True, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='mnist', seed=SEED)\n",
    "model.load_model(model_save_path, weights_save_path)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Model Accuracy FGSM-WB: %.5f' % (model.model.evaluate(fgsm_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-A WB: %.5f' % (model.model.evaluate(bim_a_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy BIM-B WB: %.5f' % (model.model.evaluate(bim_b_wb_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P1 CW: %.5f' % (model.model.evaluate(p1_cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 CW: %.5f' % (model.model.evaluate(p2_cw_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 FGSM: %.5f' % (model.model.evaluate(p2_cw_fgsm_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 BIM-A: %.5f' % (model.model.evaluate(p2_cw_bim_a_data,model.test_labels[test_indices])[1]))\n",
    "print ('Model Accuracy P2 BIM-B %.5f' % (model.model.evaluate(p2_cw_bim_b_data,model.test_labels[test_indices])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 10)\n",
    "print ('Regular: ')\n",
    "visualize(reg_data[x_vis].reshape(-1,*input_shape), 10,)\n",
    "print ('FGSM-WB: ')\n",
    "visualize(fgsm_wb_data[x_vis].reshape(-1,*input_shape), 10, '../figures/fgsm-wb-cifar2')\n",
    "print ('BIM-A-WB: ')\n",
    "visualize(bim_a_wb_data[x_vis].reshape(-1,*input_shape), 10, '../figures/bim-a-wb-cifar2')\n",
    "print ('BIM-B-WB: ')\n",
    "visualize(bim_b_wb_data[x_vis].reshape(-1,*input_shape), 10, '../figures/bim-b-wb-cifar2')\n",
    "print ('P1-CW: ')\n",
    "visualize(p1_cw_data[x_vis].reshape(-1,*input_shape), 10, '../figures/p1-cw-cifar2')\n",
    "print ('P2-CW: ')\n",
    "visualize(p2_cw_data[x_vis].reshape(-1,*input_shape), 10, '../figures/p2-cw-cifar2')\n",
    "print ('P2-FGSM: ')\n",
    "visualize(p2_cw_fgsm_data[x_vis].reshape(-1,*input_shape), 10, '../figures/p2-fgsm-cifar2')\n",
    "print ('P2-BIM-A')\n",
    "visualize(p2_cw_bim_a_data[x_vis].reshape(-1,*input_shape), 10, '../figures/p2-bim-a-cifar2')\n",
    "print ('P2-BIM-B')\n",
    "visualize(p2_cw_bim_b_data[x_vis].reshape(-1,*input_shape), 10, '../figures/p2-bim-b-cifar2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "fgsm_wb_preds = model.model.predict(fgsm_wb_data.reshape(-1,*input_shape))\n",
    "bim_a_wb_preds = model.model.predict(bim_a_wb_data.reshape(-1,*input_shape))\n",
    "bim_b_wb_preds = model.model.predict(bim_a_wb_data.reshape(-1,*input_shape))\n",
    "p1_cw_preds = model.model.predict(p1_cw_data.reshape(-1,*input_shape))\n",
    "p2_cw_preds = model.model.predict(p2_cw_data.reshape(-1,*input_shape))\n",
    "p2_cw_fgsm_preds = model.model.predict(p2_cw_fgsm_data.reshape(-1,*input_shape))\n",
    "p2_cw_bim_a_preds = model.model.predict(p2_cw_bim_a_data.reshape(-1,*input_shape))\n",
    "p2_cw_bim_b_preds = model.model.predict(p2_cw_bim_b_data.reshape(-1,*input_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "fgsm_wb_labels = preds_to_labels(fgsm_wb_preds)\n",
    "bim_a_wb_labels = preds_to_labels(bim_a_wb_preds)\n",
    "bim_b_wb_labels = preds_to_labels(bim_b_wb_preds)\n",
    "p1_cw_labels = preds_to_labels(p1_cw_preds)\n",
    "p2_cw_labels = preds_to_labels(p2_cw_preds)\n",
    "p2_cw_fgsm_labels = preds_to_labels(p2_cw_fgsm_preds)\n",
    "p2_cw_bim_a_labels = preds_to_labels(p2_cw_bim_a_preds)\n",
    "p2_cw_bim_b_labels = preds_to_labels(p2_cw_bim_b_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check which points are actually adversarial and select those\n",
    "fgsm_wb_idx =  np.where(np.argmax(fgsm_wb_preds, axis=1) != true_preds)[0]\n",
    "bim_a_wb_idx = np.where(np.argmax(bim_a_wb_preds, axis=1) != true_preds)[0]\n",
    "bim_b_wb_idx = np.where(np.argmax(bim_b_wb_preds, axis=1) != true_preds)[0]\n",
    "p1_cw_idx = np.where(np.argmax(p1_cw_preds, axis=1) != true_preds)[0]\n",
    "p2_cw_idx = np.where(np.argmax(p2_cw_preds, axis=1) != true_preds)[0]\n",
    "p2_cw_fgsm_idx = np.where(np.argmax(p2_cw_fgsm_preds, axis=1) != true_preds)[0]\n",
    "p2_cw_bim_a_idx = np.where(np.argmax(p2_cw_bim_a_preds, axis=1) != true_preds)[0]\n",
    "p2_cw_bim_b_idx = np.where(np.argmax(p2_cw_bim_b_preds, axis=1) != true_preds)[0]\n",
    "\n",
    "#Filter data points to be used for similarity\n",
    "fgsm_wb_data_fil = fgsm_wb_data[fgsm_wb_idx]\n",
    "bim_a_wb_data_fil = bim_a_wb_data[bim_a_wb_idx]\n",
    "bim_b_wb_data_fil = bim_b_wb_data[bim_b_wb_idx]\n",
    "p1_cw_data_fil = p1_cw_data[p1_cw_idx]\n",
    "p2_cw_data_fil = p2_cw_data[p2_cw_idx]\n",
    "p2_cw_fgsm_data_fil = p2_cw_fgsm_data[p2_cw_fgsm_idx]\n",
    "p2_cw_bim_a_data_fil = p2_cw_bim_a_data[p2_cw_bim_a_idx]\n",
    "p2_cw_bim_b_data_fil = p2_cw_bim_b_data[p2_cw_bim_b_idx]\n",
    "\n",
    "#Filter labels to be used\n",
    "fgsm_wb_labels_fil = fgsm_wb_labels[fgsm_wb_idx]\n",
    "bim_a_wb_labels_fil = bim_a_wb_labels[bim_a_wb_idx]\n",
    "bim_b_wb_labels_fil = bim_b_wb_labels[bim_b_wb_idx]\n",
    "p1_cw_labels_fil = p1_cw_labels[p1_cw_idx]\n",
    "p2_cw_labels_fil = p2_cw_labels[p2_cw_idx]\n",
    "p2_cw_fgsm_labels_fil = p2_cw_fgsm_labels[p2_cw_fgsm_idx]\n",
    "p2_cw_bim_a_labels_fil = p2_cw_bim_a_labels[p2_cw_bim_a_idx]\n",
    "p2_cw_bim_b_labels_fil = p2_cw_bim_b_labels[p2_cw_bim_b_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get distortion (Prints nan if no sample was adversarial)\n",
    "print ('FGSM-WB: %.5f' % (avg_l2_dist(reg_data[fgsm_wb_idx], fgsm_wb_data_fil)))\n",
    "print ('BIM-A-WB: %.5f' % (avg_l2_dist(reg_data[bim_a_wb_idx], bim_a_wb_data_fil)))\n",
    "print ('BIM-B-WB: %.5f' % (avg_l2_dist(reg_data[bim_b_wb_idx], bim_b_wb_data_fil)))\n",
    "print ('P1-CW: %.5f' % (avg_l2_dist(reg_data[p1_cw_idx], p1_cw_data_fil)))\n",
    "print ('P2-CW: %.5f' % (avg_l2_dist(reg_data[p2_cw_idx], p2_cw_data_fil)))\n",
    "print ('P2-CW FGSM: %.5f' % (avg_l2_dist(reg_data[p2_cw_fgsm_idx], p2_cw_fgsm_data_fil)))\n",
    "print ('P2-CW BIM A: %.5f' % (avg_l2_dist(reg_data[p2_cw_bim_a_idx], p2_cw_bim_a_data_fil)))\n",
    "print ('P2-CW BIM B: %.5f' % (avg_l2_dist(reg_data[p2_cw_bim_b_idx], p2_cw_bim_b_data_fil)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity and norms\n",
    "grads_fgsm_wb_norms, cos_sim_fgsm_wb = norms_and_cos(model, fgsm_wb_data_fil, fgsm_wb_labels_fil, grads_train)\n",
    "grads_bim_a_wb_norms, cos_sim_bim_a_wb = norms_and_cos(model, bim_a_wb_data_fil, bim_a_wb_labels_fil, grads_train)\n",
    "grads_bim_b_wb_norms, cos_sim_bim_b_wb = norms_and_cos(model, bim_b_wb_data_fil, bim_b_wb_labels_fil, grads_train)\n",
    "grads_p1_cw_norms, cos_sim_p1_cw = norms_and_cos(model, p1_cw_data_fil, p1_cw_labels_fil, grads_train)\n",
    "grads_p2_cw_norms, cos_sim_p2_cw = norms_and_cos(model, p2_cw_data_fil, p2_cw_labels_fil, grads_train)\n",
    "grads_p2_cw_fgsm_norms, cos_sim_p2_cw_fgsm = norms_and_cos(model, p2_cw_fgsm_data_fil, p2_cw_fgsm_labels_fil, grads_train)\n",
    "grads_p2_cw_bim_a_norms, cos_sim_p2_cw_bim_a = norms_and_cos(model, p2_cw_bim_a_data_fil, p2_cw_bim_a_labels_fil, grads_train)\n",
    "grads_p2_cw_bim_b_norms, cos_sim_p2_cw_bim_b = norms_and_cos(model, p2_cw_bim_b_data_fil, p2_cw_bim_b_labels_fil, grads_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THRESHOLDING FOR WHITEBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having cos sim smaller\n",
    "print ('FGSM-WB:  %.4f' % ( comp_cos(cos_sim_fgsm_wb, cos_sim_reg[fgsm_wb_idx])))\n",
    "print ('BIM-A-WB:  %.4f' % ( comp_cos(cos_sim_bim_a_wb, cos_sim_reg[bim_a_wb_idx])))\n",
    "print ('BIM-B-WB:  %.4f' % ( comp_cos(cos_sim_bim_b_wb, cos_sim_reg[bim_b_wb_idx])))\n",
    "print ('1 Phase CW:  %.4f' % ( comp_cos(cos_sim_p1_cw, cos_sim_reg[p1_cw_idx])))\n",
    "print ('2 Phase CW:  %.4f' % ( comp_cos(cos_sim_p2_cw, cos_sim_reg[p2_cw_idx])))\n",
    "print ('2 Phase CW FGSM:  %.4f' % ( comp_cos(cos_sim_p2_cw_fgsm, cos_sim_reg[p2_cw_fgsm_idx])))\n",
    "print ('2 Phase CW BIM A:  %.4f' % ( comp_cos(cos_sim_p2_cw_bim_a, cos_sim_reg[p2_cw_bim_a_idx])))\n",
    "print ('2 Phase CW BIM B:  %.4f' % ( comp_cos(cos_sim_p2_cw_bim_b, cos_sim_reg[p2_cw_bim_b_idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ratio of perturbed samples having norm greater\n",
    "print ('FGSM-WB:  %.4f' % ( comp_norm(grads_fgsm_wb_norms, grads_reg_norms[fgsm_wb_idx])))\n",
    "print ('BIM-A-WB:  %.4f' % ( comp_norm(grads_bim_a_wb_norms, grads_reg_norms[bim_a_wb_idx])))\n",
    "print ('BIM-B-WB:  %.4f' % ( comp_norm(grads_bim_b_wb_norms, grads_reg_norms[bim_b_wb_idx])))\n",
    "print ('1 Phase CW: %.4f' % ( comp_norm(grads_p1_cw_norms, grads_reg_norms[p1_cw_idx])))\n",
    "print ('2 Phase CW: %.4f' % ( comp_norm(grads_p2_cw_norms, grads_reg_norms[p2_cw_idx])))\n",
    "print ('2 Phase CW FGSM: %.4f' % ( comp_norm(grads_p2_cw_fgsm_norms, grads_reg_norms[p2_cw_fgsm_idx])))\n",
    "print ('2 Phase CW BIM A: %.4f' % ( comp_norm(grads_p2_cw_bim_a_norms, grads_reg_norms[p2_cw_bim_a_idx])))\n",
    "print ('2 Phase CW BIM B: %.4f' % ( comp_norm(grads_p2_cw_bim_b_norms, grads_reg_norms[p2_cw_bim_b_idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Using Cos Sim\n",
    "print ('REG:  %.4f' % ( greater_cos(cos_sim_reg, eta)))\n",
    "print ('FGSM-WB:  %.4f' % ( greater_cos(cos_sim_fgsm_wb, eta)))\n",
    "print ('BIM-A-WB:  %.4f' % ( greater_cos(cos_sim_bim_a_wb, eta)))\n",
    "print ('BIM-B-WB:  %.4f' % ( greater_cos(cos_sim_bim_b_wb, eta)))\n",
    "print ('1 Phase CW:  %.4f' % ( greater_cos(cos_sim_p1_cw, eta)))        \n",
    "print ('2 Phase CW:  %.4f' % ( greater_cos(cos_sim_p2_cw, eta)))\n",
    "print ('2 Phase CW FGSM:  %.4f' % ( greater_cos(cos_sim_p2_cw_fgsm, eta)))       \n",
    "print ('2 Phase CW BIM-A:  %.4f' % ( greater_cos(cos_sim_p2_cw_bim_a, eta)))      \n",
    "print ('2 Phase CW BIM-B:  %.4f' % ( greater_cos(cos_sim_p2_cw_bim_b, eta)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate using just norm\n",
    "print ('Regular: %.4f' % ( smaller_norm(grads_reg_norms, gamma)))\n",
    "print ('FGSM-WB:  %.4f' % ( smaller_norm(grads_fgsm_wb_norms, gamma)))\n",
    "print ('BIM-A-WB:  %.4f' % ( smaller_norm(grads_bim_a_wb_norms, gamma)))\n",
    "print ('BIM-B-WB:  %.4f' % ( smaller_norm(grads_bim_b_wb_norms, gamma)))\n",
    "print ('1 Phase CW:  %.4f' % ( smaller_norm(grads_p1_cw_norms, gamma)))        \n",
    "print ('2 Phase CW:  %.4f' % ( smaller_norm(grads_p2_cw_norms, gamma)))\n",
    "print ('2 Phase CW FGSM:  %.4f' % ( smaller_norm(grads_p2_cw_fgsm_norms, gamma)))       \n",
    "print ('2 Phase CW BIM-A:  %.4f' % ( smaller_norm(grads_p2_cw_bim_a_norms, gamma)))      \n",
    "print ('2 Phase CW BIM-B:  %.4f' % ( smaller_norm(grads_p2_cw_bim_b_norms, gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use both cos and norm\n",
    "print ('Regular: %.4f' % ( cos_and_norm_sep(cos_sim_reg, grads_reg_norms, eta, gamma)))\n",
    "print ('FGSM-WB:  %.4f' % ( cos_and_norm_sep(cos_sim_fgsm_wb, grads_fgsm_wb_norms, eta, gamma)))\n",
    "print ('BIM-A-WB:  %.4f' % ( cos_and_norm_sep(cos_sim_bim_a_wb, grads_bim_a_wb_norms, eta, gamma)))\n",
    "print ('BIM-B-WB:  %.4f' % ( cos_and_norm_sep(cos_sim_bim_b_wb, grads_bim_b_wb_norms, eta, gamma)))\n",
    "print ('1 Phase CW: %.4f' % ( cos_and_norm_sep(cos_sim_p1_cw, grads_p1_cw_norms, eta, gamma)))\n",
    "print ('2 Phase CW: %.4f' % ( cos_and_norm_sep(cos_sim_p2_cw, grads_p2_cw_norms, eta, gamma)))\n",
    "print ('2 Phase CW FGSM: %.4f' % ( cos_and_norm_sep(cos_sim_p2_cw_fgsm, grads_p2_cw_fgsm_norms, eta, gamma)))\n",
    "print ('2 Phase CW BIM A: %.4f' % ( cos_and_norm_sep(cos_sim_p2_cw_bim_a, grads_p2_cw_bim_a_norms, eta, gamma)))\n",
    "print ('2 Phase CW BIM B: %.4f' % ( cos_and_norm_sep(cos_sim_p2_cw_bim_b, grads_p2_cw_bim_b_norms, eta, gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(grads_reg_norms[:250])), grads_reg_norms[:250], 'x', label='Original', ms=6, color='black')\n",
    "plt.plot(np.arange(len(grads_fgsm_norms[:250])), grads_fgsm_norms[:250], 'x', label='FGSM', ms=3)\n",
    "plt.plot(np.arange(len(grads_bim_a_norms[:250])), grads_bim_a_norms[:250], 'x', label='BIM-A', ms=3)\n",
    "plt.plot(np.arange(len(grads_bim_b_norms[:250])), grads_bim_b_norms[:250], 'x', label='BIM-B', ms=3, color='red')\n",
    "plt.plot(np.arange(len(grads_cw_norms[:250])), grads_cw_norms[:250], 'x', label='C&W', ms=3)\n",
    "plt.plot(np.arange(len(grads_df_norms[:250])), grads_df_norms[:250], 'x', label='DF', ms=3)\n",
    "plt.plot(np.arange(len(grads_jsma_norms[:250])), grads_jsma_norms[:250], 'x', label='JSMA', ms=3)\n",
    "#plt.xlabel('Transformed', fontsize=12)\n",
    "plt.ylabel('Norm', fontsize=12)\n",
    "plt.title('Norms of Gradient Vectors')\n",
    "plt.legend(loc=\"upper right\", fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_norm.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(cos_sim_reg[:250])), np.max(cos_sim_reg[:250], axis=1), 'x', label='Original', ms=3, color='black')\n",
    "plt.plot(np.arange(len(cos_sim_fgsm[:250])), np.max(cos_sim_fgsm[:250], axis=1), 'x', label='FGSM', ms=3)\n",
    "plt.plot(np.arange(len(cos_sim_bim_a[:250])), np.max(cos_sim_bim_a[:250], axis=1), 'x', label='BIM-A', ms=3)\n",
    "plt.plot(np.arange(len(cos_sim_bim_b[:250])), np.max(cos_sim_bim_b[:250], axis=1), 'x', label='BIM-B', ms=3, color='red')\n",
    "plt.plot(np.arange(len(cos_sim_cw[:250])), np.max(cos_sim_cw[:250], axis=1), 'x', label='C&W', ms=3)\n",
    "plt.plot(np.arange(len(cos_sim_df[:250])), np.max(cos_sim_df[:250], axis=1), 'x', label='DF',ms=3)\n",
    "plt.plot(np.arange(len(cos_sim_jsma[:250])), np.max(cos_sim_jsma[:250], axis=1), 'x', label='JSMA',ms=3)\n",
    "#plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "         # fancybox=True, shadow=True, ncol=3)\n",
    "#plt.xlabel('Transformed', fontsize=12)\n",
    "plt.ylabel('Cos Sim', fontsize=12)\n",
    "plt.title('Cosine Similarity of Gradient Vectors')\n",
    "plt.legend(loc=\"lower right\", fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_cos.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
