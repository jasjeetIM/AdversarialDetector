{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture state\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('./src/')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from influence.neural_network import NeuralNetwork\n",
    "from influence.cnn import CNN\n",
    "import influence.util as util\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73257 samples, validate on 13016 samples\n",
      "Epoch 1/50\n",
      "73257/73257 [==============================] - 97s 1ms/step - loss: 3.5038 - acc: 0.3732 - val_loss: 1.3914 - val_acc: 0.6627\n",
      "Epoch 2/50\n",
      "73257/73257 [==============================] - 95s 1ms/step - loss: 0.9956 - acc: 0.7979 - val_loss: 0.8350 - val_acc: 0.8376\n",
      "Epoch 3/50\n",
      "73257/73257 [==============================] - 95s 1ms/step - loss: 0.7932 - acc: 0.8440 - val_loss: 0.8157 - val_acc: 0.8481\n",
      "Epoch 4/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.7206 - acc: 0.8570 - val_loss: 0.7666 - val_acc: 0.8434\n",
      "Epoch 5/50\n",
      "73257/73257 [==============================] - 95s 1ms/step - loss: 0.6702 - acc: 0.8681 - val_loss: 0.7771 - val_acc: 0.8328\n",
      "Epoch 6/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.6397 - acc: 0.8746 - val_loss: 0.5978 - val_acc: 0.8868\n",
      "Epoch 7/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.6242 - acc: 0.8778 - val_loss: 0.6238 - val_acc: 0.8735\n",
      "Epoch 8/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.6032 - acc: 0.8833 - val_loss: 0.7777 - val_acc: 0.8360\n",
      "Epoch 9/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.5910 - acc: 0.8848 - val_loss: 0.5535 - val_acc: 0.8993\n",
      "Epoch 10/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.5747 - acc: 0.8885 - val_loss: 0.5703 - val_acc: 0.8890\n",
      "Epoch 11/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.5670 - acc: 0.8910 - val_loss: 0.5747 - val_acc: 0.8843\n",
      "Epoch 12/50\n",
      "73257/73257 [==============================] - 94s 1ms/step - loss: 0.5555 - acc: 0.8936 - val_loss: 0.5552 - val_acc: 0.8934\n",
      "Epoch 13/50\n",
      "73257/73257 [==============================] - 93s 1ms/step - loss: 0.5437 - acc: 0.8960 - val_loss: 0.6279 - val_acc: 0.8711\n",
      "Epoch 14/50\n",
      "73257/73257 [==============================] - 93s 1ms/step - loss: 0.5372 - acc: 0.8982 - val_loss: 0.5216 - val_acc: 0.9036\n",
      "Epoch 15/50\n",
      "73257/73257 [==============================] - 93s 1ms/step - loss: 0.5284 - acc: 0.9006 - val_loss: 0.5336 - val_acc: 0.8979\n",
      "Epoch 16/50\n",
      " 2432/73257 [..............................] - ETA: 1:28 - loss: 0.4821 - acc: 0.9202"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'SVHN'\n",
    "model_save_path = './trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = './trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='svhn')\n",
    "epochs = 50\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 10000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_test_samples_per_class = 100\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy')\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM')\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Whitebox CW Attack\n",
    "#First get guide images\n",
    "guide_indices = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images for modified CW attacks\n",
    "for idx in test_indices:\n",
    "    label = np.argmax(model.test_labels[idx])\n",
    "    #Add 1 to the label mod 10 to get a target label\n",
    "    mod_label = (label + 1) % 10\n",
    "    #Get a test point with the target label\n",
    "    guide_imgs_indices = np.where(model.train_labels[:,mod_label] == 1)[0]\n",
    "    #Choose a guide image\n",
    "    guide_img_idx = np.random.choice(guide_imgs_indices, 1)[0]\n",
    "    guide_indices.append(guide_img_idx)\n",
    "\n",
    "\n",
    "#1 Phase Attack\n",
    "p1_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True)\n",
    "\n",
    "#2 Phase Attack\n",
    "#Phase 1: Generate targeted adversarial images\n",
    "tar_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, use_cos_norm_reg=False)\n",
    "#Phase 2: Optimize for higher cosine sim and smaller norm\n",
    "p2_cw_data = model.generate_perturbed_data(tar_cw_data, model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='svhn')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(32,32,3))\n",
    "visualize(noisy_data[x_vis].reshape(32,32,3))\n",
    "visualize(fgsm_data[x_vis].reshape(32,32,3))\n",
    "visualize(bim_data[x_vis].reshape(32,32,3))\n",
    "visualize(cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p1_cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p2_cw_data[x_vis].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,32,32,3))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,32,32,3))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,32,32,3))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,32,32,3))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,32,32,3))\n",
    "p1_cw_preds = model.model.predict(p1_cw_data.reshape(-1,32,32,3))\n",
    "p2_cw_preds = model.model.predict(p2_cw_data.reshape(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1\n",
    "\n",
    "p1_cw_labels = np.zeros(p1_cw_preds.shape)\n",
    "p1_cw_labels[np.arange(num_test_samples),np.argmax(p1_cw_preds, axis=1)] = 1\n",
    "\n",
    "p2_cw_labels = np.zeros(p2_cw_preds.shape)\n",
    "p2_cw_labels[np.arange(num_test_samples),np.argmax(p2_cw_preds, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))\n",
    "print (np.argmax(p1_cw_preds, axis=1))\n",
    "print (np.argmax(p2_cw_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "grads_p1_cw = model.get_gradients_wrt_params(p1_cw_data, p1_cw_labels)\n",
    "grads_p2_cw = model.get_gradients_wrt_params(p2_cw_data, p2_cw_labels)\n",
    "\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "grads_p1_cw_nm = normalize(grads_p1_cw)\n",
    "grads_p2_cw_nm = normalize(grads_p2_cw)\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()\n",
    "grads_p1_cw_norms = np.sqrt(np.dot(grads_p1_cw, grads_p1_cw.T)).diagonal()\n",
    "grads_p2_cw_norms = np.sqrt(np.dot(grads_p2_cw, grads_p2_cw.T)).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p1_cw = np.dot(grads_p1_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p2_cw = np.dot(grads_p2_cw_nm, grads_train_nm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.81\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('1 Phase CW:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('2 Phase CW:  %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate using just norm\n",
    "gamma = 0.15\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use both cos and norm\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta and grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta and grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
