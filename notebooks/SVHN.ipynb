{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture state\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from models.neural_network import NeuralNetwork\n",
    "from models.cnn import CNN\n",
    "#from models.util import avg_l2_dist, visualize, normalize\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#Seed used for all calculations of training and test point indices \n",
    "SEED = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualization of samples\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    if image.shape[-1] == 1:\n",
    "        # image is in black and white\n",
    "        image = image[:, :, 0]\n",
    "        plt.imshow(image, cmap='Greys')\n",
    "    else:\n",
    "        # image is in color\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Normalize rows of a given matrix\n",
    "def normalize(matrix):\n",
    "    matrix_nm = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix_nm[i] = matrix[i]/np.linalg.norm(matrix[i]) \n",
    "    return matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22247242\n",
      "Train on 604388 samples, validate on 13016 samples\n",
      "Epoch 1/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.8540 - acc: 0.8480 - val_loss: 0.7491 - val_acc: 0.8638\n",
      "Epoch 2/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.5641 - acc: 0.9097 - val_loss: 0.6356 - val_acc: 0.8848\n",
      "Epoch 3/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.5155 - acc: 0.9192 - val_loss: 0.5934 - val_acc: 0.8973\n",
      "Epoch 4/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.4850 - acc: 0.9250 - val_loss: 0.5619 - val_acc: 0.9033\n",
      "Epoch 5/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.4547 - acc: 0.9291 - val_loss: 0.5317 - val_acc: 0.9072\n",
      "Epoch 6/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.4307 - acc: 0.9325 - val_loss: 0.5062 - val_acc: 0.9100\n",
      "Epoch 7/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.4173 - acc: 0.9345 - val_loss: 0.4939 - val_acc: 0.9140\n",
      "Epoch 8/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.4096 - acc: 0.9359 - val_loss: 0.4914 - val_acc: 0.9130\n",
      "Epoch 9/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.4037 - acc: 0.9369 - val_loss: 0.4948 - val_acc: 0.9121\n",
      "Epoch 10/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3987 - acc: 0.9380 - val_loss: 0.4770 - val_acc: 0.9163\n",
      "Epoch 11/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3929 - acc: 0.9395 - val_loss: 0.4828 - val_acc: 0.9134\n",
      "Epoch 12/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3893 - acc: 0.9404 - val_loss: 0.4694 - val_acc: 0.9184\n",
      "Epoch 13/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3865 - acc: 0.9410 - val_loss: 0.4630 - val_acc: 0.9201\n",
      "Epoch 14/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3814 - acc: 0.9418 - val_loss: 0.4657 - val_acc: 0.9182\n",
      "Epoch 15/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3777 - acc: 0.9425 - val_loss: 0.4714 - val_acc: 0.9155\n",
      "Epoch 16/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3742 - acc: 0.9431 - val_loss: 0.4528 - val_acc: 0.9245\n",
      "Epoch 17/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3709 - acc: 0.9435 - val_loss: 0.4757 - val_acc: 0.9134\n",
      "Epoch 18/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3685 - acc: 0.9441 - val_loss: 0.4630 - val_acc: 0.9208\n",
      "Epoch 19/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3668 - acc: 0.9445 - val_loss: 0.4427 - val_acc: 0.9232\n",
      "Epoch 20/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3637 - acc: 0.9446 - val_loss: 0.4423 - val_acc: 0.9233\n",
      "Epoch 21/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3612 - acc: 0.9456 - val_loss: 0.4386 - val_acc: 0.9242\n",
      "Epoch 22/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3596 - acc: 0.9453 - val_loss: 0.4372 - val_acc: 0.9262\n",
      "Epoch 23/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3575 - acc: 0.9458 - val_loss: 0.4382 - val_acc: 0.9243\n",
      "Epoch 24/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3554 - acc: 0.9462 - val_loss: 0.4375 - val_acc: 0.9261\n",
      "Epoch 25/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3536 - acc: 0.9461 - val_loss: 0.4435 - val_acc: 0.9212\n",
      "Epoch 26/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3536 - acc: 0.9464 - val_loss: 0.4317 - val_acc: 0.9242\n",
      "Epoch 27/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3516 - acc: 0.9467 - val_loss: 0.4311 - val_acc: 0.9295\n",
      "Epoch 28/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3497 - acc: 0.9473 - val_loss: 0.4285 - val_acc: 0.9264\n",
      "Epoch 29/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3490 - acc: 0.9473 - val_loss: 0.4306 - val_acc: 0.9245\n",
      "Epoch 30/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3487 - acc: 0.9475 - val_loss: 0.4383 - val_acc: 0.9232\n",
      "Epoch 31/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3472 - acc: 0.9482 - val_loss: 0.4266 - val_acc: 0.9261\n",
      "Epoch 32/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3470 - acc: 0.9476 - val_loss: 0.4221 - val_acc: 0.9284\n",
      "Epoch 33/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3452 - acc: 0.9482 - val_loss: 0.4243 - val_acc: 0.9276\n",
      "Epoch 34/200\n",
      "604388/604388 [==============================] - 179s 296us/step - loss: 0.3437 - acc: 0.9481 - val_loss: 0.4266 - val_acc: 0.9276\n",
      "Epoch 35/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3438 - acc: 0.9481 - val_loss: 0.4376 - val_acc: 0.9220\n",
      "Epoch 36/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3431 - acc: 0.9486 - val_loss: 0.4250 - val_acc: 0.9291\n",
      "Epoch 37/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3426 - acc: 0.9487 - val_loss: 0.4263 - val_acc: 0.9263\n",
      "Epoch 38/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3428 - acc: 0.9487 - val_loss: 0.4201 - val_acc: 0.9286\n",
      "Epoch 39/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3409 - acc: 0.9489 - val_loss: 0.4117 - val_acc: 0.9296\n",
      "Epoch 40/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3409 - acc: 0.9489 - val_loss: 0.4224 - val_acc: 0.9267\n",
      "Epoch 41/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3402 - acc: 0.9490 - val_loss: 0.4164 - val_acc: 0.9265\n",
      "Epoch 42/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3385 - acc: 0.9493 - val_loss: 0.4149 - val_acc: 0.9282\n",
      "Epoch 43/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3388 - acc: 0.9495 - val_loss: 0.4057 - val_acc: 0.9301\n",
      "Epoch 44/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3381 - acc: 0.9495 - val_loss: 0.4212 - val_acc: 0.9286\n",
      "Epoch 45/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3379 - acc: 0.9494 - val_loss: 0.4153 - val_acc: 0.9286\n",
      "Epoch 46/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3363 - acc: 0.9495 - val_loss: 0.4262 - val_acc: 0.9268\n",
      "Epoch 47/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3357 - acc: 0.9495 - val_loss: 0.4147 - val_acc: 0.9277\n",
      "Epoch 48/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3356 - acc: 0.9498 - val_loss: 0.4283 - val_acc: 0.9230\n",
      "Epoch 49/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3358 - acc: 0.9497 - val_loss: 0.4237 - val_acc: 0.9292\n",
      "Epoch 50/200\n",
      "604388/604388 [==============================] - 181s 300us/step - loss: 0.3337 - acc: 0.9503 - val_loss: 0.4165 - val_acc: 0.9266\n",
      "Epoch 51/200\n",
      "604388/604388 [==============================] - 181s 299us/step - loss: 0.3343 - acc: 0.9500 - val_loss: 0.4272 - val_acc: 0.9256\n",
      "Epoch 52/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3342 - acc: 0.9501 - val_loss: 0.4224 - val_acc: 0.9264\n",
      "Epoch 53/200\n",
      "604388/604388 [==============================] - 179s 296us/step - loss: 0.3337 - acc: 0.9501 - val_loss: 0.4202 - val_acc: 0.9257\n",
      "Epoch 54/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3322 - acc: 0.9505 - val_loss: 0.4113 - val_acc: 0.9307\n",
      "Epoch 55/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3319 - acc: 0.9503 - val_loss: 0.4112 - val_acc: 0.9294\n",
      "Epoch 56/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3320 - acc: 0.9501 - val_loss: 0.4075 - val_acc: 0.9312\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3312 - acc: 0.9502 - val_loss: 0.4141 - val_acc: 0.9282\n",
      "Epoch 58/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3309 - acc: 0.9503 - val_loss: 0.4160 - val_acc: 0.9301\n",
      "Epoch 59/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3307 - acc: 0.9504 - val_loss: 0.4101 - val_acc: 0.9267\n",
      "Epoch 60/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3305 - acc: 0.9504 - val_loss: 0.4163 - val_acc: 0.9269\n",
      "Epoch 61/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3294 - acc: 0.9504 - val_loss: 0.4229 - val_acc: 0.9230\n",
      "Epoch 62/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3289 - acc: 0.9507 - val_loss: 0.4347 - val_acc: 0.9202\n",
      "Epoch 63/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3289 - acc: 0.9508 - val_loss: 0.4021 - val_acc: 0.9312\n",
      "Epoch 64/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3285 - acc: 0.9507 - val_loss: 0.4206 - val_acc: 0.9298\n",
      "Epoch 65/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3289 - acc: 0.9506 - val_loss: 0.4080 - val_acc: 0.9292\n",
      "Epoch 66/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3284 - acc: 0.9507 - val_loss: 0.4218 - val_acc: 0.9284\n",
      "Epoch 67/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3273 - acc: 0.9508 - val_loss: 0.4111 - val_acc: 0.9267\n",
      "Epoch 68/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3270 - acc: 0.9511 - val_loss: 0.4040 - val_acc: 0.9320\n",
      "Epoch 69/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3262 - acc: 0.9511 - val_loss: 0.4093 - val_acc: 0.9291\n",
      "Epoch 70/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3267 - acc: 0.9509 - val_loss: 0.4191 - val_acc: 0.9302\n",
      "Epoch 71/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3260 - acc: 0.9511 - val_loss: 0.4089 - val_acc: 0.9302\n",
      "Epoch 72/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3254 - acc: 0.9512 - val_loss: 0.4059 - val_acc: 0.9285\n",
      "Epoch 73/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3256 - acc: 0.9509 - val_loss: 0.4145 - val_acc: 0.9306\n",
      "Epoch 74/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3251 - acc: 0.9510 - val_loss: 0.4205 - val_acc: 0.9256\n",
      "Epoch 75/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3233 - acc: 0.9516 - val_loss: 0.4117 - val_acc: 0.9288\n",
      "Epoch 76/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3257 - acc: 0.9514 - val_loss: 0.4116 - val_acc: 0.9279\n",
      "Epoch 77/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3236 - acc: 0.9514 - val_loss: 0.4249 - val_acc: 0.9233\n",
      "Epoch 78/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3240 - acc: 0.9512 - val_loss: 0.4093 - val_acc: 0.9276\n",
      "Epoch 79/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3233 - acc: 0.9515 - val_loss: 0.4083 - val_acc: 0.9311\n",
      "Epoch 80/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3215 - acc: 0.9520 - val_loss: 0.4030 - val_acc: 0.9302\n",
      "Epoch 81/200\n",
      "604388/604388 [==============================] - 179s 297us/step - loss: 0.3231 - acc: 0.9515 - val_loss: 0.3935 - val_acc: 0.9340\n",
      "Epoch 82/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3212 - acc: 0.9514 - val_loss: 0.4193 - val_acc: 0.9306\n",
      "Epoch 83/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3223 - acc: 0.9515 - val_loss: 0.3924 - val_acc: 0.9358\n",
      "Epoch 84/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3221 - acc: 0.9516 - val_loss: 0.4070 - val_acc: 0.9317\n",
      "Epoch 85/200\n",
      "604388/604388 [==============================] - 184s 304us/step - loss: 0.3217 - acc: 0.9516 - val_loss: 0.4061 - val_acc: 0.9307\n",
      "Epoch 86/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3223 - acc: 0.9517 - val_loss: 0.4023 - val_acc: 0.9309\n",
      "Epoch 87/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3200 - acc: 0.9522 - val_loss: 0.4328 - val_acc: 0.9225\n",
      "Epoch 88/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3205 - acc: 0.9520 - val_loss: 0.4020 - val_acc: 0.9314\n",
      "Epoch 89/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3204 - acc: 0.9522 - val_loss: 0.4021 - val_acc: 0.9302\n",
      "Epoch 90/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3196 - acc: 0.9520 - val_loss: 0.4108 - val_acc: 0.9285\n",
      "Epoch 91/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3197 - acc: 0.9517 - val_loss: 0.3982 - val_acc: 0.9303\n",
      "Epoch 92/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3188 - acc: 0.9522 - val_loss: 0.4064 - val_acc: 0.9298\n",
      "Epoch 93/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3180 - acc: 0.9521 - val_loss: 0.4034 - val_acc: 0.9312\n",
      "Epoch 94/200\n",
      "604388/604388 [==============================] - 179s 295us/step - loss: 0.3183 - acc: 0.9522 - val_loss: 0.4025 - val_acc: 0.9305\n",
      "Epoch 95/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3177 - acc: 0.9526 - val_loss: 0.4010 - val_acc: 0.9328\n",
      "Epoch 96/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3176 - acc: 0.9523 - val_loss: 0.4054 - val_acc: 0.9315\n",
      "Epoch 97/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3177 - acc: 0.9524 - val_loss: 0.4046 - val_acc: 0.9303\n",
      "Epoch 98/200\n",
      "604388/604388 [==============================] - 181s 299us/step - loss: 0.3171 - acc: 0.9523 - val_loss: 0.4110 - val_acc: 0.9293\n",
      "Epoch 99/200\n",
      "604388/604388 [==============================] - 181s 300us/step - loss: 0.3169 - acc: 0.9522 - val_loss: 0.3950 - val_acc: 0.9340\n",
      "Epoch 100/200\n",
      "604388/604388 [==============================] - 182s 301us/step - loss: 0.3161 - acc: 0.9527 - val_loss: 0.4042 - val_acc: 0.9294\n",
      "Epoch 101/200\n",
      "604388/604388 [==============================] - 180s 298us/step - loss: 0.3170 - acc: 0.9523 - val_loss: 0.3979 - val_acc: 0.9324\n",
      "Epoch 102/200\n",
      "604388/604388 [==============================] - 181s 300us/step - loss: 0.3169 - acc: 0.9525 - val_loss: 0.4066 - val_acc: 0.9296\n",
      "Epoch 103/200\n",
      "604388/604388 [==============================] - 182s 300us/step - loss: 0.3173 - acc: 0.9525 - val_loss: 0.4245 - val_acc: 0.9252\n",
      "Epoch 104/200\n",
      "604388/604388 [==============================] - 181s 300us/step - loss: 0.3166 - acc: 0.9520 - val_loss: 0.3994 - val_acc: 0.9326\n",
      "Epoch 105/200\n",
      "604388/604388 [==============================] - 179s 296us/step - loss: 0.3165 - acc: 0.9527 - val_loss: 0.4195 - val_acc: 0.9236\n",
      "Epoch 106/200\n",
      "604388/604388 [==============================] - 180s 297us/step - loss: 0.3157 - acc: 0.9525 - val_loss: 0.3945 - val_acc: 0.9313\n",
      "Epoch 107/200\n",
      "604388/604388 [==============================] - 179s 295us/step - loss: 0.3151 - acc: 0.9529 - val_loss: 0.4080 - val_acc: 0.9322\n",
      "Epoch 108/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3149 - acc: 0.9525 - val_loss: 0.4091 - val_acc: 0.9300\n",
      "Epoch 109/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3149 - acc: 0.9526 - val_loss: 0.3950 - val_acc: 0.9317\n",
      "Epoch 110/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3145 - acc: 0.9527 - val_loss: 0.3862 - val_acc: 0.9353\n",
      "Epoch 111/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3144 - acc: 0.9527 - val_loss: 0.3951 - val_acc: 0.9323\n",
      "Epoch 112/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3146 - acc: 0.9528 - val_loss: 0.4029 - val_acc: 0.9304\n",
      "Epoch 113/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3131 - acc: 0.9531 - val_loss: 0.4036 - val_acc: 0.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "604388/604388 [==============================] - 178s 295us/step - loss: 0.3140 - acc: 0.9527 - val_loss: 0.4140 - val_acc: 0.9259\n",
      "Epoch 115/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3140 - acc: 0.9527 - val_loss: 0.3921 - val_acc: 0.9329\n",
      "Epoch 116/200\n",
      "604388/604388 [==============================] - 178s 294us/step - loss: 0.3142 - acc: 0.9525 - val_loss: 0.3945 - val_acc: 0.9303\n",
      "Epoch 117/200\n",
      "604388/604388 [==============================] - 179s 296us/step - loss: 0.3136 - acc: 0.9527 - val_loss: 0.3962 - val_acc: 0.9315\n",
      "Epoch 118/200\n",
      "597376/604388 [============================>.] - ETA: 2s - loss: 0.3125 - acc: 0.9532"
     ]
    }
   ],
   "source": [
    "#Load model from disk\n",
    "model_name = 'SVHN'\n",
    "model_save_path = '../trained_models/' + model_name + '-model.json'\n",
    "weights_save_path = '../trained_models/' + model_name + 'weights'\n",
    "model = CNN(model_name=model_name, dataset='svhn')\n",
    "print (model.num_params)\n",
    "epochs = 200\n",
    "model.train(epochs=epochs)\n",
    "model.save_model(model_save_path, weights_save_path)  \n",
    "#model.load_model(model_save_path, weights_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get training samples\n",
    "num_train_samples = 1000\n",
    "data_indices = model.gen_rand_indices(low=0, high=model.train_data.shape[0], seed=SEED, num_samples=num_train_samples)\n",
    "train_data = model.train_data[data_indices]\n",
    "train_data_labels = model.train_labels[data_indices]\n",
    "train_data_labels_int = np.argmax(train_data_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/notebook/cleverhans/cleverhans/src/cleverhans/cleverhans/utils_keras.py:144: UserWarning: Please update your version to keras >= 2.1.3; support for earlier keras versions will be dropped on 2018-07-22\n",
      "  \"Please update your version to keras >= 2.1.3; \"\n"
     ]
    }
   ],
   "source": [
    "num_test_samples_per_class = 10\n",
    "num_test_samples = 10*num_test_samples_per_class\n",
    "\n",
    "#Generate test points\n",
    "test_indices = model.gen_rand_indices_all_classes(y=model.test_labels, seed=SEED, num_samples=num_test_samples_per_class)\n",
    "\n",
    "#Get Regular, Noisy, FGSM, BIM, and CW test points\n",
    "reg_data = model.test_data[test_indices]\n",
    "noisy_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='Noisy', eps=0.1)\n",
    "fgsm_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='FGSM', eps=0.1)\n",
    "bim_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices], seed=SEED, perturbation='BIM', iterations=10, eps=0.1)\n",
    "cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.test_labels[test_indices],seed=SEED, perturbation='CW', targeted=False, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Whitebox CW Attack\n",
    "#First get guide images\n",
    "guide_indices = list()\n",
    "np.random.seed(SEED)\n",
    "#Generate guide images for modified CW attacks\n",
    "for idx in test_indices:\n",
    "    label = np.argmax(model.test_labels[idx])\n",
    "    #Add 1 to the label mod 10 to get a target label\n",
    "    mod_label = (label + 1) % 10\n",
    "    #Get a test point with the target label\n",
    "    guide_imgs_indices = np.where(model.train_labels[:,mod_label] == 1)[0]\n",
    "    #Choose a guide image\n",
    "    guide_img_idx = np.random.choice(guide_imgs_indices, 1)[0]\n",
    "    guide_indices.append(guide_img_idx)\n",
    "\n",
    "\n",
    "#1 Phase Attack\n",
    "p1_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True, eps=0.1)\n",
    "\n",
    "#2 Phase Attack\n",
    "#Phase 1: Generate targeted adversarial images\n",
    "tar_cw_data = model.generate_perturbed_data(model.test_data[test_indices], model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, use_cos_norm_reg=False, eps=0.1)\n",
    "#Phase 2: Optimize for higher cosine sim and smaller norm\n",
    "p2_cw_data = model.generate_perturbed_data(tar_cw_data, model.train_labels[guide_indices],seed=SEED, perturbation='CW', targeted=True, x_tar = model.train_data[guide_indices], use_cos_norm_reg=True, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Reset tf.graph() as Cleverhans modifies the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Reload the model and weights\n",
    "model = CNN(model_name=model_name, dataset='svhn')\n",
    "model.load_model(model_save_path, weights_save_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15816/15816 [==============================] - 5s 290us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.69354552166234018, 0.88359888720283253]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.evaluate(model.test_data, model.test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACvRJREFUeJztXEmOHbkRfSRz+kOpWi2hjV4Y8Nl8Bi98Fm98Ct/K3TX8\nKSeSXsQLMksqQ99ogBJgxiYnkpkZ+Rgz08QYUakM2e/9AP9PVJldkCqzC1JldkGqzC5IldkFqTK7\nIFVmF6TK7ILUlLzZX//5j+Su6k6MhnuBx9mjDbzmYwCM7FvPfiG3+2IIBAAxhu0prN5zu8IH3ss4\nAICzNt17XVcAgNHxY8wPy37WZowaI/v/+vvfDL5BFdkFqSiyp1nQFSwQiBJPxG1J0a3bgJjgayFo\ntNrGRyxh5b7094iIPIiEZQanYj2fXBSpMaYZs+qzrh4Zsl8je7v/LSrK7Ms8AwCCydN88coUoTdi\nZMMYfeHoed1TFISAoH3Y3FoHGDlwVj6Op3jAO4E3QxFlEGF5J8sbRtcgBj6j0fYyhnMOrrmfhVWM\nFKSiyL4uEwAgxJgQPK+c+4okEzfopggIJiN/ochQZbVRlM4JijsDtE0LAGg4zV3MIsBBkayzStFs\n4Kg0Wyf9TbCYZn1uzzGkfdM2GHb93e9fkV2QysrsiTIbIQlpTxkc+dkDQpbPSVGaJOP7VhDniJPo\nPaLKb8v2xifZ66hQu5ZbaxPaTXTcEvXGJjNwP+x5rsH1KucU4Y732e16PDw83P3+FdkFqSiyR1oE\n0WzML/3eXp2QkGSoqv9oQpLRDVEIOhMRBpb7jZPt0DrsdZ/WwrHrAACtcego250+QnJWsvXy+PhR\n2rgGp1eZTbfxKud4v+Nxj8effrr7/Ysy26vCi1mMqNmlJ0KyjJGVZgzJ3NKpbPiRWli0ZOhDvwMA\nfPqwx6ejiIGfqMA+c7p31sHq96JyDVS6xkUc2O/j488AgHUJ+O33ZwDA6fUMAJiXRcb++RG//vqn\nu9+/ipGCVBTZIX1aAxBVJr718GAMTFKRmy131bOzFDF93+KwEzR+5pT+8y+f8JdfPwMAfnnkteNR\n2huL8XyTe64C8Xma+AwLPn0W8XHYyUx4PV2xo0h67kScPJ9eAQAfH/b4/PF49/tXZBekosjOZFS/\nQfVdTMoQGdkhK0oV7dbJIzsjKGubHn0nsnqgzD4MA46DyOoHmnCHXhRkDws2R+Dsmhyji97C8oHO\nry8AgOv5Clp6OAwyxhp2fIaIy/l091uXZXYKLJlNcEe5GNNx/EKMRGPSx7BUhs627NdgoTi4jSIO\nTqcbngZhQuNXbj8AEAVpVsY2aHlEflQfgOtVxrheRdSM84KhFeZmZS7b6zgjvtzP7CpGClJZBalI\nzeowY1xj9WZzVaEQ8kyIPKljLcFjmgW9p/MIAHhqztg37OEFqR1fdde26IzODrnTQqU7zyt8ELPu\nSpvaOoeup6cJxksg97nNIya2v4cqsgtSUWTHDT6zhH57bRttNpuDSHmpMe7IhIGJDjc2bBhneXHA\nzkk7Ew4AgL0bAADLMGDXqoKTMcdRYjarX7ESqa+nCwCg63rspGtSKzN1xOl6wxrmu9+/IrsglUX2\nOynRFCVJit7meHaS47l9sgg2UcPrIuiyTtDexQVtlHOeDkvLG03HBxwGTcXRqrjdeBTgidTTReTy\nPhpcb0Qv4zevJ3HbX04nTJjueXUA383OzhNKFZ7m/oyN7/bISlNt8O15KrqgqbaYzMGFcYzLTZg3\n9Ds4Kx9lnuTay4t4hMYELCu9SUap9k0PDoWFTFfzcJwmhO7++vYqRgpSYQUp9G6BhdG6kfeuAZFQ\nDgzTrgtDrt5izxRWw9BpCCFlvQ+M9n14lLiJcy00E/f7k3iJT08S1fNhTWbe40dxgvpuwMIO/36W\n9r/99gQAeB1fMXwc7nt5VGQXpaLI/rL+4s25jVODlA5j+goxRQdVQarZ5mxEw9hGS3nfWIOmYbyb\n7n3XSazERJtmxTjSgbmJDPZxRWQYoOul/dAPmOksabTwyrCAD0Db3Y/swgoyfPOaidmm3uTUoV/D\nkqFMgsMZC4Y4ku5sW4eubdI+kOtU1hAwTyIW1AoZmZCwzsBSFO0Z1GpsgwsV6Y3tVtaRuMZh31cx\n8kNSWTHyxj1k3o+HuQgtwhLF29ig+pyUDmB4A9ZHNKy21Nxg6xz6juKDHbTmw88LzrShp3nko8jY\nw6HHhw+qGEWMLPOMy0W8SS3IbDl2O7TomNu8hyqyC1JZmW3+u8y2WjIsDXlWlSKS0tQqpkbluokp\nxaaJhbaxaJOC5LZlzHr0mOcrh195jRn43QGPRzEVGyqA2+WM81mcnlnrRli70u922FWZ/WNSUWS/\n9cQ14btFtGA6mXkaCdzU82ldsJqA1sRUKqxKwdoBjVorqZZEXnWMHsskVohGEHui83DYY8fUV6Tz\ndH0+4fVFnJmFsZFhkEjibtihbe+v9Sts+sV39t+aeWLkvRUmxuQPAC0Z1iRmiKn8zGtCM6wwKrL4\nJTR0Ok8jbtczr8kYu17YcNj12A8iIiYNNj3/jttJUl/9XszBB9aiHPcdevOuP/wuVTFSkL5T1C+m\nCqfkuChgEbIyjF+bfjnEqigOaQxVhk1rcnCQyJ7pJY7jiBAF5Zo03u/oyAwGDWfE00XQfL2ck4d6\nVERT1AzWwq41LfZDUmGnJq1sScovW4NvcmDcfi3jG9uwnyLbJ9f8eBTF9XA8oG2p6NhupLnn1xX7\nncjensg+7qT/0Bqsk7QbKdcbC/zps9T9HR9k/I7Kt0dAY+7Ha0V2QSqLbEVxxFcyO5c0xCyfkzjP\naxF1KUc2/TK6NIbtrE2xbV22oZWn0Ye0NEQDWBoCaBuTiuEfPwiKW2PQ0yU/HjgjaLEMw4CGDs49\nVNbO1tQXbGbyF2IkblYlJDFikMy0uOjKMF1vE9OKA6MLUteAwDCqlilreYeBhUuepsZPRPH17ZBC\ns4+PEiPZdV1aQzMMYo+3ZHDTtmjaulrsh6SiyG7CJuahsY3wNl4SgY3px3MxIq+V5gqvhOyQ1+Ms\ndGBmj4mJAed5H50ZsHBUshpLMXps3WYlWMfb+WRmrjQjl5HPtwaYsdaN/JD0XWT2NvOCN+eoOKO2\nz7WBOZ69kePSIS35UD/HLwEz6//sqlX0ROW0pIYWzMCMEiu5XAY0LVeG3WgCXq5YUziAJRNa2xAt\n/pdf9RVlttsGlBKz9VCZuCm6TH9ZyIVrzr5tHiPy4idl6LJivOnSbWH6xITBOo/pA7csvly8MH1Z\n17QI6sTg0+nlFTODUrrMPi0njAahxkZ+TCocYt0gm3Za/t9IjpFkxch0F2JGsqIsJJkBT0W3sNJp\nsnMqeF9og1+4DmadJoSgCQgZQpMCq/cptXY7ixi5Xi6ppFgRvXoN5VrApQV+337/u1tW+sNUWEHq\nTwE2jsuXce1oNgkFlY15RoSVSVqec8amxaMrZfb1csFCz1GTx9eX53Qb9TgDO54vWkcyJi/UqFxe\nkP/iY3VJdvoXRqpVvOv9725Z6Q9TWWR7dQACFMkau9AiGoNshSTMm4gI/cfT2zrixkU0RLnGlmNw\n8ERt+GKWiOXIZd10dLzOOMTkBOk6S+dsMi1NArRml1w+eQcVZfa2wkLTVq1TZvN8RLKhk6I0MRl/\nOvXVg7QmV0Jpxt3GbNM3Olij62Jiaq9/HLKau0RMH93xfyWta9ISwVT6Bg18Gdhq+v2YZOrPystR\nRXZBqswuSJXZBakyuyBVZhekyuyCVJldkCqzC1JldkGqzC5IldkFqTK7IFVmF6TK7IJUmV2QKrML\nUmV2QarMLkiV2QWpMrsgVWYXpMrsglSZXZD+A6vC8+OfUPa/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68e2804750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD3dJREFUeJztnElzHEd2x39V1d0EwA0kRa0xMQpRIkEKW1d1NwBSlEBS\nIjUxDismxgeHL4qwb/4UDn8AR/jmg7+FpfGYkihww9ZV3WgQFBeNRhpJQys03EXs3ZU+/F9jTg7g\nVHbE1LtUdVVWVuarf773fy8z23POkUs24v9fN+AvSXJlZyi5sjOUXNkZSq7sDCVXdoaSKztDyZWd\noeTKzlAKWb7s/d/+kwOIEogjXXOxZ3dT/Q5DoiQBoO50b9Sl4FUAaI7ac3VFvhEJrmKVpfYcEWGs\n+tJI19rzerA92qaT2rsaAQALflO/naM90gagUg9VZ+ggtiaW62pDs2rvhkZFzzY//JduR/5XyZGd\noWSK7MGNDgCrbViZEbo6o7pmAITpDZ6FgwAsx4LUCo7ErQFQnVkAoBkKedfnh9hcXgHAdY4DMJpc\n4WkoJLvLRwGII5VJ11LAXvamDs4XUokd4YZGzLWV6wCUp0bxuuWvlgE47quuqxFUV1d23P9MlX1l\nYwOAdDDC2TAfnpkHYMrKhG4dNtS5p+sq8yyCZaZ1rSNlHFm+DEC8kpJeM5MiXbA+FMDcLABBtQbA\nyIzMQxI6omREBc36NBoq60UhC/UGACVZLZbqLVyqH2GlY+X1vlIrYKmwcxXmZiRDyRTZK7PrAKTu\nOi4UOpbbQstxTzBb8aaJbShHbR2vbng4G8nPhoXKuC7U+2W35VBnY6G4VGgxPjYOQKEpPC0EKn+q\n1GShJF/m3dC7T4/rOb/hEZzcBcDiQlFl9voMDvVauzUKz54S0luLBXp69+64/zmyM5RMkT0wOARA\nPamDzDfr80Kvq7bt3jBdJre2qXtrbQ83LGRSFF2rnTS6Nj+KAZqaL4daWvBpJqpvvCqH2pMIzXuK\nNSbtWc/V7Ki6m0WfWknXLuzeA4BfKXD1qpzg4JBGS9BUu86/tcTdvZM77n+O7AwlU2Rfbwtt4egI\niQF1LhLK6Mh+ljt1NueNClhQ047ruFRUY35CD9YauueiBl5dmCkUROFuFhfoq6neuy2h8Rd7bwCw\neOcWE7XdAATJHb3HgpwXz8CLTSH7d+8fUJmFFq8cOgbAS7+/CsBCv96z59C7/Oqrr3bc/0yVPYqG\nXyeuM2oBWsMzG4CiszRyOCuXmOMLwzJeomuNDTnZ1XUdF+d8esbUjb29fQA8/+W7HLp3C4Bzv/pv\nAP6w928A+Ac/oGmRZuXnqjOdldNd+dEx8nd6bvJ3alX7569w8eELALz69H0AXt4UVew/fJaXhk/s\nuP+5GclQMkV22v20vkdigUHVZvedRRjOi/FQYOF5RtEaHok92+mIfnXaGhHVkz0c+EJofK7/a73n\nl4f49b2/BeD5N3XvvTsyBbsinxPLPwIQt2Wahr5TwPSQTQYefADA7fOidG/MXOWD2kEAPrskOvj4\n6CnVefcWz504suP+58jOUDJFdrJ15lGpGpJlqolDoTn0PTzMQdYtkRbW8Zoy8v7CGAAL44sAvNN6\ni13vKOjoOaDj7ps93PmrJQAe35wE4P6YHOSuJZ/hVZXbm8rG7+nrAeB0x6cZqkGdabXv6rEndOZ1\n7e2eYQCe3P4CgOCtkyxf/kltnNw+uMlU2ZETD05dhbqdR5Gxika3VIUYU3Kki3HiEUUahH6zBUCr\neBKAxC9wpi02cW1NTvODoyf42afycN+e+RSAwvoZACaOBVybk+kKjJe7st43Px9RWNH5ypHPAFhb\nGaanLOV68912CQwrazPETyYAeGMH/c/NSIaSKbLrhthwi9wBZjIiy5XEjZjQkENioSQxSSKUV3zx\n5tR+b3pV1jfE348+U87008IzXnkkrJ1/pFzHD4gjf14sMrFupsg3yjejcHZg4zrzTzYBOL6mdG1z\nYZ6J3WfVikDYPILSvasbwxwZuGJtPLZt/3NkZyiZIttt2eJki+p1JbbchatUsFgGL9RJFEe4itlV\n86jVRFFcMZzn2rQwMzmmhP+ThVP0nlO5Tz57G4APLAq8c6qHK4NzANRsqu3pmpA91xmhva7zR1OP\nAfiptM7mKbUjjfXOmTn5iEfLq4yUX99x/3NkZyiZIju0nLWjjutO6oY2eWqfPfF9wopYQsNoYVpJ\ncIlQ6NnoSIxIVuerHB9WXuXKiip5940pnvtUbKX/9EMAfqN4h/5He9l98xkA99Fsz9XVVQAqUZlO\nOgPApYGnAJzu62VlVWg/tiy7f+DoqwB8MjXFwykxIMbObNv/jHm2mYWkSmTnSaKEUd2JR3vOkZhj\ntG9DkjicnUdNKb1hiaw4goqlYodtQmGzJ2R2j77UuU1Rs+VVmZhTm+9ye0gO9fNpOcPXX5czvfjw\nEpttzX+GC9a+8yc5XxeN3DyhFPHKxf8CYG1wkM6Nna9vz81IhpKxg5QkQBQJqlGs7x17ynm4OIKt\nEWBwrtiEAzA/qvLtWaG4sOkT2BRWa1wTC283UqrV0wDs3qvIbt/ZcwAEQZERWR3uP3qi4wMFPj+k\nI5SWrqncuzILu0o9zNoD9//zEgA/e/U1AF57dIn1oVM77n+O7AwlU2R7htQoSunyu4Z5Rs+MctiI\nScx+d7f7eC6mUta1BIXrgWUEAz+kUFMeZNzyJ4UgodBSvYsXVP6lG8pFe6HPnI2KV9aU61hZlRNd\niddxp2XHS7sUDJ1a6mHjmIKf3xxTbnzlk/sAzKcR/S8pr8Ivt+9/trkRW2KWkGyt2TDigbN5QAiJ\nuqnVruFJHIQqWG0q+otr+h2kPn6gyvyqPmCxGFA6ICWPLyo9+o05zLl6xMa6Is2rJz4G4LVL4tSd\nwKMayPzc2qVk1Y9+gSfTmiw48f0fAbhYVlq11lrg+12Hrd1/vW3/czOSoWSKbJsvoOIgMe7mm6Ps\nxHYzcvie8WxneRMgtvtjY0LvhHHw5qij5cuBveWpzmJQY1epH4AbBc0R7nZajtYZus6xS0L2NzM6\nNsri2b13b7Jv35cArJUUcQ4PbfCnewMAPDj8vOrfEN/u6+tjojSx4/7nyM5QsrXZhrykUd6y2d3l\nuE2b8A2TiK0UiuW8vQp4WNCTaB1Iy3IlQScFWz7cDDTNdfB0kwcFIfvFMR3HbypLeN2NMrMhCheF\nWnQ5tyn7vqd3P/vvTALw8BXVv7p8mWeXfwBg46gQHiwq87jrnS/o/e6mdWRy2/7nyM5QvCy3Ux/6\nx7/XYvgISLrhuRCX0qV23Qz3n/MgsYsJI7WzoLiFoq0baY46AgtS9ixooF7YN8nPbN3HC18rKfJV\n3zsAPH71MT/c+y0AA1eU8yiOib49d/ggh7/VSOgJNKH85P5Dvr93D4DZjkZmz+RtAPb9/iwHDu0D\n4J8/LG+7GD5j6tddDxKBKc+zbx0mNk0GOLvXMF5e8VIS+xi+LRke79jinrojtGmxW77Rx3QOr3Fe\n5/224yAVf96Yvs6J7+T80lAD+4slOdFfvHCSvufkIKd/0pKzlx9/wrWf/gTAyT7Rwa97LwCw5/QN\nTt56a8f9z81IhpJt1i/6s1f0GmZGbAeBZ57Si1LoZgBTQzjhlrMMLOFPKBRHnTKNuu6dseVnrfF+\nHvxBxd6zZb4bq6Joa2trpKFQvtBQTuXwIdmmvp4GrYqWph3/aAqAj5afMVaThbjTr6jyvZ4SAL1+\nFb+9ueP+58jOULLNjbjuDq8yDVvdXrFlUnHXUTvAdpB1J4GTBBILak4GQqFXFoqTdJbeorpxZ48c\n1wt7+ikWle1zZaFwbUM2ePTFEa5fUxBz5rSQ/c3XSgHcLH5FdVrlPjouu1546WW+tzWEF/YK9Tcs\n132qt4eWvfs81W37nyM7Q8kU2RULsRMHntGQhtlnv7uPo+622Igf65oXObpTNQuLCmoqngKYghcw\n5gkzB6s6vuj7HK5pBAQN28B0TMsPLndS/FQ23veE+jFfue5DBY8Fq2P/A42SoneckyWVu3NbbOTs\npBhIz82bnB0v7rj/mSq7aQ4viHw8c3SVeVNyZGlV5qEjZSSjVj6NIBYfd1V13G3YaqY0JO7oA1yY\ntznOc/uoz4rC9RVVbnhW013egE8tULeLLR1L55WiXfr2PXqWRCn3D2jyoPfGdb6sqq197yhavGkR\n5FipROGGqfC17fufm5EMJVNkF1JzfKkjsQjQtx0FidE3R7TlGAMzIy6MYdQo35yGrSvbUuN0Fjci\n55TeFc2b29jHgTVFjMGoFlTGm8JVeNXH89Vtv6Zjo6nj+4cXKPgqN13UCEonikTOtkw7mabNNxV5\nTrUG8d5UP4Z30P8c2RlKpsiuli3FV3dbRClJZasrUTcjGNONuoOO0Ozq9a3cSMuCm0Ijsjor3MR2\njpU1y9LZ3MOGrf+rXlPQkbRF92YHNyFWMqVnXXg8+OZ+AJYPHqCwKPwNLGsN39qVFT4d1egbNXq6\nOadpsSRsEn5r+1WOb9//TBNRv/7wX7tEm63campRpW2vTrx4K/vqmdlJo7T7EMWCOUhjLy4dYSmQ\n89xvuYv9t9/m7ZKcWcnTZ11fFhtpD62BOerFlurfN6mNTAf7z1EI9OGOPtGysqlLTxka0XI12/TA\nvDnu0FWoN/Tu//j3f8v/leH/k2RL/czxEQMVZeNC150E1r1KGOEZamOn4e45tzUh7M8ZyspmazrT\nTNhuhL2nhOy7qzOstEXPNj2tA7nyk5aTtT8fJC2r3rFHes+ei4oQ+889IPAeAHDx8ncArCwPcOmx\nosrOEZmMkc/U1in/KlhEuxPJkZ2hZIpsvy6jF1XS7rZHki7Ns4mClqtQMUSPWQ47jh1RpAfqI3JW\nnm3DrlWaLNiflZTmZM9PBh5TlSkAqrZ/8skT29VVucLYhjBmPpTLAxaNfvwxVfvvkddHjYrOtkks\neq02LYdelOMuVMZwyc7xmiM7Q8mW+o0qGEjmynRndYt1hdouFLoqaZuGBTqhMZYJF+JiwTBoGyWw\nZQ7FOGSsqgnbguWW43JAzUL3Odv9FV6xfItzwIi9U0gdrWskBdVhOvYPBs2OytSClJr9h5RXU56l\nYQxkYqFGUtjaebWtZKrskqVBJiLwbN3IovmX0I5eDD1GXW8ZOwyrjthmJvvmuzkRKW+pAlXrb8vy\nLUHs06zqfjHWtaWxZdWfVPEraojv617VkmJ+Em/9D0pge94XSy1o2b83eKZkm5/0qw16G9syvi3J\nzUiGkmlQ85cuObIzlFzZGUqu7AwlV3aGkis7Q8mVnaHkys5QcmVnKLmyM5Rc2RlKruwMJVd2hpIr\nO0PJlZ2h5MrOUHJlZyi5sjOUXNkZSq7sDCVXdoaSKztDyZWdoeTKzlD+B1zlvvjqKRLLAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a2994150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyvYopbI9Sqlsj/LfLJxvMzFv+GcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a28db510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmd0gtcxukFpmN0gtsxuk/wFxksmzH51BSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a2878710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADZVJREFUeJztXNly48iVPYmF4CZukkhCVKndXW5vj/6D+YX5kPmHefCn\n+MVfMd8wXsJtu6urVBJBSiTFVSIBItMP5yZUFTExRYcjsh1h3BdsiQTy4uTdE8oYg5LckPdjv8C/\nE5XMdkglsx1SyWyHVDLbIZXMdkglsx1SyWyHVDLbIQUuH/Zfv/utAYAJJhhgCAAwZgoAmEy0HL96\ntNooAEBuNKC4f5XLtcGwaCfNML1PAACXiGGG7G/CU+j1eeMxP+Ko5VkTHwAQeMScHhpMPn5kH7Z/\nMwZMLA+9BwAspp9gVHH/f37z3+pL4y+R7ZCcInufEVEt1ce7MRGk8/yzNv04LtBtzBgAMElMAd8f\nQDR6t7cAgMt8iPvBke23bQBAJd7BbNlv9Yx97V7YvxZU84W4STzOLvxgYDTb333/AwCgc9mHwrPc\nwP5rbcFoAjzZe08gp8zepSkAYDIBjOF+J+8DAAw431eHA2YJ9y1jLuIYczlnchEzOa8t9V+g38k5\n4WMjvQYUD56mD2x+5AfB/xF4UyKiFAw8cN8ToVD1AxjND2fFlVLsw3/jIwrenDz+Uow4JLfIzg4A\ngJeegRlzf33ktqe4nd++L8RIL+b244cPsHg0mYgMQb2nX5HqX1PEGJVj9RgCAIKA53zD9srz4MMi\nWRBboFkhvmL70Of9Sp/h44f3AABt2N4T2F/dvMFVLTp5/CWyHZJTZG8PlNPPyT0sVHVORZnIZ9fQ\nUGJpJZkoyqMqTLlheAMA8KQDk+cwIr99MeEeJ3eo+hyaLwo1vrkGADx5XmHqxaKAp2Pef3U1Kvqo\nVzd8jmpgW68BAA7pQZ7DZ1/UIpw1myePv0S2Q3KK7JcjUZzmr+ZXJ5bvLTJ1kWi08ys5R9m4NONC\nRh+lXSDOhIGCJ/trn2ZYLfRR83kuekNrYVCpAAB89YDKA9GOIVE5+FacHG+Focdr7dav2N73sV/S\n5OvsufVjvtdmt8YNvjp5/E6ZPU9k6kOjIw6aBhm7BL0zEw+RWxmjaO41hwMocMo/iLKyHynECLWA\nw2gs6gCAXuctemec+p3KEwDg4hsy5dprwvua5mYsylWLWai8KRoNtmufdQAA+cxAv6Gd3YzYZyrt\nf9YYYfCry5PHX4oRh+QU2ab4tArLCVHVHQraE3tJYYNJ0Q4AjJmgdcUZUO9TFB2PvBZFIZo1Ino0\nZJs3lz181e8BAC4F4b0GzbZnNURtt2O/Is6SB7qSBgNc9Kid40YDALBVe/z6/KcAgNWa9333/nsA\nQO2iDy9snDz+EtkOySmyX0kVn9m6wK2YqDRTg40gGlq2QwVlHQ+fCi9QdDoqQYRqheitikxtRBGa\nEZ0NK2frFR534CGrUjGKrsXNkDNptjyHb5YAgPETt5vNFp0mZ0k94jPPmpxJvpqhgtOR7ZbZ4hlq\nqMKWzi23xXZdYwIrPgoxohS0yCBPlOFmKgO/DpAeybWXPe3gzXaPZbQFAPiaymy1ZpuK30UvktiG\nWB4wXQBAu3nAekeRsttSKe4PKdJULKHCiuJ7Pe9TbES0nEKlGHFITpHdFESsYACrEIeCYvO6KaId\nAoWWmIe8zpMtsXVTneOQEr3rHZH9p9kOqwWvn7dpUl6f00SrV1Ls1TkA4LLDJ01mc/Z1eEGuMwBA\no0bx87J7QaXqS3uajMstw6/PhxesXmz49ctUItshuTX9BI0tGAAitAtEq8+2ANAe2jYGRmLOWlJT\nRo8AAMr4eJb4ciCxbrNNUPOpxJSmMqwHVQBAVquhTnGPxoGyerXljGDKjPGbTNMbXe8i3MQ9eTbv\nSyUJstm94Gn1VwDAf+I/vjj+EtkOyS2yxQRZJ/do2RyqFd7WPPG8Ip69kvvOFLCWTI2SKF5b3P1j\nbrDLiMblA2V3u7ZBKJmg/EDUhoLK7tk3CEeE9uI9LYnp80r61sg1299umEer1xVe9uwLj+xktWZE\nsL5e41DtnTz+H8nO9gBwmpqE4mAlnqQyBq2YjJfMFlZJ8ipePGsOvl5TklCIRNQc8xCZmINZRoW3\neybz3kc53ib0JrM9r1WqDFKpB4PbjDa3Cfg138Zdm4FDVmf752d+kPHhgME/UN9eihGH5FaMfHpg\nTb/YHt8XbVZjRvjatl5DMW4BAPrIGfEiiYg0S1GTFJbvU8RorXHlccbgjE5Kq/NzAMD1MICEVbCY\nrwEATwuKkdzLsZE0fLsnHmolQibQnq/Zfj5bAADW3TU66elipES2Q3KK7FejTmMte22pP7Bm3moy\nRstGAm0ocGKgJIWlFF/5ZULZ6ntA4LPn0KOcDbwEs4AzIA7pwFSitdzfx92Y5Q1K5O3zC2fJ3fgj\namIXfhVRjlcrEW4/cNZNZfssYYG+jhFWqieP37GCvP9/rlmmG6wmkv0WZrQwhBEhtPUeeU3CGt2r\nEdLHGc9JsiEIfVRCDi2UrTGc7h8fjkgPtmKHfe4lt6j1AKNr2uf1azIx8IJCkb5Iu8sBPUkEBvXl\n08mjL8WIQ3KK7I3NdhkUdp0niLZFaOvEwBOPsG0FT/xacHkub6w0xY6XG3RGRFpdcpHpfIZKhQ0r\nAc8Nzvmcu7sMWwmRzn7/RwDAXpRi9ayK1hkVcUVCslmaorVj+2zAPnapzJpqiDkOJ4+/RLZDciuz\npSz4E01ZkEW4ig1aymbXpbkyRSxcgSgOBP1KmUL2elIrMnozwvU5M+HDLrdhaKOLCdJbUWqGzlAg\ncv3b2lu0G4ylzBaMBPaaDWwb9Bg/SAxFh9QR31Rr8NE9efglsh2SU2R7n3g1rdi65xJvKGIfgBeL\nmSdxbPNJPR+k3s5WnvrKYH7He/eC7Muf/wxS4ldUOEX2hMmR9RiP1gs+O4qI9EajjuWGDk5VHKR3\nf32H/J7t0pwmYvWMqbBlr47uxelVrI5Nv1emraWGxAaU2jF3VknC5AKADixjgc3YfgBeC0UZKm3g\niYeXy4eb3n9ERTOor9stAMDmkfenhzY6GRXiTlY9fBOxNK3xkwrOz2mXH94xSJU9bfDQpLl5Xafy\nPOQ0BZv1Cr46vWykFCMu6UeK+hm0r0Sp2SSwgN6LNVpm+Nm1ZZLAzoqu1I8Ecry6uy/QHouZN7y5\nwuhcSpFF8T698HjfPuLxf7lq4XrEIs16jyKjXlUIxCRdNpkwfm5t8fiO3mq7Q2Xb618AAH7iDeFN\njiePukS2Q3KK7PbQrvDS8AzRYmPWXiGn40K0L0VOkyT1JX66sjkqbRCGVFJn31JxnTUaCAPKV1uQ\nuX+mDM7na9QlmdtacdsckQ1RoHAUV/6Hd38DAGyWGwwu6Oo3RTHexOw7qmkEwel4LZHtkNyafrbG\nxQBKEeVW3tqKJxhTBJ16Es9+wrhYd7RObMTOlg77CBStCs9jTd7DwxTDtpT3ykw4ZrKkI9fF0hCP\nRggsOMNAYbagw9JuE8WhUoik3LjZ/JrXmjITqhGCIDx5/I6ZbRk7xUpMP2VLzOxKgjhHxyYN+lK5\nNDFFVWb3gh/p6d5m2Q3OR/LhJMAyuBhASwY8fxAFLGlEBQ++2OOhbCtzlppVAh/VqpQaizL8unID\nMdWxqjFMG9VESQcrPG1PZ3YpRhySU2QH2pYCD9EbSHXU/ecxbnMPrCVR0BXR0RsOUQRUjoRv95JK\naqkzGDk3ub0DAKTtFs7eUqT4bUkQr+1KBQ++x2FPH+ms6HOactrzEUhCOQgZ9ZtHi6IC0zMUSe/v\n+M4qCKFUevL4S2Q7JKfIXt1/ur5R9vuUt4vEpr1MYfqtRZ53dVI4+oFHR2QhfwDw9BHzkIjrNBh3\n1tkAaSprFo+SZdnTpMsO2StSwWudPV37bfUG1xIdnD+yz/1uWlSv5oaz6UL0AQaAsXXHJ5BTZvui\nIH0NWI4u5E8KvjU3lEGvqBuxJWe6iMrKuqQiqNU1QLVPJnRkCV2nccReCmvuJ1ypcJBS4Mu0i4nm\nh90F7HXaJ9N7sxmm8oDbD98BADardbGGpt+nF/rnnPeb768wUF/8GUNBpRhxSE6RfSFZ88XYAIrK\nTJnPTT+YV3vcSDjVhynsbCMoyy8YndN5hqOUDGcet3svhTpKsrjNVV/fT2i2LQ7fFQv/JSmPP/yB\niP3FLxfwJZpYiWhn1xpAkPJdV0t6las79n01esZOQrGnUIlsh+TYqWFKyzO3BZB7VnbbxftGYTW+\nkzts/cirHJ8dGfhXY1kWcjWCjbgkYgL6ux0y8RxtzKVapeOCWqtYsDr3qS+2gfx1ZzKBJx6MsuXH\nGQqr0xOX8+am+BdGUZx/0vhPblnSP01ukS1ppYvLc8wTOjhrRbT4tuIJr5FAa+4pZVAZUx77l+KT\n55IWG48RjBj164uZZ7SPXESpFtPMxltoxbCvSzHlAs3GGTIE0q8nusT3PUwTCQdIEVB8JYX4iY+J\nso7al8lt3Uhiqyk1IrtaQKbyJ5ZfMW2VVYrKFAtRaw/iEYrt5ymgIu0DZRkFzO758az6OqYMsSqY\n4i85Q6m99CSbT0Usf3iQKqu5HyIIXsUGAMwfJPAVeqiWpt+/JqnyZ+XuqES2QyqZ7ZBKZjukktkO\nqWS2QyqZ7ZBKZjukktkOqWS2QyqZ7ZBKZjukktkOqWS2QyqZ7ZBKZjukktkOqWS2QyqZ7ZBKZjuk\nktkOqWS2QyqZ7ZBKZjukvwMDFVjka/xGaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a283bd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a27202d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADtpJREFUeJztXMmS5FhWPZpHd/kcU0YOnVWdXVVYGxhb+BY+gw2fwYY/\n4Rd6RZthRlU3nZWZUTG5R/ggd9c8sTg3wFilrx5lhu5GEfKn9/Suzp2vpHVdh57UkP5/fQP/n6hn\ntkLqma2QemYrpJ7ZCqlntkLqma2QemYrpJ7ZCslUudg//PO/dACQaAlMwwAAVLVEsFoNAHDsEJ2n\nAQBszQUAWE6BOM4BAJHhAwCKQwEAqA0LvmcBAPbgXG3TwM/4uxVyrvvbPa8raqSmDQBoWm5/6HKM\nUxXY67yPl8h6qJuIHK55LDLeq871HKdDmrUAgH/9p3/Uvrb/HtkKSSmydYPPtms7FAWBUHsVAMCy\niZDtNsGiHQEA8oZjdk6HoKUkPKVEl15wrjrfox2EAID18wMAYBMnuJhdAgCmI/5Wdg0AwA41OPsd\nACA2iFAt4HqZ4WBwIKJ3myMAoLB87HRKhRNS0po6BQCs8hpd9lVA/zcpZXbBvaEtbfhjh+c6nkwO\nFN/S0/EljQEAvsEH0NUNipzMroVp8WEDAJiMz1CUOxlH1ZEfKjSvqHY8g4z0plQFWm7BfM1xyRO3\nPzBKjik93Ge8D9v0OF5z0FR8sPe3HPeiDy5NE7nvnrz/Xo0oJKXIXidbAIBxTFFrRJqRUgzzgmi7\nfVwjmo0BAF1E1NtagDokqp5THrWW6qdtC6QpUd5eEP2DxWuYPs8tk3sAwMPHBADgjs4xyoixkUnp\n8lOi87lLoYHGc07tA71xUORyrc/r4iP/Dy8vMLLsk/ffI1shKUX2w+0zAMDwIhw2RES+XwMASqpi\nNOEM45T/ND6N1So7oK4eAQDJLgAAXF8QevtDigdB6KiLAACD6QBJzGsHMREeuTSsQbEFTG7bjyhN\nQ5tzZs8FZi519Zt37wAAVtciLSlFf/rpPwAAZyNK3qwFgmh48v57ZCskpchGSO9Cc49wj0RVYRHF\nusZbscIUtUlUZksZE4TYaBcAgPGCut684DFdrRDa1LlXeyLQRYZwyiX9Ef+YWm8AALvtEY2sNbG5\ndpeK52F6uJzPeV3AOY9pAgf8/Yfvr3hfa9qGN9dThKPBydtXymzD4sa7dotCp2H0GzLIk6hxdNkh\nk2iyyM8BAElWoj3QvYuuyaA0WwEAHu8eMb/gvLO/+hvO/8saU5sq5fViAgC4AJmXXBgwKs5RWHQP\ni5jr/WBF6Byqt/FoBgA4FgMcxLdfP5Gx3phsG02HOJ+dnbz/Xo0oJKXIrg9LAEDr+Yi3Ek0WRNLF\ntxIF3tYoMkZvjU1Xcehl8HVRQQFF+u7fqGIq/QxTk4jTWkrH5fvf42//+jcAgFcmJSfViOLvDyNk\nBec3dKor76qV9UoEAVliGpxzX+bYPjOCfNA4Psnpfr47n2E4PV2N9MhWSGp1tk/0um6IqU+XrwKN\nTXb7CwDAnk1QW3TlBMxwnBCjMxrE5IFBSrigTt09l3g48Dd/R+z87m0Hp2JAVPn8LTgSjbvzA3Bz\nAACYA/7mSHrDaS1kLSUGBaVqn8SoC7IpHNJFHIx4tIwCj2vmY7D45qv7V8psraFhqjoNtc2lDTFI\nZk6DVm32KFoy2xUu+MEMn8UjOBt8BwDIdD6k7vkLKkksVY34y4WL4nADAGhqGkZN8jJv8zO0C861\nzJhQSo/0xW+OJb65ptezOVDVbI8V2ooG1AInqRuqk+WhBCqOw3df33+vRhSS2hSrPNu86ZBLFs8a\nES3djGjbJzqqhOM0AhZP1QoBiLi8IqpsSJT5eorWZZZQKynSX0wLM/HR4wn969eSRh12CdKUSDXE\nP398pgR1wxrLj0SqN+E6rmtgl3Ct4YRq8MWAx2mN9vQMa49slaQU2btQ9LTd4HxOA5fdUl9mS8lP\nz0IUIfW3YxDazREo7+8AAGd/91sAgP5SvtJa6Fsi7m7NOYz/XOPniDhyN184bk7039stNJfB0jsu\ng/CSlnj97zVWM65ZPAp6Ewczn3alLGVNnVL4+HQDdO3J+++RrZCUIntSUEcW9hGHlujIpZCrBwyJ\nDURwLSLImxJ6T9MAppTBHlccb66koDuo0GyI7IHJvIZjOGhzIlOziPZf7mkbsmKL6yupCgXvAQDL\nmq4gBjaOGZE9DKWyU2bIxD2ttwxu2o73cKiPsO3Tka2U2fuXiK1ysbHIPFvqh0bMDddmgVXBB9F0\nZOi00OGAfnL3UsfUyUxXCzCUktfHT3T3dv4Qdz+RIb9/TXcwiOifB5aJxZgPpS45/+c/3AIAtFGL\nuiRjVzYf0tRbQG+5pi/q5O72ifegGVg3+5P336sRhaQ2gjQYrOzvj9DnNFyZQ+RFLo9F5WAmqU+j\nlIBnvkZ5w7/rlCWpvKXBM+0SqcMEvnHBDJ9WVHg3ptq4BSXgg7kAAPiaCxiUnM93LGZspOxl3Tiw\nxlR1rmQGjdBEo1FVLO+ZaXwoOL5Jc+hGcPL+e2QrJLXFA9HBMBP4R8mqOTymC7kVy0OuE1VnayJI\n2xgYTBk9fNpRp3o1jWf5PMHVNccNIOF6l2Fr0OAuwIT/WUvJuJ68hnOg/v/5888AgPuY60XOAVbC\n+c/eUK+P5jPED8yTrJ943K15dCIf/sQ7eftq1UhLL0BHhwpk0MghU8KOm3u42yEKXyrWVBV1NcQG\nfFAj8VRaSSzVeoHHH2l4jW9pKNvAxAeDnsZoTma8fc8INAoH+PHxEwBgVzA3UiRyzE3UUswYg6pj\nFHhoLd7jdiDV/oTr7ZMjRovpyfvv1YhCUotsl8/WCENYUrtrVxTlOP8MAPBHrxB24s9qHO9FJm5i\nIs6ppdcjpOjP31wj3f4FAHDYc84PV1NcXdFohi5zIl+2NIbO5gnplqiNTI5pHErNYlLCvqB6qhuu\nc3e3hCXRqmPRTU1MShyaHLqRnrz/HtkKSSmysydxsXwAR7pkuk8EdRV18DptkQ1opIYFzy3zDnXM\na6dTunfvfveac9U6puYHAICWSZOmWyPRRff6PIat5LWfckQabYJzLuWwmuttMMVbkZzKINr32wJ1\nxQBp8xMDr/GE45u5Ay3wT95/j2yFpDaf7RCddRWgfiayTclnmFNa+lmkIdgbcoWE7VmKbfvSiC69\nfjpx0po5nn9ht1S6F6/keo6LkHrWfUVEvxR3b/8SY50SoaOACHcn1N1nzTmcIX+LNHY97dZrPD+w\nUG2N6Xn4FC4EoQ9HH528f6XM9k0anzaKUEpLbjCk2B4z6Z8+5GgkEjQeWAzwqxrmhBFgviFj//wH\n5ifqbY10Q+PnWmRo6v0A4zX7OVJN/O0hU7ql3WJ7w1yInnPtMicTrfMDrn2JNB0+zNsva2w3K7lX\n3qN25MMJJiHm49OVQ69GFJJSZCealLLiNST9gc+N9Hzs6U7p6wMcnYgb1jRM9lsb1poXeCAKm5yI\nTdsjRguWvt7OKDmmZaCRgGX1JxrIfcWozy7/R0WYElUOpDQXBCbcTiQtZbW/Tl10Epl6LtnlhBzv\n1g2SXe/6/SpJbUeU5I9904YpqK0+MagxAukpWQQoJGaoMim6zmzU4gZiTF3sbqlHnTMLl+fUoROf\nCBy6IZyJuGTSfiwvkqGxTYRTjttpEsxEtB+u2+A+ZSivbSg5ppngt7/h+zkLl4Z7L2xzmxxGfToL\ne2QrJKXIdjpx6SoLtcGlzwdEkC93snanqG/ocZhDIs8sQ0jcASdhKG+MqW8DP0BZUS83AyLWHs8Q\nDOjRJBUlp3opX22BeEcvx7EkXPeI/sHFFLpkJo8Nb+gisjAKKU2GVHFCixnI8bBCrp/OQrV+9rOU\ntuY+GiknVU/0a8shjZtdJGgM6ZvOaYjSrEAwYUXc2pIZN3+k+xZMa8zPJNH/zSsAgDOrcPPHjwCA\nTUwD9v2YzD8kK7gT+t6jjqpmNqbBvPCmgC8V9JKuZXHQYFiMCWyLcxSmrGfb0Mq+ePCrJLVBzYjI\nztocpoiwN6Z4ux5FdD2K8EHeBIufpfi6rFAcKQnZs1TCJSunFXsYMaO4g6iHo1Mhkp7AhbT0tjsG\nPvbAhO8SyVpIq3m0aZxru4bBpVEfifC8bNFuqTaiOaVEl2r7/cGDLjn3U6hHtkJSiuwmoVE7eDY0\neZP2jRi1LqAenOzu8fBEFDa5oLI8wJtSEsbvWebynmlEP5pjrJcsHn/7+D0A4Kpy4IzF17PETSto\n5IokxvqWbuNA3E39O7YvL38soI2l57Ci4W6LCpuK41dPRLgVSSVp52AvxWL8/df3r5bZL33Qlg5n\nygRUuSajkNDwZUWJAGRCa0sJLM9xjKVMZVOE7W/IvPPVClvJYxSfaBQfizM0R6qUWN7VGSylxbhL\noDecaxNz7TP3IP+/xzxhv8heZL49HrB/5rmklletDUnXtiViMeanUK9GFJJSZNsmETvVG1g50XK7\nlJdBXfkAwHSGtxWRV75Yq8DAtpPvhsiL/1c3dMfCIEFayUcHBDrHpyNQEMljgy7lKpYuprpBFlNN\neR63H3xhviWYLPH5jpFt6ErfyWqDuqRhLCWIdeQVQyvX0Fkv6eCvU49shaS4lUH0mx7iacW+PEgr\ng/uKAcOiSGBIOOlLp/moGSKWL+HUDl2t/FJyKWsPkehNK+McelMiTSgV3XQp54jYztRhyrs9g4AI\nLRoaufinNSpxO58kw6ejgG/+794QxySatbCEXvWfwPhVklJkBx2tfhXnqBKiypGX9gvpXG2NFmOd\n7uC+JBqTuoTvyItCDXXpoOX1OXRE59JVJdtJuhZRThyVKc9pJa8vRxWMPXXwsZGv7Tj0MvbaGsMB\n9beXU1paq4YtRekkpzs5HTLMv13maJGdvH/Fny2SGmG1hd9xg35LF24mb2Jluz1KU9KnDTdepjEG\nkiAyXHlXZskH59ozWPKq9HwujZvbCm4mvSdSRGg9acxcVUjlmyWhT189Tlky89wBDOlVKRdkorYZ\nocvkw10hH34qnV227WIR9W8e/CpJ6z9Wro56ZCukntkKqWe2QuqZrZB6ZiukntkKqWe2QuqZrZB6\nZiukntkKqWe2QuqZrZB6ZiukntkKqWe2QuqZrZB6ZiukntkKqWe2QuqZrZB6ZiukntkKqWe2Qvov\nF0/RSbuwKX8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68a24c36d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets visualize one sample from each dataset\n",
    "x_vis = np.random.choice(range(0,num_test_samples), 1)\n",
    "visualize(reg_data[x_vis].reshape(32,32,3))\n",
    "visualize(noisy_data[x_vis].reshape(32,32,3))\n",
    "visualize(fgsm_data[x_vis].reshape(32,32,3))\n",
    "visualize(bim_data[x_vis].reshape(32,32,3))\n",
    "visualize(cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p1_cw_data[x_vis].reshape(32,32,3))\n",
    "visualize(p2_cw_data[x_vis].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "reg_preds = model.model.predict(reg_data.reshape(-1,32,32,3))\n",
    "noisy_preds = model.model.predict(noisy_data.reshape(-1,32,32,3))\n",
    "fgsm_preds = model.model.predict(fgsm_data.reshape(-1,32,32,3))\n",
    "bim_preds = model.model.predict(bim_data.reshape(-1,32,32,3))\n",
    "cw_preds = model.model.predict(cw_data.reshape(-1,32,32,3))\n",
    "p1_cw_preds = model.model.predict(p1_cw_data.reshape(-1,32,32,3))\n",
    "p2_cw_preds = model.model.predict(p2_cw_data.reshape(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert preds to labels\n",
    "reg_labels = np.zeros(reg_preds.shape)\n",
    "reg_labels[np.arange(num_test_samples),np.argmax(reg_preds, axis=1)] = 1\n",
    "\n",
    "noisy_labels = np.zeros(noisy_preds.shape)\n",
    "noisy_labels[np.arange(num_test_samples),np.argmax(noisy_preds, axis=1)] = 1\n",
    "\n",
    "fgsm_labels = np.zeros(fgsm_preds.shape)\n",
    "fgsm_labels[np.arange(num_test_samples),np.argmax(fgsm_preds, axis=1)] = 1\n",
    "\n",
    "bim_labels = np.zeros(bim_preds.shape)\n",
    "bim_labels[np.arange(num_test_samples),np.argmax(bim_preds, axis=1)] = 1\n",
    "\n",
    "cw_labels = np.zeros(cw_preds.shape)\n",
    "cw_labels[np.arange(num_test_samples),np.argmax(cw_preds, axis=1)] = 1\n",
    "\n",
    "p1_cw_labels = np.zeros(p1_cw_preds.shape)\n",
    "p1_cw_labels[np.arange(num_test_samples),np.argmax(p1_cw_preds, axis=1)] = 1\n",
    "\n",
    "p2_cw_labels = np.zeros(p2_cw_preds.shape)\n",
    "p2_cw_labels[np.arange(num_test_samples),np.argmax(p2_cw_preds, axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 6 5 5 5 5 5 5 5 6 6 6 6 6 6 6 1 6 6 1 1 1 7\n",
      " 7 7 7 7 7 7 6 8 8 1 6 8 8 9 8 8 9 9 9 6 9 9 9 9 9 9]\n",
      "[0 9 1 6 1 1 3 0 9 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 5\n",
      " 3 1 3 4 4 4 1 4 4 2 1 4 4 5 5 6 5 5 5 5 1 5 5 6 5 6 5 2 6 6 1 6 6 1 1 1 1\n",
      " 1 2 1 2 7 2 6 1 3 1 6 8 8 2 8 8 2 9 9 2 9 9 9 3 2 9]\n",
      "[5 5 5 5 5 4 5 1 5 2 1 2 2 2 2 5 3 6 2 1 5 2 4 5 3 1 2 2 2 5 2 2 1 1 9 2 5\n",
      " 2 4 5 6 5 1 1 1 5 9 5 1 2 6 3 6 5 1 5 6 1 1 1 1 2 2 3 5 0 5 1 5 6 1 4 1 1\n",
      " 3 1 2 1 2 2 6 5 3 1 1 1 2 2 5 6 1 2 3 5 1 9 5 2 3 5]\n",
      "[5 8 5 5 8 5 5 4 5 3 3 5 6 0 3 2 0 0 4 0 5 5 5 3 6 6 3 0 0 6 7 9 2 0 9 2 6\n",
      " 2 1 5 0 3 3 1 1 0 2 6 6 3 6 3 3 6 3 0 6 6 1 7 7 3 2 3 2 0 3 0 3 3 3 4 7 0\n",
      " 9 2 9 9 2 2 2 1 3 9 2 2 9 2 5 6 6 2 3 9 2 2 3 0 6 5]\n",
      "[8 9 9 5 6 9 8 6 9 2 3 2 3 0 3 2 8 0 4 0 5 3 9 3 3 0 7 3 0 7 7 8 8 1 8 2 5\n",
      " 8 1 5 6 3 1 1 1 1 2 5 6 3 6 3 5 6 3 8 6 6 3 3 8 5 8 5 8 0 5 0 3 0 2 4 7 1\n",
      " 0 2 2 3 2 2 8 6 3 0 8 6 9 2 3 6 8 2 3 9 2 2 5 0 0 5]\n",
      "[1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 5 6 7 7 7 6 7 7 6 1 7 7 8 1 1 8\n",
      " 8 8 8 8 8 7 6 8 8 9 6 9 9 9 9 9 0 9 9 0 0 0 9 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 8 8 8 8\n",
      " 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Check preds to ensure adversarial samples were generated correctly\n",
    "print (np.argmax(reg_preds, axis=1))\n",
    "print (np.argmax(noisy_preds, axis=1))\n",
    "print (np.argmax(fgsm_preds, axis=1))\n",
    "print (np.argmax(bim_preds, axis=1))\n",
    "print (np.argmax(cw_preds, axis=1))\n",
    "print (np.argmax(p1_cw_preds, axis=1))\n",
    "print (np.argmax(p2_cw_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get gradients for all test points\n",
    "grads_reg = model.get_gradients_wrt_params(reg_data, reg_labels)\n",
    "grads_noisy = model.get_gradients_wrt_params(noisy_data, noisy_labels)\n",
    "grads_fgsm = model.get_gradients_wrt_params(fgsm_data, fgsm_labels)\n",
    "grads_bim = model.get_gradients_wrt_params(bim_data, bim_labels)\n",
    "grads_cw = model.get_gradients_wrt_params(cw_data, cw_labels)\n",
    "grads_p1_cw = model.get_gradients_wrt_params(p1_cw_data, p1_cw_labels)\n",
    "grads_p2_cw = model.get_gradients_wrt_params(p2_cw_data, p2_cw_labels)\n",
    "\n",
    "#Get gradients for training points \n",
    "grads_train = model.get_gradients_wrt_params(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_reg_nm = normalize(grads_reg)\n",
    "grads_noisy_nm = normalize(grads_noisy)\n",
    "grads_fgsm_nm = normalize(grads_fgsm)\n",
    "grads_bim_nm = normalize(grads_bim)\n",
    "grads_cw_nm = normalize(grads_cw)\n",
    "grads_p1_cw_nm = normalize(grads_p1_cw)\n",
    "grads_p2_cw_nm = normalize(grads_p2_cw)\n",
    "grads_train_nm = normalize(grads_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in sqrt\n",
      "  import sys\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Get norms \n",
    "grads_reg_norms = np.sqrt(np.dot(grads_reg, grads_reg.T)).diagonal()\n",
    "grads_noisy_norms = np.sqrt(np.dot(grads_noisy, grads_noisy.T)).diagonal()\n",
    "grads_bim_norms = np.sqrt(np.dot(grads_bim, grads_bim.T)).diagonal()\n",
    "grads_fgsm_norms = np.sqrt(np.dot(grads_fgsm, grads_fgsm.T)).diagonal()\n",
    "grads_cw_norms = np.sqrt(np.dot(grads_cw, grads_cw.T)).diagonal()\n",
    "grads_p1_cw_norms = np.sqrt(np.dot(grads_p1_cw, grads_p1_cw.T)).diagonal()\n",
    "grads_p2_cw_norms = np.sqrt(np.dot(grads_p2_cw, grads_p2_cw.T)).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity matrix\n",
    "cos_sim_reg = np.dot(grads_reg_nm, grads_train_nm.T)\n",
    "cos_sim_noisy = np.dot(grads_noisy_nm, grads_train_nm.T)\n",
    "cos_sim_fgsm = np.dot(grads_fgsm_nm, grads_train_nm.T)\n",
    "cos_sim_bim = np.dot(grads_bim_nm, grads_train_nm.T)\n",
    "cos_sim_cw = np.dot(grads_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p1_cw = np.dot(grads_p1_cw_nm, grads_train_nm.T)\n",
    "cos_sim_p2_cw = np.dot(grads_p2_cw_nm, grads_train_nm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8700\n",
      "Noisy:  0.6300\n",
      "FGSM:  0.1700\n",
      "BIM:  0.7200\n",
      "CW: 0.5200\n",
      "1 Phase CW:  0.5100\n",
      "2 Phase CW:  0.5200\n"
     ]
    }
   ],
   "source": [
    "#Separate Using Cos Sim\n",
    "\n",
    "eta = 0.45\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('1 Phase CW:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('2 Phase CW:  %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.8700\n",
      "Noisy:  0.5900\n",
      "FGSM:  0.4300\n",
      "BIM:  0.9700\n",
      "CW: 0.5400\n",
      "1 Phase CW: 0.7300\n",
      "2 Phase CW: 0.5100\n"
     ]
    }
   ],
   "source": [
    "#Separate using just norm\n",
    "gamma = 55.45\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 0.7700\n",
      "Noisy:  0.3100\n",
      "FGSM:  0.0300\n",
      "BIM:  0.7200\n",
      "CW: 0.3500\n",
      "1 Phase CW: 0.3500\n",
      "2 Phase CW: 0.3000\n"
     ]
    }
   ],
   "source": [
    "#Use both cos and norm\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_reg[i]) > eta and grads_reg_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('Regular: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count = 0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_noisy[i]) > eta and grads_noisy_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('Noisy:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_fgsm[i]) > eta and grads_fgsm_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('FGSM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_bim[i]) > eta and grads_bim_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "        \n",
    "print ('BIM:  %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_cw[i]) > eta and grads_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p1_cw[i]) > eta and grads_p1_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('1 Phase CW: %.4f' % ( count/num_test_samples))\n",
    "\n",
    "count=0.0\n",
    "for i in range(num_test_samples):\n",
    "    if np.max(cos_sim_p2_cw[i]) > eta and grads_p2_cw_norms[i] < gamma:\n",
    "        count+=1.0\n",
    "    \n",
    "print ('2 Phase CW: %.4f' % ( count/num_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_l2_distortion(orig, adv):\n",
    "    \"\"\"Get the mean l2 distortion between two orig and adv images\"\"\"\n",
    "    l2_dist = 0.0\n",
    "    for i in range(orig.shape[0]):\n",
    "        l2_dist+= np.linalg.norm(orig[i] - adv[i])\n",
    "    return l2_dist/orig.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47094364166\n",
      "2.99962949991\n",
      "1.90662316561\n",
      "3.88002795231\n",
      "2.10292658372\n"
     ]
    }
   ],
   "source": [
    "print (avg_l2_distortion(reg_data, fgsm_data))\n",
    "print (avg_l2_distortion(reg_data, bim_data))\n",
    "print (avg_l2_distortion(reg_data, cw_data))\n",
    "print (avg_l2_distortion(reg_data, p1_cw_data))\n",
    "print (avg_l2_distortion(reg_data, p2_cw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
